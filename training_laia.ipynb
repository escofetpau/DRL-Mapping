{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "import gymnasium as gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/laia/Documents/GNN-DRL-qbit-allocation/')  # Cambia esto por la ruta absoluta a src\n",
    "from src.environment.env import GraphSeriesEnv\n",
    "from src.models.ppo_policy import CustomPPOPolicy\n",
    "from src.models.feature_extractor import GATv2FeatureExtractor\n",
    "from data.circuit_generator import generate_circuit\n",
    "from src.utils.callback import CustomTensorboardCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.constants import N_CORES, OUT_FEATURES_GAT\n",
    "\n",
    "\n",
    "run_id = datetime.datetime.now().strftime(\"%m_%d-%H_%M_%S\")\n",
    "\n",
    "\n",
    "gnn_config = dict(\n",
    "                  in_features = 2*N_CORES,\n",
    "                  edge_dim = 2,\n",
    "                  hidden_features_gat = 64,\n",
    "                  out_features_gat = OUT_FEATURES_GAT,\n",
    "                  num_heads = 1,\n",
    "                  hidden_layers_gat=4,\n",
    "                  gat_dropout = 0.3\n",
    "                  )\n",
    "\n",
    "\n",
    "config = {\n",
    "    'circuit_config': {'circuit': None , 'random_circuits': True, 'n_slices': 32, 'n_qubits': 8, 'gates_per_slice': 1},\n",
    "    'weights_reward': {'nonlocal': 10, 'capacity': 30, 'intervention': 40, 'slice_idx': 50},\n",
    "    'ppo_config': {'batch_size': 64, 'learning_rate': 0.0005, 'n_steps': 4096 , 'gae_lambda': 0.95},\n",
    "    'policy_kwargs': {'net_arch': [64, 64, 64], 'features_extractor_kwargs': gnn_config},\n",
    "    'total_timesteps': 3000000\n",
    "    }\n",
    "\n",
    "\n",
    "load_model = False\n",
    "load_path = 'models/'\n",
    "run_dir = f\"runs/{run_id}/\"\n",
    "\n",
    "\n",
    "model_dir = f'models/{run_id}/'\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "with open(model_dir + 'config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "\n",
    "config['policy_kwargs']['features_extractor_class'] = GATv2FeatureExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ActionMasker<GraphSeriesEnv instance>>\n"
     ]
    }
   ],
   "source": [
    "# environment\n",
    "\n",
    "a = sparse.load_npz('../data/cuccaroadder_q8.npz')\n",
    "#circuit_config = {'circuit': a}\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    env = GraphSeriesEnv(config=config['circuit_config'], weights_reward=config['weights_reward'])\n",
    "    env = ActionMasker(env, lambda e: e.qbit_mask())\n",
    "    #env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "print(env.envs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "{}\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "if load_model:\n",
    "    model = MaskablePPO.load(load_path, env=env, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "else:\n",
    "    model = MaskablePPO(policy=CustomPPOPolicy,\n",
    "                policy_kwargs=config['policy_kwargs'],\n",
    "                env = env,\n",
    "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                verbose = 1,\n",
    "                seed = 42,\n",
    "                tensorboard_log = 'runs',\n",
    "                **config['ppo_config']\n",
    "            )\n",
    "\n",
    "print(model.device)\n",
    "\n",
    "\n",
    "feature_extr = model.policy.features_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs/01_10-16_22_27_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "| episode/                         |          |\n",
      "|    direct_capacity_violation_sum | 0        |\n",
      "|    final_reward                  | -2640.0  |\n",
      "|    intervention_sum              | 34       |\n",
      "|    nl_comm_sum                   | 128      |\n",
      "| time/                            |          |\n",
      "|    fps                           | 68       |\n",
      "|    iterations                    | 1        |\n",
      "|    time_elapsed                  | 59       |\n",
      "|    total_timesteps               | 4096     |\n",
      "| total/                           |          |\n",
      "|    truncated                     | 0        |\n",
      "-----------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -2460.0     |\n",
      "|    intervention_sum              | 30          |\n",
      "|    nl_comm_sum                   | 126         |\n",
      "| time/                            |             |\n",
      "|    fps                           | 52          |\n",
      "|    iterations                    | 2           |\n",
      "|    time_elapsed                  | 157         |\n",
      "|    total_timesteps               | 8192        |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008515568 |\n",
      "|    clip_fraction                 | 0.0531      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.86       |\n",
      "|    explained_variance            | -1.59e-05   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 6.96e+03    |\n",
      "|    n_updates                     | 10          |\n",
      "|    policy_gradient_loss          | -0.00587    |\n",
      "|    value_loss                    | 1.67e+04    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -2420.0      |\n",
      "|    intervention_sum              | 28           |\n",
      "|    nl_comm_sum                   | 130          |\n",
      "| time/                            |              |\n",
      "|    fps                           | 48           |\n",
      "|    iterations                    | 3            |\n",
      "|    time_elapsed                  | 251          |\n",
      "|    total_timesteps               | 12288        |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066382545 |\n",
      "|    clip_fraction                 | 0.0367       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -1.84        |\n",
      "|    explained_variance            | 1.19e-07     |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 6.44e+03     |\n",
      "|    n_updates                     | 20           |\n",
      "|    policy_gradient_loss          | -0.00445     |\n",
      "|    value_loss                    | 1.72e+04     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -2280.0      |\n",
      "|    intervention_sum              | 28           |\n",
      "|    nl_comm_sum                   | 116          |\n",
      "| time/                            |              |\n",
      "|    fps                           | 47           |\n",
      "|    iterations                    | 4            |\n",
      "|    time_elapsed                  | 344          |\n",
      "|    total_timesteps               | 16384        |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066592135 |\n",
      "|    clip_fraction                 | 0.035        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -1.83        |\n",
      "|    explained_variance            | 0            |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 8.17e+03     |\n",
      "|    n_updates                     | 30           |\n",
      "|    policy_gradient_loss          | -0.00385     |\n",
      "|    value_loss                    | 1.54e+04     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -2000.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 112         |\n",
      "| time/                            |             |\n",
      "|    fps                           | 46          |\n",
      "|    iterations                    | 5           |\n",
      "|    time_elapsed                  | 437         |\n",
      "|    total_timesteps               | 20480       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009399194 |\n",
      "|    clip_fraction                 | 0.0808      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.8        |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 6.48e+03    |\n",
      "|    n_updates                     | 40          |\n",
      "|    policy_gradient_loss          | -0.00626    |\n",
      "|    value_loss                    | 1.46e+04    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1760.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 96          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 46          |\n",
      "|    iterations                    | 6           |\n",
      "|    time_elapsed                  | 530         |\n",
      "|    total_timesteps               | 24576       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008670555 |\n",
      "|    clip_fraction                 | 0.0861      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.76       |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 5.31e+03    |\n",
      "|    n_updates                     | 50          |\n",
      "|    policy_gradient_loss          | -0.00612    |\n",
      "|    value_loss                    | 1.19e+04    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -2180.0      |\n",
      "|    intervention_sum              | 24           |\n",
      "|    nl_comm_sum                   | 122          |\n",
      "| time/                            |              |\n",
      "|    fps                           | 46           |\n",
      "|    iterations                    | 7            |\n",
      "|    time_elapsed                  | 623          |\n",
      "|    total_timesteps               | 28672        |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0068333764 |\n",
      "|    clip_fraction                 | 0.0518       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -1.74        |\n",
      "|    explained_variance            | 0            |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 4.57e+03     |\n",
      "|    n_updates                     | 60           |\n",
      "|    policy_gradient_loss          | -0.0037      |\n",
      "|    value_loss                    | 1.08e+04     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -2140.0      |\n",
      "|    intervention_sum              | 25           |\n",
      "|    nl_comm_sum                   | 114          |\n",
      "| time/                            |              |\n",
      "|    fps                           | 45           |\n",
      "|    iterations                    | 8            |\n",
      "|    time_elapsed                  | 715          |\n",
      "|    total_timesteps               | 32768        |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0076770247 |\n",
      "|    clip_fraction                 | 0.0685       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -1.71        |\n",
      "|    explained_variance            | 0            |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 4.35e+03     |\n",
      "|    n_updates                     | 70           |\n",
      "|    policy_gradient_loss          | -0.00497     |\n",
      "|    value_loss                    | 1.05e+04     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1560.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 88          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 9           |\n",
      "|    time_elapsed                  | 808         |\n",
      "|    total_timesteps               | 36864       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008919423 |\n",
      "|    clip_fraction                 | 0.119       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.63       |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.56e+03    |\n",
      "|    n_updates                     | 80          |\n",
      "|    policy_gradient_loss          | -0.00722    |\n",
      "|    value_loss                    | 8.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1800.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 80          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 10          |\n",
      "|    time_elapsed                  | 901         |\n",
      "|    total_timesteps               | 40960       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006969681 |\n",
      "|    clip_fraction                 | 0.0905      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.62       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 4.02e+03    |\n",
      "|    n_updates                     | 90          |\n",
      "|    policy_gradient_loss          | -0.00538    |\n",
      "|    value_loss                    | 8.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 88          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 11          |\n",
      "|    time_elapsed                  | 993         |\n",
      "|    total_timesteps               | 45056       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008517064 |\n",
      "|    clip_fraction                 | 0.089       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.57       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.03e+03    |\n",
      "|    n_updates                     | 100         |\n",
      "|    policy_gradient_loss          | -0.00461    |\n",
      "|    value_loss                    | 6.89e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 12          |\n",
      "|    time_elapsed                  | 1086        |\n",
      "|    total_timesteps               | 49152       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008982079 |\n",
      "|    clip_fraction                 | 0.108       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.51       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.51e+03    |\n",
      "|    n_updates                     | 110         |\n",
      "|    policy_gradient_loss          | -0.00414    |\n",
      "|    value_loss                    | 6.09e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1480.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 80         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 45         |\n",
      "|    iterations                    | 13         |\n",
      "|    time_elapsed                  | 1178       |\n",
      "|    total_timesteps               | 53248      |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00894638 |\n",
      "|    clip_fraction                 | 0.0972     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -1.47      |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 2.01e+03   |\n",
      "|    n_updates                     | 120        |\n",
      "|    policy_gradient_loss          | -0.00355   |\n",
      "|    value_loss                    | 6.05e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 14          |\n",
      "|    time_elapsed                  | 1271        |\n",
      "|    total_timesteps               | 57344       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014611041 |\n",
      "|    clip_fraction                 | 0.115       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.41       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3e+03       |\n",
      "|    n_updates                     | 130         |\n",
      "|    policy_gradient_loss          | -0.00402    |\n",
      "|    value_loss                    | 5.13e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 45          |\n",
      "|    iterations                    | 15          |\n",
      "|    time_elapsed                  | 1363        |\n",
      "|    total_timesteps               | 61440       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013103599 |\n",
      "|    clip_fraction                 | 0.12        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.37       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.67e+03    |\n",
      "|    n_updates                     | 140         |\n",
      "|    policy_gradient_loss          | -0.00376    |\n",
      "|    value_loss                    | 5.45e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1660.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 82         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 16         |\n",
      "|    time_elapsed                  | 1457       |\n",
      "|    total_timesteps               | 65536      |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.10700518 |\n",
      "|    clip_fraction                 | 0.269      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -1.28      |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 2.46e+03   |\n",
      "|    n_updates                     | 150        |\n",
      "|    policy_gradient_loss          | 0.0112     |\n",
      "|    value_loss                    | 4.46e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1880.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 92          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 17          |\n",
      "|    time_elapsed                  | 1549        |\n",
      "|    total_timesteps               | 69632       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014732726 |\n",
      "|    clip_fraction                 | 0.102       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.36       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.58e+03    |\n",
      "|    n_updates                     | 160         |\n",
      "|    policy_gradient_loss          | 0.000908    |\n",
      "|    value_loss                    | 5.4e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1640.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 80         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 18         |\n",
      "|    time_elapsed                  | 1642       |\n",
      "|    total_timesteps               | 73728      |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03421081 |\n",
      "|    clip_fraction                 | 0.256      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -1.35      |\n",
      "|    explained_variance            | -1.19e-07  |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 4.86e+03   |\n",
      "|    n_updates                     | 170        |\n",
      "|    policy_gradient_loss          | 0.0175     |\n",
      "|    value_loss                    | 5.77e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1800.0    |\n",
      "|    intervention_sum              | 25         |\n",
      "|    nl_comm_sum                   | 80         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 19         |\n",
      "|    time_elapsed                  | 1735       |\n",
      "|    total_timesteps               | 77824      |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02279533 |\n",
      "|    clip_fraction                 | 0.187      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -1.29      |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 1.44e+03   |\n",
      "|    n_updates                     | 180        |\n",
      "|    policy_gradient_loss          | 0.00439    |\n",
      "|    value_loss                    | 5.88e+03   |\n",
      "-------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1660.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 74           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 20           |\n",
      "|    time_elapsed                  | 1827         |\n",
      "|    total_timesteps               | 81920        |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0063301283 |\n",
      "|    clip_fraction                 | 0.0922       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -1.27        |\n",
      "|    explained_variance            | 0            |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 3.81e+03     |\n",
      "|    n_updates                     | 190          |\n",
      "|    policy_gradient_loss          | -0.000454    |\n",
      "|    value_loss                    | 5.97e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 21          |\n",
      "|    time_elapsed                  | 1920        |\n",
      "|    total_timesteps               | 86016       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011649533 |\n",
      "|    clip_fraction                 | 0.139       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.22       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.87e+03    |\n",
      "|    n_updates                     | 200         |\n",
      "|    policy_gradient_loss          | 0.00335     |\n",
      "|    value_loss                    | 6.05e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1580.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 22          |\n",
      "|    time_elapsed                  | 2013        |\n",
      "|    total_timesteps               | 90112       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012994534 |\n",
      "|    clip_fraction                 | 0.158       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.16       |\n",
      "|    explained_variance            | 5.96e-08    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 4.43e+03    |\n",
      "|    n_updates                     | 210         |\n",
      "|    policy_gradient_loss          | 0.00136     |\n",
      "|    value_loss                    | 5.84e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 23          |\n",
      "|    time_elapsed                  | 2106        |\n",
      "|    total_timesteps               | 94208       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020522699 |\n",
      "|    clip_fraction                 | 0.183       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.17       |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 5.45e+03    |\n",
      "|    n_updates                     | 220         |\n",
      "|    policy_gradient_loss          | 0.00386     |\n",
      "|    value_loss                    | 6.14e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 24          |\n",
      "|    time_elapsed                  | 2199        |\n",
      "|    total_timesteps               | 98304       |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012473615 |\n",
      "|    clip_fraction                 | 0.179       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.18       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.07e+03    |\n",
      "|    n_updates                     | 230         |\n",
      "|    policy_gradient_loss          | 0.00319     |\n",
      "|    value_loss                    | 5.82e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_100000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 25          |\n",
      "|    time_elapsed                  | 2292        |\n",
      "|    total_timesteps               | 102400      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.030733073 |\n",
      "|    clip_fraction                 | 0.184       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.2        |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 4.02e+03    |\n",
      "|    n_updates                     | 240         |\n",
      "|    policy_gradient_loss          | 0.00367     |\n",
      "|    value_loss                    | 5.69e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1060.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 26          |\n",
      "|    time_elapsed                  | 2384        |\n",
      "|    total_timesteps               | 106496      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020640867 |\n",
      "|    clip_fraction                 | 0.178       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.24       |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.74e+03    |\n",
      "|    n_updates                     | 250         |\n",
      "|    policy_gradient_loss          | 0.00347     |\n",
      "|    value_loss                    | 6.25e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 27          |\n",
      "|    time_elapsed                  | 2477        |\n",
      "|    total_timesteps               | 110592      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017569104 |\n",
      "|    clip_fraction                 | 0.203       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.17       |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.29e+03    |\n",
      "|    n_updates                     | 260         |\n",
      "|    policy_gradient_loss          | 0.00572     |\n",
      "|    value_loss                    | 6.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 28          |\n",
      "|    time_elapsed                  | 2570        |\n",
      "|    total_timesteps               | 114688      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023146968 |\n",
      "|    clip_fraction                 | 0.178       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.13       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.14e+03    |\n",
      "|    n_updates                     | 270         |\n",
      "|    policy_gradient_loss          | 0.00139     |\n",
      "|    value_loss                    | 5.81e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 29          |\n",
      "|    time_elapsed                  | 2663        |\n",
      "|    total_timesteps               | 118784      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015617037 |\n",
      "|    clip_fraction                 | 0.167       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.12       |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 4.6e+03     |\n",
      "|    n_updates                     | 280         |\n",
      "|    policy_gradient_loss          | 0.00478     |\n",
      "|    value_loss                    | 6.08e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 30          |\n",
      "|    time_elapsed                  | 2755        |\n",
      "|    total_timesteps               | 122880      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018249473 |\n",
      "|    clip_fraction                 | 0.19        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.09       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.96e+03    |\n",
      "|    n_updates                     | 290         |\n",
      "|    policy_gradient_loss          | 0.00209     |\n",
      "|    value_loss                    | 6.07e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1100.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 42         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 31         |\n",
      "|    time_elapsed                  | 2848       |\n",
      "|    total_timesteps               | 126976     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01579519 |\n",
      "|    clip_fraction                 | 0.157      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -1.05      |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 3.34e+03   |\n",
      "|    n_updates                     | 300        |\n",
      "|    policy_gradient_loss          | 0.00387    |\n",
      "|    value_loss                    | 5.74e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 32          |\n",
      "|    time_elapsed                  | 2943        |\n",
      "|    total_timesteps               | 131072      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010665355 |\n",
      "|    clip_fraction                 | 0.126       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.998      |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.6e+03     |\n",
      "|    n_updates                     | 310         |\n",
      "|    policy_gradient_loss          | 0.00235     |\n",
      "|    value_loss                    | 5.42e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1320.0    |\n",
      "|    intervention_sum              | 20         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 33         |\n",
      "|    time_elapsed                  | 3036       |\n",
      "|    total_timesteps               | 135168     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01681522 |\n",
      "|    clip_fraction                 | 0.162      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.988     |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 2.61e+03   |\n",
      "|    n_updates                     | 320        |\n",
      "|    policy_gradient_loss          | 0.00375    |\n",
      "|    value_loss                    | 5.5e+03    |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 34          |\n",
      "|    time_elapsed                  | 3128        |\n",
      "|    total_timesteps               | 139264      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.030277804 |\n",
      "|    clip_fraction                 | 0.193       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.04       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.62e+03    |\n",
      "|    n_updates                     | 330         |\n",
      "|    policy_gradient_loss          | 0.00335     |\n",
      "|    value_loss                    | 5.83e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 35          |\n",
      "|    time_elapsed                  | 3220        |\n",
      "|    total_timesteps               | 143360      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022065142 |\n",
      "|    clip_fraction                 | 0.181       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -1.04       |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.81e+03    |\n",
      "|    n_updates                     | 340         |\n",
      "|    policy_gradient_loss          | 0.00481     |\n",
      "|    value_loss                    | 5.66e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -980.0      |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 38          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 36          |\n",
      "|    time_elapsed                  | 3313        |\n",
      "|    total_timesteps               | 147456      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028361041 |\n",
      "|    clip_fraction                 | 0.148       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.963      |\n",
      "|    explained_variance            | 5.96e-08    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.72e+03    |\n",
      "|    n_updates                     | 350         |\n",
      "|    policy_gradient_loss          | 0.00068     |\n",
      "|    value_loss                    | 5.71e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 37          |\n",
      "|    time_elapsed                  | 3406        |\n",
      "|    total_timesteps               | 151552      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028448537 |\n",
      "|    clip_fraction                 | 0.171       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.938      |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.6e+03     |\n",
      "|    n_updates                     | 360         |\n",
      "|    policy_gradient_loss          | 0.0047      |\n",
      "|    value_loss                    | 5.34e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 38          |\n",
      "|    time_elapsed                  | 3498        |\n",
      "|    total_timesteps               | 155648      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024142906 |\n",
      "|    clip_fraction                 | 0.15        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.912      |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.23e+03    |\n",
      "|    n_updates                     | 370         |\n",
      "|    policy_gradient_loss          | -0.000106   |\n",
      "|    value_loss                    | 5.44e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 39          |\n",
      "|    time_elapsed                  | 3590        |\n",
      "|    total_timesteps               | 159744      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014809884 |\n",
      "|    clip_fraction                 | 0.127       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.836      |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.02e+03    |\n",
      "|    n_updates                     | 380         |\n",
      "|    policy_gradient_loss          | 0.00249     |\n",
      "|    value_loss                    | 5.43e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 38          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 40          |\n",
      "|    time_elapsed                  | 3683        |\n",
      "|    total_timesteps               | 163840      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028060397 |\n",
      "|    clip_fraction                 | 0.168       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.837      |\n",
      "|    explained_variance            | -1.19e-07   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.86e+03    |\n",
      "|    n_updates                     | 390         |\n",
      "|    policy_gradient_loss          | 0.00195     |\n",
      "|    value_loss                    | 5.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 41          |\n",
      "|    time_elapsed                  | 3776        |\n",
      "|    total_timesteps               | 167936      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011645829 |\n",
      "|    clip_fraction                 | 0.138       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.815      |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.54e+03    |\n",
      "|    n_updates                     | 400         |\n",
      "|    policy_gradient_loss          | 0.00295     |\n",
      "|    value_loss                    | 5.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 42          |\n",
      "|    time_elapsed                  | 3868        |\n",
      "|    total_timesteps               | 172032      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025125246 |\n",
      "|    clip_fraction                 | 0.152       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.799      |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.67e+03    |\n",
      "|    n_updates                     | 410         |\n",
      "|    policy_gradient_loss          | 0.00256     |\n",
      "|    value_loss                    | 5.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 43          |\n",
      "|    time_elapsed                  | 3961        |\n",
      "|    total_timesteps               | 176128      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.036553003 |\n",
      "|    clip_fraction                 | 0.166       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.884      |\n",
      "|    explained_variance            | -3.25e-05   |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.78e+03    |\n",
      "|    n_updates                     | 420         |\n",
      "|    policy_gradient_loss          | 0.0043      |\n",
      "|    value_loss                    | 5.16e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 44          |\n",
      "|    time_elapsed                  | 4053        |\n",
      "|    total_timesteps               | 180224      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021135695 |\n",
      "|    clip_fraction                 | 0.15        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.812      |\n",
      "|    explained_variance            | 5.96e-08    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 3.37e+03    |\n",
      "|    n_updates                     | 430         |\n",
      "|    policy_gradient_loss          | 0.00135     |\n",
      "|    value_loss                    | 5.56e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1340.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 58         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 45         |\n",
      "|    time_elapsed                  | 4147       |\n",
      "|    total_timesteps               | 184320     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01421785 |\n",
      "|    clip_fraction                 | 0.105      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.809     |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 2.81e+03   |\n",
      "|    n_updates                     | 440        |\n",
      "|    policy_gradient_loss          | -0.00248   |\n",
      "|    value_loss                    | 4.87e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1140.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 50         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 46         |\n",
      "|    time_elapsed                  | 4239       |\n",
      "|    total_timesteps               | 188416     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03301181 |\n",
      "|    clip_fraction                 | 0.188      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.812     |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 1.72e+03   |\n",
      "|    n_updates                     | 450        |\n",
      "|    policy_gradient_loss          | 0.00104    |\n",
      "|    value_loss                    | 4.85e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 47          |\n",
      "|    time_elapsed                  | 4332        |\n",
      "|    total_timesteps               | 192512      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021963695 |\n",
      "|    clip_fraction                 | 0.186       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.813      |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.59e+03    |\n",
      "|    n_updates                     | 460         |\n",
      "|    policy_gradient_loss          | 0.00674     |\n",
      "|    value_loss                    | 4.79e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1000.0    |\n",
      "|    intervention_sum              | 15         |\n",
      "|    nl_comm_sum                   | 40         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 48         |\n",
      "|    time_elapsed                  | 4424       |\n",
      "|    total_timesteps               | 196608     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03859096 |\n",
      "|    clip_fraction                 | 0.171      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.828     |\n",
      "|    explained_variance            | 0          |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 2.91e+03   |\n",
      "|    n_updates                     | 470        |\n",
      "|    policy_gradient_loss          | 0.00193    |\n",
      "|    value_loss                    | 4.76e+03   |\n",
      "-------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_200000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 49          |\n",
      "|    time_elapsed                  | 4518        |\n",
      "|    total_timesteps               | 200704      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028138688 |\n",
      "|    clip_fraction                 | 0.179       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.874      |\n",
      "|    explained_variance            | 1.19e-07    |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.25e+03    |\n",
      "|    n_updates                     | 480         |\n",
      "|    policy_gradient_loss          | 0.00281     |\n",
      "|    value_loss                    | 5.06e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 50          |\n",
      "|    time_elapsed                  | 4610        |\n",
      "|    total_timesteps               | 204800      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019541021 |\n",
      "|    clip_fraction                 | 0.164       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.862      |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 2.83e+03    |\n",
      "|    n_updates                     | 490         |\n",
      "|    policy_gradient_loss          | 0.00038     |\n",
      "|    value_loss                    | 5.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 51          |\n",
      "|    time_elapsed                  | 4703        |\n",
      "|    total_timesteps               | 208896      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.046277307 |\n",
      "|    clip_fraction                 | 0.196       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.852      |\n",
      "|    explained_variance            | 0           |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.37e+03    |\n",
      "|    n_updates                     | 500         |\n",
      "|    policy_gradient_loss          | 0.00891     |\n",
      "|    value_loss                    | 4.44e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -860.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 34          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 52          |\n",
      "|    time_elapsed                  | 4796        |\n",
      "|    total_timesteps               | 212992      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009405604 |\n",
      "|    clip_fraction                 | 0.0844      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.845      |\n",
      "|    explained_variance            | 0.408       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.01e+03    |\n",
      "|    n_updates                     | 510         |\n",
      "|    policy_gradient_loss          | 0.00467     |\n",
      "|    value_loss                    | 2.58e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 53          |\n",
      "|    time_elapsed                  | 4889        |\n",
      "|    total_timesteps               | 217088      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008201569 |\n",
      "|    clip_fraction                 | 0.0701      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.847      |\n",
      "|    explained_variance            | 0.626       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.17e+03    |\n",
      "|    n_updates                     | 520         |\n",
      "|    policy_gradient_loss          | 0.00554     |\n",
      "|    value_loss                    | 2.5e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 54          |\n",
      "|    time_elapsed                  | 4981        |\n",
      "|    total_timesteps               | 221184      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008508403 |\n",
      "|    clip_fraction                 | 0.0682      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.844      |\n",
      "|    explained_variance            | 0.604       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 729         |\n",
      "|    n_updates                     | 530         |\n",
      "|    policy_gradient_loss          | 0.00359     |\n",
      "|    value_loss                    | 2.77e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 55          |\n",
      "|    time_elapsed                  | 5074        |\n",
      "|    total_timesteps               | 225280      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010354212 |\n",
      "|    clip_fraction                 | 0.0774      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.866      |\n",
      "|    explained_variance            | 0.524       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.23e+03    |\n",
      "|    n_updates                     | 540         |\n",
      "|    policy_gradient_loss          | 0.0074      |\n",
      "|    value_loss                    | 3.08e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 56          |\n",
      "|    time_elapsed                  | 5167        |\n",
      "|    total_timesteps               | 229376      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011549167 |\n",
      "|    clip_fraction                 | 0.0861      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.908      |\n",
      "|    explained_variance            | 0.607       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 715         |\n",
      "|    n_updates                     | 550         |\n",
      "|    policy_gradient_loss          | 0.0073      |\n",
      "|    value_loss                    | 2.75e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 57          |\n",
      "|    time_elapsed                  | 5260        |\n",
      "|    total_timesteps               | 233472      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009410873 |\n",
      "|    clip_fraction                 | 0.0689      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.853      |\n",
      "|    explained_variance            | 0.623       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 843         |\n",
      "|    n_updates                     | 560         |\n",
      "|    policy_gradient_loss          | 0.00428     |\n",
      "|    value_loss                    | 2.66e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 12           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 58           |\n",
      "|    time_elapsed                  | 5352         |\n",
      "|    total_timesteps               | 237568       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0086402185 |\n",
      "|    clip_fraction                 | 0.0644       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.858       |\n",
      "|    explained_variance            | 0.676        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 943          |\n",
      "|    n_updates                     | 570          |\n",
      "|    policy_gradient_loss          | 0.005        |\n",
      "|    value_loss                    | 2.57e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 59          |\n",
      "|    time_elapsed                  | 5445        |\n",
      "|    total_timesteps               | 241664      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008192599 |\n",
      "|    clip_fraction                 | 0.071       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.885      |\n",
      "|    explained_variance            | 0.721       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 689         |\n",
      "|    n_updates                     | 580         |\n",
      "|    policy_gradient_loss          | 0.00507     |\n",
      "|    value_loss                    | 2.21e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1520.0    |\n",
      "|    intervention_sum              | 23         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 60         |\n",
      "|    time_elapsed                  | 5538       |\n",
      "|    total_timesteps               | 245760     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00769485 |\n",
      "|    clip_fraction                 | 0.0647     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.883     |\n",
      "|    explained_variance            | 0.63       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 1.07e+03   |\n",
      "|    n_updates                     | 590        |\n",
      "|    policy_gradient_loss          | 0.00506    |\n",
      "|    value_loss                    | 2.38e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 61          |\n",
      "|    time_elapsed                  | 5631        |\n",
      "|    total_timesteps               | 249856      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007926775 |\n",
      "|    clip_fraction                 | 0.0611      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.869      |\n",
      "|    explained_variance            | 0.685       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 775         |\n",
      "|    n_updates                     | 600         |\n",
      "|    policy_gradient_loss          | 0.00353     |\n",
      "|    value_loss                    | 2.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 62          |\n",
      "|    time_elapsed                  | 5723        |\n",
      "|    total_timesteps               | 253952      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008417387 |\n",
      "|    clip_fraction                 | 0.0635      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.851      |\n",
      "|    explained_variance            | 0.673       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.28e+03    |\n",
      "|    n_updates                     | 610         |\n",
      "|    policy_gradient_loss          | 0.00372     |\n",
      "|    value_loss                    | 2.43e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 68           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 63           |\n",
      "|    time_elapsed                  | 5816         |\n",
      "|    total_timesteps               | 258048       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0084711015 |\n",
      "|    clip_fraction                 | 0.0538       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.838       |\n",
      "|    explained_variance            | 0.716        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 800          |\n",
      "|    n_updates                     | 620          |\n",
      "|    policy_gradient_loss          | 0.0029       |\n",
      "|    value_loss                    | 2.17e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 64          |\n",
      "|    time_elapsed                  | 5910        |\n",
      "|    total_timesteps               | 262144      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008832762 |\n",
      "|    clip_fraction                 | 0.0648      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.827      |\n",
      "|    explained_variance            | 0.702       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.03e+03    |\n",
      "|    n_updates                     | 630         |\n",
      "|    policy_gradient_loss          | 0.00414     |\n",
      "|    value_loss                    | 2.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 65          |\n",
      "|    time_elapsed                  | 6002        |\n",
      "|    total_timesteps               | 266240      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006762434 |\n",
      "|    clip_fraction                 | 0.0602      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.85       |\n",
      "|    explained_variance            | 0.745       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 788         |\n",
      "|    n_updates                     | 640         |\n",
      "|    policy_gradient_loss          | 0.004       |\n",
      "|    value_loss                    | 2.21e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 66           |\n",
      "|    time_elapsed                  | 6095         |\n",
      "|    total_timesteps               | 270336       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0053583453 |\n",
      "|    clip_fraction                 | 0.0492       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.812       |\n",
      "|    explained_variance            | 0.732        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 1.04e+03     |\n",
      "|    n_updates                     | 650          |\n",
      "|    policy_gradient_loss          | 0.00331      |\n",
      "|    value_loss                    | 1.93e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 67          |\n",
      "|    time_elapsed                  | 6187        |\n",
      "|    total_timesteps               | 274432      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008725319 |\n",
      "|    clip_fraction                 | 0.0559      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.824      |\n",
      "|    explained_variance            | 0.637       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 876         |\n",
      "|    n_updates                     | 660         |\n",
      "|    policy_gradient_loss          | 0.00421     |\n",
      "|    value_loss                    | 2.04e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 68          |\n",
      "|    time_elapsed                  | 6280        |\n",
      "|    total_timesteps               | 278528      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007820556 |\n",
      "|    clip_fraction                 | 0.0535      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.796      |\n",
      "|    explained_variance            | 0.743       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.02e+03    |\n",
      "|    n_updates                     | 670         |\n",
      "|    policy_gradient_loss          | 0.00304     |\n",
      "|    value_loss                    | 2.03e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 66           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 69           |\n",
      "|    time_elapsed                  | 6377         |\n",
      "|    total_timesteps               | 282624       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0062323175 |\n",
      "|    clip_fraction                 | 0.0547       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.813       |\n",
      "|    explained_variance            | 0.697        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 1.26e+03     |\n",
      "|    n_updates                     | 680          |\n",
      "|    policy_gradient_loss          | 0.00185      |\n",
      "|    value_loss                    | 2.06e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -900.0       |\n",
      "|    intervention_sum              | 11           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 70           |\n",
      "|    time_elapsed                  | 6472         |\n",
      "|    total_timesteps               | 286720       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0059570298 |\n",
      "|    clip_fraction                 | 0.049        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.814       |\n",
      "|    explained_variance            | 0.731        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 654          |\n",
      "|    n_updates                     | 690          |\n",
      "|    policy_gradient_loss          | 0.00187      |\n",
      "|    value_loss                    | 1.96e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 71          |\n",
      "|    time_elapsed                  | 6565        |\n",
      "|    total_timesteps               | 290816      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004518548 |\n",
      "|    clip_fraction                 | 0.0456      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.793      |\n",
      "|    explained_variance            | 0.69        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 997         |\n",
      "|    n_updates                     | 700         |\n",
      "|    policy_gradient_loss          | 0.00207     |\n",
      "|    value_loss                    | 2.12e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1480.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 60           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 72           |\n",
      "|    time_elapsed                  | 6659         |\n",
      "|    total_timesteps               | 294912       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0055626365 |\n",
      "|    clip_fraction                 | 0.0456       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.792       |\n",
      "|    explained_variance            | 0.739        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 675          |\n",
      "|    n_updates                     | 710          |\n",
      "|    policy_gradient_loss          | 0.00131      |\n",
      "|    value_loss                    | 1.95e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 73          |\n",
      "|    time_elapsed                  | 6752        |\n",
      "|    total_timesteps               | 299008      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006220414 |\n",
      "|    clip_fraction                 | 0.0472      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.8        |\n",
      "|    explained_variance            | 0.733       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 711         |\n",
      "|    n_updates                     | 720         |\n",
      "|    policy_gradient_loss          | 0.00061     |\n",
      "|    value_loss                    | 1.95e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_300000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 58           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 74           |\n",
      "|    time_elapsed                  | 6844         |\n",
      "|    total_timesteps               | 303104       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0051787673 |\n",
      "|    clip_fraction                 | 0.0411       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.78        |\n",
      "|    explained_variance            | 0.716        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 727          |\n",
      "|    n_updates                     | 730          |\n",
      "|    policy_gradient_loss          | 0.00239      |\n",
      "|    value_loss                    | 1.98e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 75           |\n",
      "|    time_elapsed                  | 6936         |\n",
      "|    total_timesteps               | 307200       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066602146 |\n",
      "|    clip_fraction                 | 0.0496       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.813       |\n",
      "|    explained_variance            | 0.759        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 1.2e+03      |\n",
      "|    n_updates                     | 740          |\n",
      "|    policy_gradient_loss          | 0.00395      |\n",
      "|    value_loss                    | 2.05e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 76           |\n",
      "|    time_elapsed                  | 7030         |\n",
      "|    total_timesteps               | 311296       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0056550894 |\n",
      "|    clip_fraction                 | 0.0437       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.792       |\n",
      "|    explained_variance            | 0.752        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 866          |\n",
      "|    n_updates                     | 750          |\n",
      "|    policy_gradient_loss          | 0.000805     |\n",
      "|    value_loss                    | 2.12e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 77          |\n",
      "|    time_elapsed                  | 7124        |\n",
      "|    total_timesteps               | 315392      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006382864 |\n",
      "|    clip_fraction                 | 0.0434      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.795      |\n",
      "|    explained_variance            | 0.78        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 743         |\n",
      "|    n_updates                     | 760         |\n",
      "|    policy_gradient_loss          | 2.76e-05    |\n",
      "|    value_loss                    | 1.95e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1480.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 72           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 78           |\n",
      "|    time_elapsed                  | 7216         |\n",
      "|    total_timesteps               | 319488       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0058423295 |\n",
      "|    clip_fraction                 | 0.0401       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.762       |\n",
      "|    explained_variance            | 0.791        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 634          |\n",
      "|    n_updates                     | 770          |\n",
      "|    policy_gradient_loss          | 0.00256      |\n",
      "|    value_loss                    | 2.25e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 79          |\n",
      "|    time_elapsed                  | 7309        |\n",
      "|    total_timesteps               | 323584      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007249243 |\n",
      "|    clip_fraction                 | 0.0517      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.806      |\n",
      "|    explained_variance            | 0.766       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 742         |\n",
      "|    n_updates                     | 780         |\n",
      "|    policy_gradient_loss          | 0.00332     |\n",
      "|    value_loss                    | 1.97e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 80          |\n",
      "|    time_elapsed                  | 7402        |\n",
      "|    total_timesteps               | 327680      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004979357 |\n",
      "|    clip_fraction                 | 0.0402      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.764      |\n",
      "|    explained_variance            | 0.799       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 978         |\n",
      "|    n_updates                     | 790         |\n",
      "|    policy_gradient_loss          | 0.00258     |\n",
      "|    value_loss                    | 1.94e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 38          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 81          |\n",
      "|    time_elapsed                  | 7496        |\n",
      "|    total_timesteps               | 331776      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006259774 |\n",
      "|    clip_fraction                 | 0.041       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.765      |\n",
      "|    explained_variance            | 0.701       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 560         |\n",
      "|    n_updates                     | 800         |\n",
      "|    policy_gradient_loss          | 0.00252     |\n",
      "|    value_loss                    | 2.35e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 60           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 82           |\n",
      "|    time_elapsed                  | 7589         |\n",
      "|    total_timesteps               | 335872       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041916254 |\n",
      "|    clip_fraction                 | 0.0353       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.742       |\n",
      "|    explained_variance            | 0.724        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 665          |\n",
      "|    n_updates                     | 810          |\n",
      "|    policy_gradient_loss          | 0.00123      |\n",
      "|    value_loss                    | 2.04e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 83           |\n",
      "|    time_elapsed                  | 7682         |\n",
      "|    total_timesteps               | 339968       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0054637915 |\n",
      "|    clip_fraction                 | 0.0385       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.772       |\n",
      "|    explained_variance            | 0.758        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 559          |\n",
      "|    n_updates                     | 820          |\n",
      "|    policy_gradient_loss          | 0.00137      |\n",
      "|    value_loss                    | 1.89e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -880.0       |\n",
      "|    intervention_sum              | 11           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 84           |\n",
      "|    time_elapsed                  | 7774         |\n",
      "|    total_timesteps               | 344064       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0069349254 |\n",
      "|    clip_fraction                 | 0.0489       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.795       |\n",
      "|    explained_variance            | 0.762        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 878          |\n",
      "|    n_updates                     | 830          |\n",
      "|    policy_gradient_loss          | 0.00124      |\n",
      "|    value_loss                    | 1.9e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -880.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 85          |\n",
      "|    time_elapsed                  | 7867        |\n",
      "|    total_timesteps               | 348160      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007124967 |\n",
      "|    clip_fraction                 | 0.0433      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.766      |\n",
      "|    explained_variance            | 0.723       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 709         |\n",
      "|    n_updates                     | 840         |\n",
      "|    policy_gradient_loss          | 0.00057     |\n",
      "|    value_loss                    | 2.12e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 86          |\n",
      "|    time_elapsed                  | 7959        |\n",
      "|    total_timesteps               | 352256      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004873976 |\n",
      "|    clip_fraction                 | 0.0408      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.765      |\n",
      "|    explained_variance            | 0.748       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 750         |\n",
      "|    n_updates                     | 850         |\n",
      "|    policy_gradient_loss          | 0.00073     |\n",
      "|    value_loss                    | 1.64e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 87          |\n",
      "|    time_elapsed                  | 8052        |\n",
      "|    total_timesteps               | 356352      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006631561 |\n",
      "|    clip_fraction                 | 0.0477      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.767      |\n",
      "|    explained_variance            | 0.731       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 465         |\n",
      "|    n_updates                     | 860         |\n",
      "|    policy_gradient_loss          | 0.00178     |\n",
      "|    value_loss                    | 1.88e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -900.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 34           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 88           |\n",
      "|    time_elapsed                  | 8145         |\n",
      "|    total_timesteps               | 360448       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0054693483 |\n",
      "|    clip_fraction                 | 0.0462       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.755       |\n",
      "|    explained_variance            | 0.76         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 442          |\n",
      "|    n_updates                     | 870          |\n",
      "|    policy_gradient_loss          | -3.25e-05    |\n",
      "|    value_loss                    | 1.54e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 89          |\n",
      "|    time_elapsed                  | 8237        |\n",
      "|    total_timesteps               | 364544      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003258693 |\n",
      "|    clip_fraction                 | 0.0288      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.745      |\n",
      "|    explained_variance            | 0.738       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 700         |\n",
      "|    n_updates                     | 880         |\n",
      "|    policy_gradient_loss          | 0.000628    |\n",
      "|    value_loss                    | 1.85e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 64           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 90           |\n",
      "|    time_elapsed                  | 8331         |\n",
      "|    total_timesteps               | 368640       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0059063556 |\n",
      "|    clip_fraction                 | 0.0472       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.764       |\n",
      "|    explained_variance            | 0.755        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 460          |\n",
      "|    n_updates                     | 890          |\n",
      "|    policy_gradient_loss          | 0.00193      |\n",
      "|    value_loss                    | 1.66e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 91          |\n",
      "|    time_elapsed                  | 8423        |\n",
      "|    total_timesteps               | 372736      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004694857 |\n",
      "|    clip_fraction                 | 0.0391      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.768      |\n",
      "|    explained_variance            | 0.782       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.32e+03    |\n",
      "|    n_updates                     | 900         |\n",
      "|    policy_gradient_loss          | 0.0018      |\n",
      "|    value_loss                    | 1.99e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1500.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 62           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 92           |\n",
      "|    time_elapsed                  | 8516         |\n",
      "|    total_timesteps               | 376832       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0051188194 |\n",
      "|    clip_fraction                 | 0.0383       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.751       |\n",
      "|    explained_variance            | 0.759        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 1.09e+03     |\n",
      "|    n_updates                     | 910          |\n",
      "|    policy_gradient_loss          | 0.000365     |\n",
      "|    value_loss                    | 2e+03        |\n",
      "---------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1400.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 56         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 93         |\n",
      "|    time_elapsed                  | 8608       |\n",
      "|    total_timesteps               | 380928     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00564292 |\n",
      "|    clip_fraction                 | 0.0382     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.75      |\n",
      "|    explained_variance            | 0.733      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 664        |\n",
      "|    n_updates                     | 920        |\n",
      "|    policy_gradient_loss          | 0.00148    |\n",
      "|    value_loss                    | 2.37e+03   |\n",
      "-------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1400.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 94           |\n",
      "|    time_elapsed                  | 8701         |\n",
      "|    total_timesteps               | 385024       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0039521675 |\n",
      "|    clip_fraction                 | 0.0343       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.742       |\n",
      "|    explained_variance            | 0.762        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 671          |\n",
      "|    n_updates                     | 930          |\n",
      "|    policy_gradient_loss          | 0.00102      |\n",
      "|    value_loss                    | 2.04e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 95           |\n",
      "|    time_elapsed                  | 8794         |\n",
      "|    total_timesteps               | 389120       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0050047836 |\n",
      "|    clip_fraction                 | 0.0389       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.743       |\n",
      "|    explained_variance            | 0.78         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 755          |\n",
      "|    n_updates                     | 940          |\n",
      "|    policy_gradient_loss          | 0.00127      |\n",
      "|    value_loss                    | 1.86e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1340.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 96           |\n",
      "|    time_elapsed                  | 8886         |\n",
      "|    total_timesteps               | 393216       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036148864 |\n",
      "|    clip_fraction                 | 0.0287       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.72        |\n",
      "|    explained_variance            | 0.787        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 495          |\n",
      "|    n_updates                     | 950          |\n",
      "|    policy_gradient_loss          | 0.00108      |\n",
      "|    value_loss                    | 1.85e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 38          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 97          |\n",
      "|    time_elapsed                  | 8979        |\n",
      "|    total_timesteps               | 397312      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005106747 |\n",
      "|    clip_fraction                 | 0.0392      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.734      |\n",
      "|    explained_variance            | 0.755       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 694         |\n",
      "|    n_updates                     | 960         |\n",
      "|    policy_gradient_loss          | 0.00213     |\n",
      "|    value_loss                    | 1.88e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_400000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 98           |\n",
      "|    time_elapsed                  | 9072         |\n",
      "|    total_timesteps               | 401408       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0047981837 |\n",
      "|    clip_fraction                 | 0.0341       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.727       |\n",
      "|    explained_variance            | 0.766        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 597          |\n",
      "|    n_updates                     | 970          |\n",
      "|    policy_gradient_loss          | 0.000323     |\n",
      "|    value_loss                    | 1.74e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 99          |\n",
      "|    time_elapsed                  | 9164        |\n",
      "|    total_timesteps               | 405504      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004028172 |\n",
      "|    clip_fraction                 | 0.0357      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.736      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 581         |\n",
      "|    n_updates                     | 980         |\n",
      "|    policy_gradient_loss          | 0.000993    |\n",
      "|    value_loss                    | 1.76e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 100         |\n",
      "|    time_elapsed                  | 9256        |\n",
      "|    total_timesteps               | 409600      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005311066 |\n",
      "|    clip_fraction                 | 0.038       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.739      |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 690         |\n",
      "|    n_updates                     | 990         |\n",
      "|    policy_gradient_loss          | -0.00013    |\n",
      "|    value_loss                    | 1.56e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -980.0      |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 101         |\n",
      "|    time_elapsed                  | 9349        |\n",
      "|    total_timesteps               | 413696      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004579018 |\n",
      "|    clip_fraction                 | 0.0326      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.73       |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 475         |\n",
      "|    n_updates                     | 1000        |\n",
      "|    policy_gradient_loss          | 0.00163     |\n",
      "|    value_loss                    | 1.53e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 102          |\n",
      "|    time_elapsed                  | 9442         |\n",
      "|    total_timesteps               | 417792       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0050445343 |\n",
      "|    clip_fraction                 | 0.0408       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.717       |\n",
      "|    explained_variance            | 0.769        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 545          |\n",
      "|    n_updates                     | 1010         |\n",
      "|    policy_gradient_loss          | 0.00219      |\n",
      "|    value_loss                    | 1.74e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 103          |\n",
      "|    time_elapsed                  | 9534         |\n",
      "|    total_timesteps               | 421888       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0047579394 |\n",
      "|    clip_fraction                 | 0.0384       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.726       |\n",
      "|    explained_variance            | 0.788        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 488          |\n",
      "|    n_updates                     | 1020         |\n",
      "|    policy_gradient_loss          | 0.00102      |\n",
      "|    value_loss                    | 1.58e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 104          |\n",
      "|    time_elapsed                  | 9627         |\n",
      "|    total_timesteps               | 425984       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0045735408 |\n",
      "|    clip_fraction                 | 0.0367       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.689       |\n",
      "|    explained_variance            | 0.795        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 716          |\n",
      "|    n_updates                     | 1030         |\n",
      "|    policy_gradient_loss          | -6.63e-05    |\n",
      "|    value_loss                    | 1.67e+03     |\n",
      "---------------------------------------------------\n",
      "-----------------------------------------------\n",
      "| episode/                         |          |\n",
      "|    direct_capacity_violation_sum | 0        |\n",
      "|    final_reward                  | -1000.0  |\n",
      "|    intervention_sum              | 12       |\n",
      "|    nl_comm_sum                   | 52       |\n",
      "| time/                            |          |\n",
      "|    fps                           | 44       |\n",
      "|    iterations                    | 105      |\n",
      "|    time_elapsed                  | 9720     |\n",
      "|    total_timesteps               | 430080   |\n",
      "| total/                           |          |\n",
      "|    truncated                     | 0        |\n",
      "| train/                           |          |\n",
      "|    approx_kl                     | 0.005013 |\n",
      "|    clip_fraction                 | 0.0399   |\n",
      "|    clip_range                    | 0.2      |\n",
      "|    entropy_loss                  | -0.703   |\n",
      "|    explained_variance            | 0.777    |\n",
      "|    learning_rate                 | 0.0005   |\n",
      "|    loss                          | 447      |\n",
      "|    n_updates                     | 1040     |\n",
      "|    policy_gradient_loss          | 0.00233  |\n",
      "|    value_loss                    | 1.75e+03 |\n",
      "-----------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1060.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 106          |\n",
      "|    time_elapsed                  | 9812         |\n",
      "|    total_timesteps               | 434176       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0057404432 |\n",
      "|    clip_fraction                 | 0.0335       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.703       |\n",
      "|    explained_variance            | 0.773        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 776          |\n",
      "|    n_updates                     | 1050         |\n",
      "|    policy_gradient_loss          | -0.00107     |\n",
      "|    value_loss                    | 1.5e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 107          |\n",
      "|    time_elapsed                  | 9904         |\n",
      "|    total_timesteps               | 438272       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0047343457 |\n",
      "|    clip_fraction                 | 0.0465       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.699       |\n",
      "|    explained_variance            | 0.777        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 733          |\n",
      "|    n_updates                     | 1060         |\n",
      "|    policy_gradient_loss          | 0.00185      |\n",
      "|    value_loss                    | 1.44e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 108         |\n",
      "|    time_elapsed                  | 9997        |\n",
      "|    total_timesteps               | 442368      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003537504 |\n",
      "|    clip_fraction                 | 0.0301      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.695      |\n",
      "|    explained_variance            | 0.799       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 539         |\n",
      "|    n_updates                     | 1070        |\n",
      "|    policy_gradient_loss          | 0.000278    |\n",
      "|    value_loss                    | 1.67e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 109          |\n",
      "|    time_elapsed                  | 10090        |\n",
      "|    total_timesteps               | 446464       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036532865 |\n",
      "|    clip_fraction                 | 0.0315       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.701       |\n",
      "|    explained_variance            | 0.818        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 655          |\n",
      "|    n_updates                     | 1080         |\n",
      "|    policy_gradient_loss          | 0.000881     |\n",
      "|    value_loss                    | 1.52e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1000.0      |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 110          |\n",
      "|    time_elapsed                  | 10183        |\n",
      "|    total_timesteps               | 450560       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0037586023 |\n",
      "|    clip_fraction                 | 0.0342       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.689       |\n",
      "|    explained_variance            | 0.771        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 642          |\n",
      "|    n_updates                     | 1090         |\n",
      "|    policy_gradient_loss          | 0.000299     |\n",
      "|    value_loss                    | 1.53e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 111         |\n",
      "|    time_elapsed                  | 10275       |\n",
      "|    total_timesteps               | 454656      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004683368 |\n",
      "|    clip_fraction                 | 0.0329      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.683      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 360         |\n",
      "|    n_updates                     | 1100        |\n",
      "|    policy_gradient_loss          | 0.00102     |\n",
      "|    value_loss                    | 1.49e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -920.0      |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 36          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 112         |\n",
      "|    time_elapsed                  | 10368       |\n",
      "|    total_timesteps               | 458752      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005368042 |\n",
      "|    clip_fraction                 | 0.0424      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.673      |\n",
      "|    explained_variance            | 0.758       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 420         |\n",
      "|    n_updates                     | 1110        |\n",
      "|    policy_gradient_loss          | 0.000338    |\n",
      "|    value_loss                    | 1.72e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1000.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 32           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 113          |\n",
      "|    time_elapsed                  | 10461        |\n",
      "|    total_timesteps               | 462848       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041683204 |\n",
      "|    clip_fraction                 | 0.033        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.669       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 505          |\n",
      "|    n_updates                     | 1120         |\n",
      "|    policy_gradient_loss          | 0.000233     |\n",
      "|    value_loss                    | 1.44e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 114         |\n",
      "|    time_elapsed                  | 10554       |\n",
      "|    total_timesteps               | 466944      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004286463 |\n",
      "|    clip_fraction                 | 0.0311      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.673      |\n",
      "|    explained_variance            | 0.832       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 562         |\n",
      "|    n_updates                     | 1130        |\n",
      "|    policy_gradient_loss          | 0.000372    |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -920.0       |\n",
      "|    intervention_sum              | 11           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 115          |\n",
      "|    time_elapsed                  | 10647        |\n",
      "|    total_timesteps               | 471040       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0055829673 |\n",
      "|    clip_fraction                 | 0.0455       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.665       |\n",
      "|    explained_variance            | 0.793        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 408          |\n",
      "|    n_updates                     | 1140         |\n",
      "|    policy_gradient_loss          | 0.000815     |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 116         |\n",
      "|    time_elapsed                  | 10739       |\n",
      "|    total_timesteps               | 475136      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005750825 |\n",
      "|    clip_fraction                 | 0.0376      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.651      |\n",
      "|    explained_variance            | 0.729       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 725         |\n",
      "|    n_updates                     | 1150        |\n",
      "|    policy_gradient_loss          | 0.00176     |\n",
      "|    value_loss                    | 1.62e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 117         |\n",
      "|    time_elapsed                  | 10833       |\n",
      "|    total_timesteps               | 479232      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005001256 |\n",
      "|    clip_fraction                 | 0.0417      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.657      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 324         |\n",
      "|    n_updates                     | 1160        |\n",
      "|    policy_gradient_loss          | 0.000419    |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 118         |\n",
      "|    time_elapsed                  | 10926       |\n",
      "|    total_timesteps               | 483328      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004564211 |\n",
      "|    clip_fraction                 | 0.0368      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.67       |\n",
      "|    explained_variance            | 0.745       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 334         |\n",
      "|    n_updates                     | 1170        |\n",
      "|    policy_gradient_loss          | 0.00054     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 119          |\n",
      "|    time_elapsed                  | 11019        |\n",
      "|    total_timesteps               | 487424       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0040581035 |\n",
      "|    clip_fraction                 | 0.0277       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.657       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 479          |\n",
      "|    n_updates                     | 1180         |\n",
      "|    policy_gradient_loss          | 0.000965     |\n",
      "|    value_loss                    | 1.23e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1260.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 120          |\n",
      "|    time_elapsed                  | 11110        |\n",
      "|    total_timesteps               | 491520       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0050629033 |\n",
      "|    clip_fraction                 | 0.0345       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.665       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 744          |\n",
      "|    n_updates                     | 1190         |\n",
      "|    policy_gradient_loss          | 0.000703     |\n",
      "|    value_loss                    | 1.23e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 121          |\n",
      "|    time_elapsed                  | 11203        |\n",
      "|    total_timesteps               | 495616       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0038359128 |\n",
      "|    clip_fraction                 | 0.03         |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.652       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 431          |\n",
      "|    n_updates                     | 1200         |\n",
      "|    policy_gradient_loss          | 0.000366     |\n",
      "|    value_loss                    | 1.39e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 122         |\n",
      "|    time_elapsed                  | 11297       |\n",
      "|    total_timesteps               | 499712      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004834948 |\n",
      "|    clip_fraction                 | 0.0424      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.653      |\n",
      "|    explained_variance            | 0.812       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 420         |\n",
      "|    n_updates                     | 1210        |\n",
      "|    policy_gradient_loss          | 4.75e-05    |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_500000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 123         |\n",
      "|    time_elapsed                  | 11389       |\n",
      "|    total_timesteps               | 503808      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004386324 |\n",
      "|    clip_fraction                 | 0.0404      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.652      |\n",
      "|    explained_variance            | 0.823       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 304         |\n",
      "|    n_updates                     | 1220        |\n",
      "|    policy_gradient_loss          | -2.78e-06   |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 124          |\n",
      "|    time_elapsed                  | 11481        |\n",
      "|    total_timesteps               | 507904       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0043067206 |\n",
      "|    clip_fraction                 | 0.0306       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.64        |\n",
      "|    explained_variance            | 0.816        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 553          |\n",
      "|    n_updates                     | 1230         |\n",
      "|    policy_gradient_loss          | 0.000987     |\n",
      "|    value_loss                    | 1.43e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -880.0      |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 32          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 125         |\n",
      "|    time_elapsed                  | 11575       |\n",
      "|    total_timesteps               | 512000      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003442062 |\n",
      "|    clip_fraction                 | 0.0275      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.642      |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 757         |\n",
      "|    n_updates                     | 1240        |\n",
      "|    policy_gradient_loss          | 0.000714    |\n",
      "|    value_loss                    | 1.52e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 126         |\n",
      "|    time_elapsed                  | 11667       |\n",
      "|    total_timesteps               | 516096      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004984157 |\n",
      "|    clip_fraction                 | 0.0444      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.638      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.48e+03    |\n",
      "|    n_updates                     | 1250        |\n",
      "|    policy_gradient_loss          | 0.00138     |\n",
      "|    value_loss                    | 1.61e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1160.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 127        |\n",
      "|    time_elapsed                  | 11760      |\n",
      "|    total_timesteps               | 520192     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00380438 |\n",
      "|    clip_fraction                 | 0.03       |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.643     |\n",
      "|    explained_variance            | 0.758      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 491        |\n",
      "|    n_updates                     | 1260       |\n",
      "|    policy_gradient_loss          | -0.000836  |\n",
      "|    value_loss                    | 1.5e+03    |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -920.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 128         |\n",
      "|    time_elapsed                  | 11852       |\n",
      "|    total_timesteps               | 524288      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005153707 |\n",
      "|    clip_fraction                 | 0.0417      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.645      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 428         |\n",
      "|    n_updates                     | 1270        |\n",
      "|    policy_gradient_loss          | 2.24e-05    |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -840.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 32           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 129          |\n",
      "|    time_elapsed                  | 11946        |\n",
      "|    total_timesteps               | 528384       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0046046996 |\n",
      "|    clip_fraction                 | 0.0474       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.628       |\n",
      "|    explained_variance            | 0.774        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 734          |\n",
      "|    n_updates                     | 1280         |\n",
      "|    policy_gradient_loss          | 0.000362     |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -640.0      |\n",
      "|    intervention_sum              | 10          |\n",
      "|    nl_comm_sum                   | 24          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 130         |\n",
      "|    time_elapsed                  | 12039       |\n",
      "|    total_timesteps               | 532480      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004629854 |\n",
      "|    clip_fraction                 | 0.0442      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.637      |\n",
      "|    explained_variance            | 0.797       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 327         |\n",
      "|    n_updates                     | 1290        |\n",
      "|    policy_gradient_loss          | -0.000681   |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1040.0    |\n",
      "|    intervention_sum              | 15         |\n",
      "|    nl_comm_sum                   | 44         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 131        |\n",
      "|    time_elapsed                  | 12131      |\n",
      "|    total_timesteps               | 536576     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00403968 |\n",
      "|    clip_fraction                 | 0.0299     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.639     |\n",
      "|    explained_variance            | 0.768      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 822        |\n",
      "|    n_updates                     | 1300       |\n",
      "|    policy_gradient_loss          | 0.00132    |\n",
      "|    value_loss                    | 1.34e+03   |\n",
      "-------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 132          |\n",
      "|    time_elapsed                  | 12224        |\n",
      "|    total_timesteps               | 540672       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049577937 |\n",
      "|    clip_fraction                 | 0.0343       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.623       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 387          |\n",
      "|    n_updates                     | 1310         |\n",
      "|    policy_gradient_loss          | 0.000113     |\n",
      "|    value_loss                    | 1.11e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 133         |\n",
      "|    time_elapsed                  | 12318       |\n",
      "|    total_timesteps               | 544768      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002831658 |\n",
      "|    clip_fraction                 | 0.0264      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.625      |\n",
      "|    explained_variance            | 0.819       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 585         |\n",
      "|    n_updates                     | 1320        |\n",
      "|    policy_gradient_loss          | 0.00103     |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 134         |\n",
      "|    time_elapsed                  | 12410       |\n",
      "|    total_timesteps               | 548864      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004219873 |\n",
      "|    clip_fraction                 | 0.0373      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.627      |\n",
      "|    explained_variance            | 0.809       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 452         |\n",
      "|    n_updates                     | 1330        |\n",
      "|    policy_gradient_loss          | -7.05e-06   |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 135          |\n",
      "|    time_elapsed                  | 12502        |\n",
      "|    total_timesteps               | 552960       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0039639943 |\n",
      "|    clip_fraction                 | 0.0368       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.624       |\n",
      "|    explained_variance            | 0.825        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 303          |\n",
      "|    n_updates                     | 1340         |\n",
      "|    policy_gradient_loss          | 0.000392     |\n",
      "|    value_loss                    | 1.08e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 136         |\n",
      "|    time_elapsed                  | 12595       |\n",
      "|    total_timesteps               | 557056      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002655975 |\n",
      "|    clip_fraction                 | 0.0299      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.619      |\n",
      "|    explained_variance            | 0.756       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 653         |\n",
      "|    n_updates                     | 1350        |\n",
      "|    policy_gradient_loss          | 0.000741    |\n",
      "|    value_loss                    | 1.51e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 137         |\n",
      "|    time_elapsed                  | 12688       |\n",
      "|    total_timesteps               | 561152      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006529333 |\n",
      "|    clip_fraction                 | 0.0462      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.615      |\n",
      "|    explained_variance            | 0.795       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 481         |\n",
      "|    n_updates                     | 1360        |\n",
      "|    policy_gradient_loss          | -0.000263   |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 138          |\n",
      "|    time_elapsed                  | 12780        |\n",
      "|    total_timesteps               | 565248       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0043717166 |\n",
      "|    clip_fraction                 | 0.0425       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.598       |\n",
      "|    explained_variance            | 0.787        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 538          |\n",
      "|    n_updates                     | 1370         |\n",
      "|    policy_gradient_loss          | 0.00011      |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 139          |\n",
      "|    time_elapsed                  | 12873        |\n",
      "|    total_timesteps               | 569344       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0059924414 |\n",
      "|    clip_fraction                 | 0.0459       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.604       |\n",
      "|    explained_variance            | 0.834        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 325          |\n",
      "|    n_updates                     | 1380         |\n",
      "|    policy_gradient_loss          | 0.00171      |\n",
      "|    value_loss                    | 1.19e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 140         |\n",
      "|    time_elapsed                  | 12966       |\n",
      "|    total_timesteps               | 573440      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005061402 |\n",
      "|    clip_fraction                 | 0.0421      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.602      |\n",
      "|    explained_variance            | 0.813       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 326         |\n",
      "|    n_updates                     | 1390        |\n",
      "|    policy_gradient_loss          | -0.000526   |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 141          |\n",
      "|    time_elapsed                  | 13059        |\n",
      "|    total_timesteps               | 577536       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0054530865 |\n",
      "|    clip_fraction                 | 0.0516       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.586       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 607          |\n",
      "|    n_updates                     | 1400         |\n",
      "|    policy_gradient_loss          | 0.000671     |\n",
      "|    value_loss                    | 1.38e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 142          |\n",
      "|    time_elapsed                  | 13152        |\n",
      "|    total_timesteps               | 581632       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041813045 |\n",
      "|    clip_fraction                 | 0.0347       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.591       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 443          |\n",
      "|    n_updates                     | 1410         |\n",
      "|    policy_gradient_loss          | -0.000156    |\n",
      "|    value_loss                    | 1.45e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -860.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 34          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 143         |\n",
      "|    time_elapsed                  | 13245       |\n",
      "|    total_timesteps               | 585728      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003162257 |\n",
      "|    clip_fraction                 | 0.0297      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.598      |\n",
      "|    explained_variance            | 0.854       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 584         |\n",
      "|    n_updates                     | 1420        |\n",
      "|    policy_gradient_loss          | 0.000365    |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 144          |\n",
      "|    time_elapsed                  | 13338        |\n",
      "|    total_timesteps               | 589824       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041881055 |\n",
      "|    clip_fraction                 | 0.0293       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.588       |\n",
      "|    explained_variance            | 0.789        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 395          |\n",
      "|    n_updates                     | 1430         |\n",
      "|    policy_gradient_loss          | -0.000331    |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -940.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 145          |\n",
      "|    time_elapsed                  | 13431        |\n",
      "|    total_timesteps               | 593920       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049421387 |\n",
      "|    clip_fraction                 | 0.0394       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.588       |\n",
      "|    explained_variance            | 0.834        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 459          |\n",
      "|    n_updates                     | 1440         |\n",
      "|    policy_gradient_loss          | 0.000793     |\n",
      "|    value_loss                    | 1.07e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -900.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 146          |\n",
      "|    time_elapsed                  | 13523        |\n",
      "|    total_timesteps               | 598016       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048764646 |\n",
      "|    clip_fraction                 | 0.0505       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.58        |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 375          |\n",
      "|    n_updates                     | 1450         |\n",
      "|    policy_gradient_loss          | 0.00133      |\n",
      "|    value_loss                    | 1.38e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_600000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 147          |\n",
      "|    time_elapsed                  | 13615        |\n",
      "|    total_timesteps               | 602112       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0043055257 |\n",
      "|    clip_fraction                 | 0.04         |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.583       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 371          |\n",
      "|    n_updates                     | 1460         |\n",
      "|    policy_gradient_loss          | 0.00145      |\n",
      "|    value_loss                    | 1.32e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 148         |\n",
      "|    time_elapsed                  | 13708       |\n",
      "|    total_timesteps               | 606208      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004277306 |\n",
      "|    clip_fraction                 | 0.0369      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.577      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 401         |\n",
      "|    n_updates                     | 1470        |\n",
      "|    policy_gradient_loss          | 0.000581    |\n",
      "|    value_loss                    | 1.14e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 149          |\n",
      "|    time_elapsed                  | 13801        |\n",
      "|    total_timesteps               | 610304       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0060020424 |\n",
      "|    clip_fraction                 | 0.0434       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.578       |\n",
      "|    explained_variance            | 0.796        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 450          |\n",
      "|    n_updates                     | 1480         |\n",
      "|    policy_gradient_loss          | -0.000404    |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -960.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 150          |\n",
      "|    time_elapsed                  | 13894        |\n",
      "|    total_timesteps               | 614400       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0046311165 |\n",
      "|    clip_fraction                 | 0.0381       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.554       |\n",
      "|    explained_variance            | 0.811        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 572          |\n",
      "|    n_updates                     | 1490         |\n",
      "|    policy_gradient_loss          | 0.00134      |\n",
      "|    value_loss                    | 1.34e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 151         |\n",
      "|    time_elapsed                  | 13986       |\n",
      "|    total_timesteps               | 618496      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004581772 |\n",
      "|    clip_fraction                 | 0.0407      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.548      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 465         |\n",
      "|    n_updates                     | 1500        |\n",
      "|    policy_gradient_loss          | 0.00118     |\n",
      "|    value_loss                    | 1.21e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 152          |\n",
      "|    time_elapsed                  | 14079        |\n",
      "|    total_timesteps               | 622592       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0028194694 |\n",
      "|    clip_fraction                 | 0.0269       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.537       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 508          |\n",
      "|    n_updates                     | 1510         |\n",
      "|    policy_gradient_loss          | -0.000233    |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 153          |\n",
      "|    time_elapsed                  | 14173        |\n",
      "|    total_timesteps               | 626688       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049987966 |\n",
      "|    clip_fraction                 | 0.049        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.536       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 432          |\n",
      "|    n_updates                     | 1520         |\n",
      "|    policy_gradient_loss          | 0.000179     |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 154         |\n",
      "|    time_elapsed                  | 14266       |\n",
      "|    total_timesteps               | 630784      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003598224 |\n",
      "|    clip_fraction                 | 0.0344      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.529      |\n",
      "|    explained_variance            | 0.754       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 522         |\n",
      "|    n_updates                     | 1530        |\n",
      "|    policy_gradient_loss          | 0.000845    |\n",
      "|    value_loss                    | 1.55e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 155          |\n",
      "|    time_elapsed                  | 14358        |\n",
      "|    total_timesteps               | 634880       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0031655165 |\n",
      "|    clip_fraction                 | 0.0322       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.542       |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 368          |\n",
      "|    n_updates                     | 1540         |\n",
      "|    policy_gradient_loss          | 0.00115      |\n",
      "|    value_loss                    | 1.06e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 156          |\n",
      "|    time_elapsed                  | 14450        |\n",
      "|    total_timesteps               | 638976       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0038447774 |\n",
      "|    clip_fraction                 | 0.0288       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.525       |\n",
      "|    explained_variance            | 0.798        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 418          |\n",
      "|    n_updates                     | 1550         |\n",
      "|    policy_gradient_loss          | -0.000177    |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 157          |\n",
      "|    time_elapsed                  | 14544        |\n",
      "|    total_timesteps               | 643072       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0039390954 |\n",
      "|    clip_fraction                 | 0.0313       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.515       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 313          |\n",
      "|    n_updates                     | 1560         |\n",
      "|    policy_gradient_loss          | -6.26e-05    |\n",
      "|    value_loss                    | 1.12e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 158          |\n",
      "|    time_elapsed                  | 14637        |\n",
      "|    total_timesteps               | 647168       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036554877 |\n",
      "|    clip_fraction                 | 0.0275       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.509       |\n",
      "|    explained_variance            | 0.805        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 809          |\n",
      "|    n_updates                     | 1570         |\n",
      "|    policy_gradient_loss          | 0.000968     |\n",
      "|    value_loss                    | 1.38e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 159          |\n",
      "|    time_elapsed                  | 14729        |\n",
      "|    total_timesteps               | 651264       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049042157 |\n",
      "|    clip_fraction                 | 0.0333       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.507       |\n",
      "|    explained_variance            | 0.775        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 286          |\n",
      "|    n_updates                     | 1580         |\n",
      "|    policy_gradient_loss          | 0.000206     |\n",
      "|    value_loss                    | 1.22e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 160         |\n",
      "|    time_elapsed                  | 14821       |\n",
      "|    total_timesteps               | 655360      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003038289 |\n",
      "|    clip_fraction                 | 0.0273      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.494      |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 468         |\n",
      "|    n_updates                     | 1590        |\n",
      "|    policy_gradient_loss          | 0.00118     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -780.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 30          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 161         |\n",
      "|    time_elapsed                  | 14914       |\n",
      "|    total_timesteps               | 659456      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004945714 |\n",
      "|    clip_fraction                 | 0.0319      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.494      |\n",
      "|    explained_variance            | 0.789       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 246         |\n",
      "|    n_updates                     | 1600        |\n",
      "|    policy_gradient_loss          | -0.000328   |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 162          |\n",
      "|    time_elapsed                  | 15007        |\n",
      "|    total_timesteps               | 663552       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049877604 |\n",
      "|    clip_fraction                 | 0.0353       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.474       |\n",
      "|    explained_variance            | 0.816        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 318          |\n",
      "|    n_updates                     | 1610         |\n",
      "|    policy_gradient_loss          | -0.00106     |\n",
      "|    value_loss                    | 1.32e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 163          |\n",
      "|    time_elapsed                  | 15100        |\n",
      "|    total_timesteps               | 667648       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0033025164 |\n",
      "|    clip_fraction                 | 0.0319       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.47        |\n",
      "|    explained_variance            | 0.833        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 390          |\n",
      "|    n_updates                     | 1620         |\n",
      "|    policy_gradient_loss          | 0.000374     |\n",
      "|    value_loss                    | 1.26e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 164          |\n",
      "|    time_elapsed                  | 15192        |\n",
      "|    total_timesteps               | 671744       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0043391995 |\n",
      "|    clip_fraction                 | 0.0331       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.474       |\n",
      "|    explained_variance            | 0.797        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 302          |\n",
      "|    n_updates                     | 1630         |\n",
      "|    policy_gradient_loss          | -0.000868    |\n",
      "|    value_loss                    | 1.38e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 165          |\n",
      "|    time_elapsed                  | 15285        |\n",
      "|    total_timesteps               | 675840       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0045882533 |\n",
      "|    clip_fraction                 | 0.0458       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.465       |\n",
      "|    explained_variance            | 0.817        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 517          |\n",
      "|    n_updates                     | 1640         |\n",
      "|    policy_gradient_loss          | 8.74e-05     |\n",
      "|    value_loss                    | 1.14e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 166         |\n",
      "|    time_elapsed                  | 15379       |\n",
      "|    total_timesteps               | 679936      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005371251 |\n",
      "|    clip_fraction                 | 0.0396      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.467      |\n",
      "|    explained_variance            | 0.796       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 354         |\n",
      "|    n_updates                     | 1650        |\n",
      "|    policy_gradient_loss          | 0.00182     |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -820.0     |\n",
      "|    intervention_sum              | 12         |\n",
      "|    nl_comm_sum                   | 34         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 167        |\n",
      "|    time_elapsed                  | 15472      |\n",
      "|    total_timesteps               | 684032     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00268634 |\n",
      "|    clip_fraction                 | 0.022      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.456     |\n",
      "|    explained_variance            | 0.821      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 463        |\n",
      "|    n_updates                     | 1660       |\n",
      "|    policy_gradient_loss          | 0.0011     |\n",
      "|    value_loss                    | 1.27e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 168         |\n",
      "|    time_elapsed                  | 15564       |\n",
      "|    total_timesteps               | 688128      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005066476 |\n",
      "|    clip_fraction                 | 0.034       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.463      |\n",
      "|    explained_variance            | 0.798       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 488         |\n",
      "|    n_updates                     | 1670        |\n",
      "|    policy_gradient_loss          | 0.000328    |\n",
      "|    value_loss                    | 1.44e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -780.0      |\n",
      "|    intervention_sum              | 11          |\n",
      "|    nl_comm_sum                   | 34          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 169         |\n",
      "|    time_elapsed                  | 15656       |\n",
      "|    total_timesteps               | 692224      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003304611 |\n",
      "|    clip_fraction                 | 0.0263      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.465      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 380         |\n",
      "|    n_updates                     | 1680        |\n",
      "|    policy_gradient_loss          | 0.000129    |\n",
      "|    value_loss                    | 1.05e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 170          |\n",
      "|    time_elapsed                  | 15749        |\n",
      "|    total_timesteps               | 696320       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0022473647 |\n",
      "|    clip_fraction                 | 0.0302       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.457       |\n",
      "|    explained_variance            | 0.783        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 518          |\n",
      "|    n_updates                     | 1690         |\n",
      "|    policy_gradient_loss          | 0.00202      |\n",
      "|    value_loss                    | 1.57e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_700000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1000.0      |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 171          |\n",
      "|    time_elapsed                  | 15842        |\n",
      "|    total_timesteps               | 700416       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0060094884 |\n",
      "|    clip_fraction                 | 0.0424       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.464       |\n",
      "|    explained_variance            | 0.781        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 506          |\n",
      "|    n_updates                     | 1700         |\n",
      "|    policy_gradient_loss          | 0.0018       |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 172         |\n",
      "|    time_elapsed                  | 15934       |\n",
      "|    total_timesteps               | 704512      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004145042 |\n",
      "|    clip_fraction                 | 0.0382      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.458      |\n",
      "|    explained_variance            | 0.771       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 270         |\n",
      "|    n_updates                     | 1710        |\n",
      "|    policy_gradient_loss          | 0.000902    |\n",
      "|    value_loss                    | 1.42e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -880.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 32           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 173          |\n",
      "|    time_elapsed                  | 16027        |\n",
      "|    total_timesteps               | 708608       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048945565 |\n",
      "|    clip_fraction                 | 0.0379       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.451       |\n",
      "|    explained_variance            | 0.819        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 366          |\n",
      "|    n_updates                     | 1720         |\n",
      "|    policy_gradient_loss          | 0.00173      |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 174          |\n",
      "|    time_elapsed                  | 16119        |\n",
      "|    total_timesteps               | 712704       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0030378392 |\n",
      "|    clip_fraction                 | 0.025        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.451       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 277          |\n",
      "|    n_updates                     | 1730         |\n",
      "|    policy_gradient_loss          | 0.000407     |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 175          |\n",
      "|    time_elapsed                  | 16212        |\n",
      "|    total_timesteps               | 716800       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034394874 |\n",
      "|    clip_fraction                 | 0.0328       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.456       |\n",
      "|    explained_variance            | 0.787        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 402          |\n",
      "|    n_updates                     | 1740         |\n",
      "|    policy_gradient_loss          | 0.000586     |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 176          |\n",
      "|    time_elapsed                  | 16305        |\n",
      "|    total_timesteps               | 720896       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0030192204 |\n",
      "|    clip_fraction                 | 0.0331       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.452       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 320          |\n",
      "|    n_updates                     | 1750         |\n",
      "|    policy_gradient_loss          | -0.000126    |\n",
      "|    value_loss                    | 1.13e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 177         |\n",
      "|    time_elapsed                  | 16397       |\n",
      "|    total_timesteps               | 724992      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005523414 |\n",
      "|    clip_fraction                 | 0.0408      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.806       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 271         |\n",
      "|    n_updates                     | 1760        |\n",
      "|    policy_gradient_loss          | -0.000846   |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -660.0      |\n",
      "|    intervention_sum              | 9           |\n",
      "|    nl_comm_sum                   | 30          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 178         |\n",
      "|    time_elapsed                  | 16490       |\n",
      "|    total_timesteps               | 729088      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004676977 |\n",
      "|    clip_fraction                 | 0.0342      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.445      |\n",
      "|    explained_variance            | 0.817       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 397         |\n",
      "|    n_updates                     | 1770        |\n",
      "|    policy_gradient_loss          | 0.0016      |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1060.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 179         |\n",
      "|    time_elapsed                  | 16583       |\n",
      "|    total_timesteps               | 733184      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002814751 |\n",
      "|    clip_fraction                 | 0.0255      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.453      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 426         |\n",
      "|    n_updates                     | 1780        |\n",
      "|    policy_gradient_loss          | -0.000418   |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1220.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 46         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 180        |\n",
      "|    time_elapsed                  | 16676      |\n",
      "|    total_timesteps               | 737280     |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00466565 |\n",
      "|    clip_fraction                 | 0.0425     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.453     |\n",
      "|    explained_variance            | 0.8        |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 373        |\n",
      "|    n_updates                     | 1790       |\n",
      "|    policy_gradient_loss          | -0.000149  |\n",
      "|    value_loss                    | 1.24e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -940.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 181         |\n",
      "|    time_elapsed                  | 16769       |\n",
      "|    total_timesteps               | 741376      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005126872 |\n",
      "|    clip_fraction                 | 0.0421      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.467      |\n",
      "|    explained_variance            | 0.842       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 381         |\n",
      "|    n_updates                     | 1800        |\n",
      "|    policy_gradient_loss          | 0.00224     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 182          |\n",
      "|    time_elapsed                  | 16862        |\n",
      "|    total_timesteps               | 745472       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0055124066 |\n",
      "|    clip_fraction                 | 0.0473       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.465       |\n",
      "|    explained_variance            | 0.81         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 309          |\n",
      "|    n_updates                     | 1810         |\n",
      "|    policy_gradient_loss          | 0.000645     |\n",
      "|    value_loss                    | 1.26e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 183         |\n",
      "|    time_elapsed                  | 16953       |\n",
      "|    total_timesteps               | 749568      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003935271 |\n",
      "|    clip_fraction                 | 0.0332      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.465      |\n",
      "|    explained_variance            | 0.806       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 577         |\n",
      "|    n_updates                     | 1820        |\n",
      "|    policy_gradient_loss          | 0.00202     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -860.0       |\n",
      "|    intervention_sum              | 12           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 184          |\n",
      "|    time_elapsed                  | 17046        |\n",
      "|    total_timesteps               | 753664       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048369714 |\n",
      "|    clip_fraction                 | 0.0346       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.456       |\n",
      "|    explained_variance            | 0.794        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 411          |\n",
      "|    n_updates                     | 1830         |\n",
      "|    policy_gradient_loss          | 0.00117      |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 185         |\n",
      "|    time_elapsed                  | 17139       |\n",
      "|    total_timesteps               | 757760      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003938473 |\n",
      "|    clip_fraction                 | 0.0332      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.46       |\n",
      "|    explained_variance            | 0.801       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 313         |\n",
      "|    n_updates                     | 1840        |\n",
      "|    policy_gradient_loss          | 0.000809    |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 186         |\n",
      "|    time_elapsed                  | 17232       |\n",
      "|    total_timesteps               | 761856      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005328184 |\n",
      "|    clip_fraction                 | 0.0389      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.461      |\n",
      "|    explained_variance            | 0.814       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 293         |\n",
      "|    n_updates                     | 1850        |\n",
      "|    policy_gradient_loss          | 0.00165     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 187         |\n",
      "|    time_elapsed                  | 17324       |\n",
      "|    total_timesteps               | 765952      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003689187 |\n",
      "|    clip_fraction                 | 0.0372      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.468      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 228         |\n",
      "|    n_updates                     | 1860        |\n",
      "|    policy_gradient_loss          | 0.00236     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -960.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 188          |\n",
      "|    time_elapsed                  | 17417        |\n",
      "|    total_timesteps               | 770048       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0074826167 |\n",
      "|    clip_fraction                 | 0.0515       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.464       |\n",
      "|    explained_variance            | 0.814        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 743          |\n",
      "|    n_updates                     | 1870         |\n",
      "|    policy_gradient_loss          | 0.00399      |\n",
      "|    value_loss                    | 1.12e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 189          |\n",
      "|    time_elapsed                  | 17509        |\n",
      "|    total_timesteps               | 774144       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0046155225 |\n",
      "|    clip_fraction                 | 0.0356       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.457       |\n",
      "|    explained_variance            | 0.788        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 513          |\n",
      "|    n_updates                     | 1880         |\n",
      "|    policy_gradient_loss          | 0.00172      |\n",
      "|    value_loss                    | 1.37e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1180.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 190          |\n",
      "|    time_elapsed                  | 17602        |\n",
      "|    total_timesteps               | 778240       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0040965164 |\n",
      "|    clip_fraction                 | 0.0362       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.468       |\n",
      "|    explained_variance            | 0.81         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 502          |\n",
      "|    n_updates                     | 1890         |\n",
      "|    policy_gradient_loss          | 0.00137      |\n",
      "|    value_loss                    | 1.33e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 191         |\n",
      "|    time_elapsed                  | 17694       |\n",
      "|    total_timesteps               | 782336      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004154235 |\n",
      "|    clip_fraction                 | 0.0317      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.813       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 508         |\n",
      "|    n_updates                     | 1900        |\n",
      "|    policy_gradient_loss          | 0.00104     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -860.0       |\n",
      "|    intervention_sum              | 12           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 192          |\n",
      "|    time_elapsed                  | 17787        |\n",
      "|    total_timesteps               | 786432       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036004665 |\n",
      "|    clip_fraction                 | 0.0259       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.446       |\n",
      "|    explained_variance            | 0.816        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 296          |\n",
      "|    n_updates                     | 1910         |\n",
      "|    policy_gradient_loss          | 0.00065      |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 193         |\n",
      "|    time_elapsed                  | 17880       |\n",
      "|    total_timesteps               | 790528      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004944853 |\n",
      "|    clip_fraction                 | 0.0421      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.816       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 360         |\n",
      "|    n_updates                     | 1920        |\n",
      "|    policy_gradient_loss          | 0.000502    |\n",
      "|    value_loss                    | 1.07e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1420.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 194          |\n",
      "|    time_elapsed                  | 17972        |\n",
      "|    total_timesteps               | 794624       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066132303 |\n",
      "|    clip_fraction                 | 0.0484       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.456       |\n",
      "|    explained_variance            | 0.773        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 461          |\n",
      "|    n_updates                     | 1930         |\n",
      "|    policy_gradient_loss          | 0.00364      |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 34           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 195          |\n",
      "|    time_elapsed                  | 18064        |\n",
      "|    total_timesteps               | 798720       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034734812 |\n",
      "|    clip_fraction                 | 0.0286       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.445       |\n",
      "|    explained_variance            | 0.79         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 350          |\n",
      "|    n_updates                     | 1940         |\n",
      "|    policy_gradient_loss          | 3.26e-05     |\n",
      "|    value_loss                    | 1.19e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_800000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 196          |\n",
      "|    time_elapsed                  | 18157        |\n",
      "|    total_timesteps               | 802816       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0037307674 |\n",
      "|    clip_fraction                 | 0.03         |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.453       |\n",
      "|    explained_variance            | 0.783        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 276          |\n",
      "|    n_updates                     | 1950         |\n",
      "|    policy_gradient_loss          | 0.001        |\n",
      "|    value_loss                    | 1.32e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 197          |\n",
      "|    time_elapsed                  | 18250        |\n",
      "|    total_timesteps               | 806912       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0063084103 |\n",
      "|    clip_fraction                 | 0.0427       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.453       |\n",
      "|    explained_variance            | 0.825        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 231          |\n",
      "|    n_updates                     | 1960         |\n",
      "|    policy_gradient_loss          | -0.00135     |\n",
      "|    value_loss                    | 1.01e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 198          |\n",
      "|    time_elapsed                  | 18344        |\n",
      "|    total_timesteps               | 811008       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048277173 |\n",
      "|    clip_fraction                 | 0.034        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.459       |\n",
      "|    explained_variance            | 0.748        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 346          |\n",
      "|    n_updates                     | 1970         |\n",
      "|    policy_gradient_loss          | 0.00147      |\n",
      "|    value_loss                    | 1.5e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -900.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 199          |\n",
      "|    time_elapsed                  | 18436        |\n",
      "|    total_timesteps               | 815104       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0037680306 |\n",
      "|    clip_fraction                 | 0.0268       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.45        |\n",
      "|    explained_variance            | 0.796        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 376          |\n",
      "|    n_updates                     | 1980         |\n",
      "|    policy_gradient_loss          | 0.00119      |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 200          |\n",
      "|    time_elapsed                  | 18529        |\n",
      "|    total_timesteps               | 819200       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036577955 |\n",
      "|    clip_fraction                 | 0.0354       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.443       |\n",
      "|    explained_variance            | 0.804        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 467          |\n",
      "|    n_updates                     | 1990         |\n",
      "|    policy_gradient_loss          | 0.00125      |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 201         |\n",
      "|    time_elapsed                  | 18621       |\n",
      "|    total_timesteps               | 823296      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005341777 |\n",
      "|    clip_fraction                 | 0.0354      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.444      |\n",
      "|    explained_variance            | 0.797       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 434         |\n",
      "|    n_updates                     | 2000        |\n",
      "|    policy_gradient_loss          | 0.00346     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 202          |\n",
      "|    time_elapsed                  | 18714        |\n",
      "|    total_timesteps               | 827392       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0064887316 |\n",
      "|    clip_fraction                 | 0.0471       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.439       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 302          |\n",
      "|    n_updates                     | 2010         |\n",
      "|    policy_gradient_loss          | 0.00334      |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 203         |\n",
      "|    time_elapsed                  | 18806       |\n",
      "|    total_timesteps               | 831488      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005378903 |\n",
      "|    clip_fraction                 | 0.0492      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.806       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 535         |\n",
      "|    n_updates                     | 2020        |\n",
      "|    policy_gradient_loss          | 1.41e-05    |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 204         |\n",
      "|    time_elapsed                  | 18899       |\n",
      "|    total_timesteps               | 835584      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007031082 |\n",
      "|    clip_fraction                 | 0.0457      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.452      |\n",
      "|    explained_variance            | 0.824       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 316         |\n",
      "|    n_updates                     | 2030        |\n",
      "|    policy_gradient_loss          | 0.0017      |\n",
      "|    value_loss                    | 1.15e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 205         |\n",
      "|    time_elapsed                  | 18992       |\n",
      "|    total_timesteps               | 839680      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005051336 |\n",
      "|    clip_fraction                 | 0.0398      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.446      |\n",
      "|    explained_variance            | 0.805       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 384         |\n",
      "|    n_updates                     | 2040        |\n",
      "|    policy_gradient_loss          | -0.000269   |\n",
      "|    value_loss                    | 1.43e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 206          |\n",
      "|    time_elapsed                  | 19084        |\n",
      "|    total_timesteps               | 843776       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0058761016 |\n",
      "|    clip_fraction                 | 0.0395       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.446       |\n",
      "|    explained_variance            | 0.817        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 593          |\n",
      "|    n_updates                     | 2050         |\n",
      "|    policy_gradient_loss          | 0.00164      |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 207         |\n",
      "|    time_elapsed                  | 19177       |\n",
      "|    total_timesteps               | 847872      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005430586 |\n",
      "|    clip_fraction                 | 0.0406      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.444      |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 458         |\n",
      "|    n_updates                     | 2060        |\n",
      "|    policy_gradient_loss          | -0.000203   |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 208         |\n",
      "|    time_elapsed                  | 19269       |\n",
      "|    total_timesteps               | 851968      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007680606 |\n",
      "|    clip_fraction                 | 0.0643      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.443      |\n",
      "|    explained_variance            | 0.797       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 365         |\n",
      "|    n_updates                     | 2070        |\n",
      "|    policy_gradient_loss          | 0.00208     |\n",
      "|    value_loss                    | 1.16e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -940.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 209          |\n",
      "|    time_elapsed                  | 19362        |\n",
      "|    total_timesteps               | 856064       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025871648 |\n",
      "|    clip_fraction                 | 0.0251       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.435       |\n",
      "|    explained_variance            | 0.824        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 456          |\n",
      "|    n_updates                     | 2080         |\n",
      "|    policy_gradient_loss          | 0.00101      |\n",
      "|    value_loss                    | 1.04e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 210          |\n",
      "|    time_elapsed                  | 19455        |\n",
      "|    total_timesteps               | 860160       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0057335873 |\n",
      "|    clip_fraction                 | 0.0466       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.419       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 361          |\n",
      "|    n_updates                     | 2090         |\n",
      "|    policy_gradient_loss          | 0.00303      |\n",
      "|    value_loss                    | 1.23e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 211         |\n",
      "|    time_elapsed                  | 19547       |\n",
      "|    total_timesteps               | 864256      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007110347 |\n",
      "|    clip_fraction                 | 0.0446      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.428      |\n",
      "|    explained_variance            | 0.823       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 319         |\n",
      "|    n_updates                     | 2100        |\n",
      "|    policy_gradient_loss          | -8.88e-05   |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 212         |\n",
      "|    time_elapsed                  | 19640       |\n",
      "|    total_timesteps               | 868352      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004140128 |\n",
      "|    clip_fraction                 | 0.0301      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.434      |\n",
      "|    explained_variance            | 0.846       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 343         |\n",
      "|    n_updates                     | 2110        |\n",
      "|    policy_gradient_loss          | -0.000217   |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 213         |\n",
      "|    time_elapsed                  | 19733       |\n",
      "|    total_timesteps               | 872448      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003743201 |\n",
      "|    clip_fraction                 | 0.0266      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.434      |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 299         |\n",
      "|    n_updates                     | 2120        |\n",
      "|    policy_gradient_loss          | 0.000182    |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -860.0       |\n",
      "|    intervention_sum              | 11           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 214          |\n",
      "|    time_elapsed                  | 19826        |\n",
      "|    total_timesteps               | 876544       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0039775264 |\n",
      "|    clip_fraction                 | 0.0306       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.424       |\n",
      "|    explained_variance            | 0.801        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 319          |\n",
      "|    n_updates                     | 2130         |\n",
      "|    policy_gradient_loss          | 0.00053      |\n",
      "|    value_loss                    | 1.37e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 215          |\n",
      "|    time_elapsed                  | 19918        |\n",
      "|    total_timesteps               | 880640       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0028368826 |\n",
      "|    clip_fraction                 | 0.0241       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.417       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 478          |\n",
      "|    n_updates                     | 2140         |\n",
      "|    policy_gradient_loss          | 0.000199     |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1500.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 62           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 216          |\n",
      "|    time_elapsed                  | 20011        |\n",
      "|    total_timesteps               | 884736       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0065837284 |\n",
      "|    clip_fraction                 | 0.037        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.434       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 471          |\n",
      "|    n_updates                     | 2150         |\n",
      "|    policy_gradient_loss          | -0.000783    |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 217          |\n",
      "|    time_elapsed                  | 20104        |\n",
      "|    total_timesteps               | 888832       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0035338989 |\n",
      "|    clip_fraction                 | 0.0271       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.426       |\n",
      "|    explained_variance            | 0.778        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 397          |\n",
      "|    n_updates                     | 2160         |\n",
      "|    policy_gradient_loss          | -0.00064     |\n",
      "|    value_loss                    | 1.55e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 218         |\n",
      "|    time_elapsed                  | 20197       |\n",
      "|    total_timesteps               | 892928      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004117229 |\n",
      "|    clip_fraction                 | 0.0321      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.425      |\n",
      "|    explained_variance            | 0.799       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 435         |\n",
      "|    n_updates                     | 2170        |\n",
      "|    policy_gradient_loss          | -1.1e-05    |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -940.0      |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 34          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 219         |\n",
      "|    time_elapsed                  | 20289       |\n",
      "|    total_timesteps               | 897024      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004545345 |\n",
      "|    clip_fraction                 | 0.025       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.418      |\n",
      "|    explained_variance            | 0.789       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 497         |\n",
      "|    n_updates                     | 2180        |\n",
      "|    policy_gradient_loss          | 0.00109     |\n",
      "|    value_loss                    | 1.48e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_900000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 220         |\n",
      "|    time_elapsed                  | 20382       |\n",
      "|    total_timesteps               | 901120      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005298835 |\n",
      "|    clip_fraction                 | 0.0329      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.417      |\n",
      "|    explained_variance            | 0.843       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 419         |\n",
      "|    n_updates                     | 2190        |\n",
      "|    policy_gradient_loss          | 0.000765    |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 221         |\n",
      "|    time_elapsed                  | 20475       |\n",
      "|    total_timesteps               | 905216      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004131316 |\n",
      "|    clip_fraction                 | 0.0299      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.411      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 363         |\n",
      "|    n_updates                     | 2200        |\n",
      "|    policy_gradient_loss          | 7.12e-05    |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 222          |\n",
      "|    time_elapsed                  | 20568        |\n",
      "|    total_timesteps               | 909312       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0052114194 |\n",
      "|    clip_fraction                 | 0.0337       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.407       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 330          |\n",
      "|    n_updates                     | 2210         |\n",
      "|    policy_gradient_loss          | 0.000167     |\n",
      "|    value_loss                    | 1.49e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 223          |\n",
      "|    time_elapsed                  | 20660        |\n",
      "|    total_timesteps               | 913408       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0027116868 |\n",
      "|    clip_fraction                 | 0.0211       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.415       |\n",
      "|    explained_variance            | 0.8          |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 345          |\n",
      "|    n_updates                     | 2220         |\n",
      "|    policy_gradient_loss          | 0.000501     |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 224         |\n",
      "|    time_elapsed                  | 20753       |\n",
      "|    total_timesteps               | 917504      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003085351 |\n",
      "|    clip_fraction                 | 0.0227      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.41       |\n",
      "|    explained_variance            | 0.804       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 348         |\n",
      "|    n_updates                     | 2230        |\n",
      "|    policy_gradient_loss          | 0.000903    |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 225         |\n",
      "|    time_elapsed                  | 20846       |\n",
      "|    total_timesteps               | 921600      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005011697 |\n",
      "|    clip_fraction                 | 0.0244      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.406      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 327         |\n",
      "|    n_updates                     | 2240        |\n",
      "|    policy_gradient_loss          | 0.0012      |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 226         |\n",
      "|    time_elapsed                  | 20939       |\n",
      "|    total_timesteps               | 925696      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002724677 |\n",
      "|    clip_fraction                 | 0.0222      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.403      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 339         |\n",
      "|    n_updates                     | 2250        |\n",
      "|    policy_gradient_loss          | 0.000196    |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -820.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 34          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 227         |\n",
      "|    time_elapsed                  | 21032       |\n",
      "|    total_timesteps               | 929792      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005771706 |\n",
      "|    clip_fraction                 | 0.0294      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.41       |\n",
      "|    explained_variance            | 0.809       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 342         |\n",
      "|    n_updates                     | 2260        |\n",
      "|    policy_gradient_loss          | 0.000509    |\n",
      "|    value_loss                    | 1.2e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 228         |\n",
      "|    time_elapsed                  | 21124       |\n",
      "|    total_timesteps               | 933888      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004145787 |\n",
      "|    clip_fraction                 | 0.0264      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.416      |\n",
      "|    explained_variance            | 0.817       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 393         |\n",
      "|    n_updates                     | 2270        |\n",
      "|    policy_gradient_loss          | 0.000189    |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 229          |\n",
      "|    time_elapsed                  | 21217        |\n",
      "|    total_timesteps               | 937984       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0038707526 |\n",
      "|    clip_fraction                 | 0.0252       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.407       |\n",
      "|    explained_variance            | 0.821        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 385          |\n",
      "|    n_updates                     | 2280         |\n",
      "|    policy_gradient_loss          | 0.00122      |\n",
      "|    value_loss                    | 1.23e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 230         |\n",
      "|    time_elapsed                  | 21310       |\n",
      "|    total_timesteps               | 942080      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005233582 |\n",
      "|    clip_fraction                 | 0.034       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.414      |\n",
      "|    explained_variance            | 0.806       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 273         |\n",
      "|    n_updates                     | 2290        |\n",
      "|    policy_gradient_loss          | 0.000824    |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -840.0      |\n",
      "|    intervention_sum              | 11          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 231         |\n",
      "|    time_elapsed                  | 21403       |\n",
      "|    total_timesteps               | 946176      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004669604 |\n",
      "|    clip_fraction                 | 0.0282      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.406      |\n",
      "|    explained_variance            | 0.82        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 330         |\n",
      "|    n_updates                     | 2300        |\n",
      "|    policy_gradient_loss          | -0.000623   |\n",
      "|    value_loss                    | 1.1e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 232          |\n",
      "|    time_elapsed                  | 21495        |\n",
      "|    total_timesteps               | 950272       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0035431301 |\n",
      "|    clip_fraction                 | 0.0232       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.406       |\n",
      "|    explained_variance            | 0.779        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 539          |\n",
      "|    n_updates                     | 2310         |\n",
      "|    policy_gradient_loss          | 0.00096      |\n",
      "|    value_loss                    | 1.83e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 233          |\n",
      "|    time_elapsed                  | 21588        |\n",
      "|    total_timesteps               | 954368       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048837624 |\n",
      "|    clip_fraction                 | 0.0277       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.399       |\n",
      "|    explained_variance            | 0.826        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 602          |\n",
      "|    n_updates                     | 2320         |\n",
      "|    policy_gradient_loss          | 0.00144      |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 234         |\n",
      "|    time_elapsed                  | 21680       |\n",
      "|    total_timesteps               | 958464      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.001468781 |\n",
      "|    clip_fraction                 | 0.0127      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.387      |\n",
      "|    explained_variance            | 0.849       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 512         |\n",
      "|    n_updates                     | 2330        |\n",
      "|    policy_gradient_loss          | 0.000502    |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 235          |\n",
      "|    time_elapsed                  | 21773        |\n",
      "|    total_timesteps               | 962560       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066269888 |\n",
      "|    clip_fraction                 | 0.0367       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.387       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 307          |\n",
      "|    n_updates                     | 2340         |\n",
      "|    policy_gradient_loss          | 0.000911     |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 236          |\n",
      "|    time_elapsed                  | 21865        |\n",
      "|    total_timesteps               | 966656       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0020977512 |\n",
      "|    clip_fraction                 | 0.0143       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.374       |\n",
      "|    explained_variance            | 0.786        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 337          |\n",
      "|    n_updates                     | 2350         |\n",
      "|    policy_gradient_loss          | 1.62e-05     |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -720.0       |\n",
      "|    intervention_sum              | 11           |\n",
      "|    nl_comm_sum                   | 28           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 237          |\n",
      "|    time_elapsed                  | 21957        |\n",
      "|    total_timesteps               | 970752       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024479516 |\n",
      "|    clip_fraction                 | 0.0151       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.385       |\n",
      "|    explained_variance            | 0.839        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 313          |\n",
      "|    n_updates                     | 2360         |\n",
      "|    policy_gradient_loss          | 0.000773     |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 238          |\n",
      "|    time_elapsed                  | 22051        |\n",
      "|    total_timesteps               | 974848       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0029334906 |\n",
      "|    clip_fraction                 | 0.0177       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.374       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 344          |\n",
      "|    n_updates                     | 2370         |\n",
      "|    policy_gradient_loss          | 0.00128      |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 239          |\n",
      "|    time_elapsed                  | 22144        |\n",
      "|    total_timesteps               | 978944       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0020189432 |\n",
      "|    clip_fraction                 | 0.012        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.371       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 353          |\n",
      "|    n_updates                     | 2380         |\n",
      "|    policy_gradient_loss          | -0.000519    |\n",
      "|    value_loss                    | 1.37e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 240          |\n",
      "|    time_elapsed                  | 22236        |\n",
      "|    total_timesteps               | 983040       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0032332735 |\n",
      "|    clip_fraction                 | 0.0206       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.367       |\n",
      "|    explained_variance            | 0.84         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 512          |\n",
      "|    n_updates                     | 2390         |\n",
      "|    policy_gradient_loss          | 0.00108      |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 241          |\n",
      "|    time_elapsed                  | 22329        |\n",
      "|    total_timesteps               | 987136       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0035573444 |\n",
      "|    clip_fraction                 | 0.0209       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.367       |\n",
      "|    explained_variance            | 0.824        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 372          |\n",
      "|    n_updates                     | 2400         |\n",
      "|    policy_gradient_loss          | -0.000396    |\n",
      "|    value_loss                    | 1.39e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 242         |\n",
      "|    time_elapsed                  | 22422       |\n",
      "|    total_timesteps               | 991232      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009913074 |\n",
      "|    clip_fraction                 | 0.0231      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.36       |\n",
      "|    explained_variance            | 0.81        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 374         |\n",
      "|    n_updates                     | 2410        |\n",
      "|    policy_gradient_loss          | 0.00288     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1340.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 243          |\n",
      "|    time_elapsed                  | 22514        |\n",
      "|    total_timesteps               | 995328       |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0023398804 |\n",
      "|    clip_fraction                 | 0.0174       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.359       |\n",
      "|    explained_variance            | 0.847        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 393          |\n",
      "|    n_updates                     | 2420         |\n",
      "|    policy_gradient_loss          | -0.00016     |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -980.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 244         |\n",
      "|    time_elapsed                  | 22607       |\n",
      "|    total_timesteps               | 999424      |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004717977 |\n",
      "|    clip_fraction                 | 0.0284      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.363      |\n",
      "|    explained_variance            | 0.792       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 283         |\n",
      "|    n_updates                     | 2430        |\n",
      "|    policy_gradient_loss          | -0.000347   |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1000000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 245          |\n",
      "|    time_elapsed                  | 22700        |\n",
      "|    total_timesteps               | 1003520      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034967442 |\n",
      "|    clip_fraction                 | 0.0225       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.36        |\n",
      "|    explained_variance            | 0.783        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 497          |\n",
      "|    n_updates                     | 2440         |\n",
      "|    policy_gradient_loss          | 0.00189      |\n",
      "|    value_loss                    | 1.43e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1340.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 246          |\n",
      "|    time_elapsed                  | 22793        |\n",
      "|    total_timesteps               | 1007616      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0023903935 |\n",
      "|    clip_fraction                 | 0.0133       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.361       |\n",
      "|    explained_variance            | 0.829        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 353          |\n",
      "|    n_updates                     | 2450         |\n",
      "|    policy_gradient_loss          | -9.15e-05    |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1180.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 247          |\n",
      "|    time_elapsed                  | 22885        |\n",
      "|    total_timesteps               | 1011712      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026571022 |\n",
      "|    clip_fraction                 | 0.0181       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.362       |\n",
      "|    explained_variance            | 0.813        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 264          |\n",
      "|    n_updates                     | 2460         |\n",
      "|    policy_gradient_loss          | 0.000229     |\n",
      "|    value_loss                    | 1.39e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 248         |\n",
      "|    time_elapsed                  | 22978       |\n",
      "|    total_timesteps               | 1015808     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002610914 |\n",
      "|    clip_fraction                 | 0.0146      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.354      |\n",
      "|    explained_variance            | 0.825       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 520         |\n",
      "|    n_updates                     | 2470        |\n",
      "|    policy_gradient_loss          | -0.000198   |\n",
      "|    value_loss                    | 1.13e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1440.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 56           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 249          |\n",
      "|    time_elapsed                  | 23070        |\n",
      "|    total_timesteps               | 1019904      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0022428655 |\n",
      "|    clip_fraction                 | 0.0166       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.356       |\n",
      "|    explained_variance            | 0.786        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 556          |\n",
      "|    n_updates                     | 2480         |\n",
      "|    policy_gradient_loss          | 0.000862     |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 250          |\n",
      "|    time_elapsed                  | 23163        |\n",
      "|    total_timesteps               | 1024000      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0027482873 |\n",
      "|    clip_fraction                 | 0.0188       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.349       |\n",
      "|    explained_variance            | 0.826        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 339          |\n",
      "|    n_updates                     | 2490         |\n",
      "|    policy_gradient_loss          | -0.000214    |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 251          |\n",
      "|    time_elapsed                  | 23256        |\n",
      "|    total_timesteps               | 1028096      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024008495 |\n",
      "|    clip_fraction                 | 0.025        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.351       |\n",
      "|    explained_variance            | 0.818        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 309          |\n",
      "|    n_updates                     | 2500         |\n",
      "|    policy_gradient_loss          | -0.000962    |\n",
      "|    value_loss                    | 1.35e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 252          |\n",
      "|    time_elapsed                  | 23349        |\n",
      "|    total_timesteps               | 1032192      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0030480083 |\n",
      "|    clip_fraction                 | 0.0146       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.349       |\n",
      "|    explained_variance            | 0.824        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 438          |\n",
      "|    n_updates                     | 2510         |\n",
      "|    policy_gradient_loss          | 0.00125      |\n",
      "|    value_loss                    | 1.12e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -920.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 253          |\n",
      "|    time_elapsed                  | 23442        |\n",
      "|    total_timesteps               | 1036288      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0013505591 |\n",
      "|    clip_fraction                 | 0.0109       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.34        |\n",
      "|    explained_variance            | 0.809        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 295          |\n",
      "|    n_updates                     | 2520         |\n",
      "|    policy_gradient_loss          | 0.00052      |\n",
      "|    value_loss                    | 911          |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 254          |\n",
      "|    time_elapsed                  | 23535        |\n",
      "|    total_timesteps               | 1040384      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025785798 |\n",
      "|    clip_fraction                 | 0.0186       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.349       |\n",
      "|    explained_variance            | 0.817        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 349          |\n",
      "|    n_updates                     | 2530         |\n",
      "|    policy_gradient_loss          | 0.000867     |\n",
      "|    value_loss                    | 1.11e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 255          |\n",
      "|    time_elapsed                  | 23627        |\n",
      "|    total_timesteps               | 1044480      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025109446 |\n",
      "|    clip_fraction                 | 0.0197       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.352       |\n",
      "|    explained_variance            | 0.824        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 404          |\n",
      "|    n_updates                     | 2540         |\n",
      "|    policy_gradient_loss          | -0.000432    |\n",
      "|    value_loss                    | 1.22e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 24           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 256          |\n",
      "|    time_elapsed                  | 23719        |\n",
      "|    total_timesteps               | 1048576      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0035470887 |\n",
      "|    clip_fraction                 | 0.0171       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.355       |\n",
      "|    explained_variance            | 0.787        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 417          |\n",
      "|    n_updates                     | 2550         |\n",
      "|    policy_gradient_loss          | 0.000977     |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 257         |\n",
      "|    time_elapsed                  | 23812       |\n",
      "|    total_timesteps               | 1052672     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003991831 |\n",
      "|    clip_fraction                 | 0.0201      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.356      |\n",
      "|    explained_variance            | 0.83        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 315         |\n",
      "|    n_updates                     | 2560        |\n",
      "|    policy_gradient_loss          | 0.00103     |\n",
      "|    value_loss                    | 1.07e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 258          |\n",
      "|    time_elapsed                  | 23905        |\n",
      "|    total_timesteps               | 1056768      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026431268 |\n",
      "|    clip_fraction                 | 0.0195       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.351       |\n",
      "|    explained_variance            | 0.825        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 379          |\n",
      "|    n_updates                     | 2570         |\n",
      "|    policy_gradient_loss          | 0.000304     |\n",
      "|    value_loss                    | 1.22e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 259         |\n",
      "|    time_elapsed                  | 23998       |\n",
      "|    total_timesteps               | 1060864     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003961215 |\n",
      "|    clip_fraction                 | 0.0193      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.358      |\n",
      "|    explained_variance            | 0.771       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 357         |\n",
      "|    n_updates                     | 2580        |\n",
      "|    policy_gradient_loss          | -0.000681   |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 260          |\n",
      "|    time_elapsed                  | 24090        |\n",
      "|    total_timesteps               | 1064960      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026719337 |\n",
      "|    clip_fraction                 | 0.0111       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.352       |\n",
      "|    explained_variance            | 0.831        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 351          |\n",
      "|    n_updates                     | 2590         |\n",
      "|    policy_gradient_loss          | 0.000382     |\n",
      "|    value_loss                    | 1.06e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 261          |\n",
      "|    time_elapsed                  | 24183        |\n",
      "|    total_timesteps               | 1069056      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0018481503 |\n",
      "|    clip_fraction                 | 0.0134       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.352       |\n",
      "|    explained_variance            | 0.827        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 575          |\n",
      "|    n_updates                     | 2600         |\n",
      "|    policy_gradient_loss          | 3.28e-05     |\n",
      "|    value_loss                    | 1.35e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -960.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 262          |\n",
      "|    time_elapsed                  | 24276        |\n",
      "|    total_timesteps               | 1073152      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041230517 |\n",
      "|    clip_fraction                 | 0.0315       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.355       |\n",
      "|    explained_variance            | 0.809        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 608          |\n",
      "|    n_updates                     | 2610         |\n",
      "|    policy_gradient_loss          | 0.000486     |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 263          |\n",
      "|    time_elapsed                  | 24369        |\n",
      "|    total_timesteps               | 1077248      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034200072 |\n",
      "|    clip_fraction                 | 0.0257       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.359       |\n",
      "|    explained_variance            | 0.826        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 318          |\n",
      "|    n_updates                     | 2620         |\n",
      "|    policy_gradient_loss          | 0.000177     |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 264          |\n",
      "|    time_elapsed                  | 24461        |\n",
      "|    total_timesteps               | 1081344      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0029045506 |\n",
      "|    clip_fraction                 | 0.0141       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.361       |\n",
      "|    explained_variance            | 0.801        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 445          |\n",
      "|    n_updates                     | 2630         |\n",
      "|    policy_gradient_loss          | -0.000634    |\n",
      "|    value_loss                    | 1.39e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 265          |\n",
      "|    time_elapsed                  | 24553        |\n",
      "|    total_timesteps               | 1085440      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0016305369 |\n",
      "|    clip_fraction                 | 0.0115       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.359       |\n",
      "|    explained_variance            | 0.784        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 412          |\n",
      "|    n_updates                     | 2640         |\n",
      "|    policy_gradient_loss          | 0.000314     |\n",
      "|    value_loss                    | 1.51e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -960.0      |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 36          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 266         |\n",
      "|    time_elapsed                  | 24647       |\n",
      "|    total_timesteps               | 1089536     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003548641 |\n",
      "|    clip_fraction                 | 0.0283      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.353      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 304         |\n",
      "|    n_updates                     | 2650        |\n",
      "|    policy_gradient_loss          | 0.00033     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 267          |\n",
      "|    time_elapsed                  | 24739        |\n",
      "|    total_timesteps               | 1093632      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0033899327 |\n",
      "|    clip_fraction                 | 0.0203       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.35        |\n",
      "|    explained_variance            | 0.833        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 384          |\n",
      "|    n_updates                     | 2660         |\n",
      "|    policy_gradient_loss          | 0.00098      |\n",
      "|    value_loss                    | 1.25e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 268          |\n",
      "|    time_elapsed                  | 24832        |\n",
      "|    total_timesteps               | 1097728      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0031292276 |\n",
      "|    clip_fraction                 | 0.0219       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.345       |\n",
      "|    explained_variance            | 0.785        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 299          |\n",
      "|    n_updates                     | 2670         |\n",
      "|    policy_gradient_loss          | -0.000366    |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1100000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 269          |\n",
      "|    time_elapsed                  | 24925        |\n",
      "|    total_timesteps               | 1101824      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0033724653 |\n",
      "|    clip_fraction                 | 0.0226       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.338       |\n",
      "|    explained_variance            | 0.829        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 325          |\n",
      "|    n_updates                     | 2680         |\n",
      "|    policy_gradient_loss          | -0.000766    |\n",
      "|    value_loss                    | 1.07e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 270         |\n",
      "|    time_elapsed                  | 25018       |\n",
      "|    total_timesteps               | 1105920     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002694504 |\n",
      "|    clip_fraction                 | 0.016       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.34       |\n",
      "|    explained_variance            | 0.795       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 431         |\n",
      "|    n_updates                     | 2690        |\n",
      "|    policy_gradient_loss          | -0.000602   |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1440.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 56           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 271          |\n",
      "|    time_elapsed                  | 25111        |\n",
      "|    total_timesteps               | 1110016      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026859124 |\n",
      "|    clip_fraction                 | 0.0217       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.333       |\n",
      "|    explained_variance            | 0.783        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 312          |\n",
      "|    n_updates                     | 2700         |\n",
      "|    policy_gradient_loss          | 0.0012       |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 272          |\n",
      "|    time_elapsed                  | 25203        |\n",
      "|    total_timesteps               | 1114112      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034056366 |\n",
      "|    clip_fraction                 | 0.0288       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.34        |\n",
      "|    explained_variance            | 0.846        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 291          |\n",
      "|    n_updates                     | 2710         |\n",
      "|    policy_gradient_loss          | -0.000525    |\n",
      "|    value_loss                    | 1.02e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 58           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 273          |\n",
      "|    time_elapsed                  | 25295        |\n",
      "|    total_timesteps               | 1118208      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025703486 |\n",
      "|    clip_fraction                 | 0.0193       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.337       |\n",
      "|    explained_variance            | 0.791        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 365          |\n",
      "|    n_updates                     | 2720         |\n",
      "|    policy_gradient_loss          | -0.000313    |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 274          |\n",
      "|    time_elapsed                  | 25389        |\n",
      "|    total_timesteps               | 1122304      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024536164 |\n",
      "|    clip_fraction                 | 0.0151       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.33        |\n",
      "|    explained_variance            | 0.831        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 374          |\n",
      "|    n_updates                     | 2730         |\n",
      "|    policy_gradient_loss          | -0.000675    |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 275          |\n",
      "|    time_elapsed                  | 25482        |\n",
      "|    total_timesteps               | 1126400      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0029306877 |\n",
      "|    clip_fraction                 | 0.0195       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.324       |\n",
      "|    explained_variance            | 0.795        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 354          |\n",
      "|    n_updates                     | 2740         |\n",
      "|    policy_gradient_loss          | -0.000325    |\n",
      "|    value_loss                    | 1.46e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 276          |\n",
      "|    time_elapsed                  | 25574        |\n",
      "|    total_timesteps               | 1130496      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0022141098 |\n",
      "|    clip_fraction                 | 0.0172       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.328       |\n",
      "|    explained_variance            | 0.82         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 519          |\n",
      "|    n_updates                     | 2750         |\n",
      "|    policy_gradient_loss          | 0.000175     |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 277          |\n",
      "|    time_elapsed                  | 25666        |\n",
      "|    total_timesteps               | 1134592      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026440627 |\n",
      "|    clip_fraction                 | 0.0177       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.325       |\n",
      "|    explained_variance            | 0.788        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 371          |\n",
      "|    n_updates                     | 2760         |\n",
      "|    policy_gradient_loss          | -0.00054     |\n",
      "|    value_loss                    | 1.33e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 278         |\n",
      "|    time_elapsed                  | 25759       |\n",
      "|    total_timesteps               | 1138688     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002102133 |\n",
      "|    clip_fraction                 | 0.0155      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.323      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 357         |\n",
      "|    n_updates                     | 2770        |\n",
      "|    policy_gradient_loss          | -0.000663   |\n",
      "|    value_loss                    | 952         |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 279          |\n",
      "|    time_elapsed                  | 25852        |\n",
      "|    total_timesteps               | 1142784      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026476816 |\n",
      "|    clip_fraction                 | 0.0157       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.325       |\n",
      "|    explained_variance            | 0.828        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 300          |\n",
      "|    n_updates                     | 2780         |\n",
      "|    policy_gradient_loss          | 8.34e-05     |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 280          |\n",
      "|    time_elapsed                  | 25945        |\n",
      "|    total_timesteps               | 1146880      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0021229065 |\n",
      "|    clip_fraction                 | 0.014        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.327       |\n",
      "|    explained_variance            | 0.837        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 354          |\n",
      "|    n_updates                     | 2790         |\n",
      "|    policy_gradient_loss          | -0.000497    |\n",
      "|    value_loss                    | 1.26e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1060.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 281          |\n",
      "|    time_elapsed                  | 26037        |\n",
      "|    total_timesteps               | 1150976      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0016093168 |\n",
      "|    clip_fraction                 | 0.0124       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.338       |\n",
      "|    explained_variance            | 0.795        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 423          |\n",
      "|    n_updates                     | 2800         |\n",
      "|    policy_gradient_loss          | 0.000475     |\n",
      "|    value_loss                    | 1.43e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1000.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 282          |\n",
      "|    time_elapsed                  | 26129        |\n",
      "|    total_timesteps               | 1155072      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0017510402 |\n",
      "|    clip_fraction                 | 0.0126       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.335       |\n",
      "|    explained_variance            | 0.782        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 373          |\n",
      "|    n_updates                     | 2810         |\n",
      "|    policy_gradient_loss          | 0.000982     |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 62           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 283          |\n",
      "|    time_elapsed                  | 26223        |\n",
      "|    total_timesteps               | 1159168      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025860853 |\n",
      "|    clip_fraction                 | 0.0197       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.329       |\n",
      "|    explained_variance            | 0.825        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 345          |\n",
      "|    n_updates                     | 2820         |\n",
      "|    policy_gradient_loss          | 2.91e-05     |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1000.0      |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 284          |\n",
      "|    time_elapsed                  | 26315        |\n",
      "|    total_timesteps               | 1163264      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0018786127 |\n",
      "|    clip_fraction                 | 0.0157       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.329       |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 509          |\n",
      "|    n_updates                     | 2830         |\n",
      "|    policy_gradient_loss          | -0.000637    |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 285          |\n",
      "|    time_elapsed                  | 26407        |\n",
      "|    total_timesteps               | 1167360      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0018508933 |\n",
      "|    clip_fraction                 | 0.0121       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.321       |\n",
      "|    explained_variance            | 0.829        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 362          |\n",
      "|    n_updates                     | 2840         |\n",
      "|    policy_gradient_loss          | -0.000176    |\n",
      "|    value_loss                    | 1.25e+03     |\n",
      "---------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1220.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 46         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 286        |\n",
      "|    time_elapsed                  | 26500      |\n",
      "|    total_timesteps               | 1171456    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00244043 |\n",
      "|    clip_fraction                 | 0.024      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.325     |\n",
      "|    explained_variance            | 0.819      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 280        |\n",
      "|    n_updates                     | 2850       |\n",
      "|    policy_gradient_loss          | 5.89e-05   |\n",
      "|    value_loss                    | 1.19e+03   |\n",
      "-------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 287          |\n",
      "|    time_elapsed                  | 26593        |\n",
      "|    total_timesteps               | 1175552      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0015682623 |\n",
      "|    clip_fraction                 | 0.0154       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.337       |\n",
      "|    explained_variance            | 0.838        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 543          |\n",
      "|    n_updates                     | 2860         |\n",
      "|    policy_gradient_loss          | 0.000217     |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 288         |\n",
      "|    time_elapsed                  | 26685       |\n",
      "|    total_timesteps               | 1179648     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002354384 |\n",
      "|    clip_fraction                 | 0.0153      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.332      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 379         |\n",
      "|    n_updates                     | 2870        |\n",
      "|    policy_gradient_loss          | -0.000598   |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 289          |\n",
      "|    time_elapsed                  | 26778        |\n",
      "|    total_timesteps               | 1183744      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0023861404 |\n",
      "|    clip_fraction                 | 0.0159       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.327       |\n",
      "|    explained_variance            | 0.839        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 336          |\n",
      "|    n_updates                     | 2880         |\n",
      "|    policy_gradient_loss          | 0.000454     |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -880.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 36           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 290          |\n",
      "|    time_elapsed                  | 26871        |\n",
      "|    total_timesteps               | 1187840      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025480604 |\n",
      "|    clip_fraction                 | 0.0187       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.326       |\n",
      "|    explained_variance            | 0.798        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 297          |\n",
      "|    n_updates                     | 2890         |\n",
      "|    policy_gradient_loss          | -0.000831    |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 291          |\n",
      "|    time_elapsed                  | 26963        |\n",
      "|    total_timesteps               | 1191936      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036073504 |\n",
      "|    clip_fraction                 | 0.0183       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.331       |\n",
      "|    explained_variance            | 0.769        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 323          |\n",
      "|    n_updates                     | 2900         |\n",
      "|    policy_gradient_loss          | 0.00177      |\n",
      "|    value_loss                    | 1.34e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 292          |\n",
      "|    time_elapsed                  | 27056        |\n",
      "|    total_timesteps               | 1196032      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0019124036 |\n",
      "|    clip_fraction                 | 0.0142       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.336       |\n",
      "|    explained_variance            | 0.797        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 293          |\n",
      "|    n_updates                     | 2910         |\n",
      "|    policy_gradient_loss          | -6.01e-05    |\n",
      "|    value_loss                    | 1.09e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1200000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 293         |\n",
      "|    time_elapsed                  | 27149       |\n",
      "|    total_timesteps               | 1200128     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002598515 |\n",
      "|    clip_fraction                 | 0.0173      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.339      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 312         |\n",
      "|    n_updates                     | 2920        |\n",
      "|    policy_gradient_loss          | -8.97e-05   |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 294          |\n",
      "|    time_elapsed                  | 27242        |\n",
      "|    total_timesteps               | 1204224      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026970888 |\n",
      "|    clip_fraction                 | 0.0142       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.333       |\n",
      "|    explained_variance            | 0.823        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 177          |\n",
      "|    n_updates                     | 2930         |\n",
      "|    policy_gradient_loss          | 0.000566     |\n",
      "|    value_loss                    | 1.09e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 295          |\n",
      "|    time_elapsed                  | 27334        |\n",
      "|    total_timesteps               | 1208320      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0016193106 |\n",
      "|    clip_fraction                 | 0.0152       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.337       |\n",
      "|    explained_variance            | 0.828        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 291          |\n",
      "|    n_updates                     | 2940         |\n",
      "|    policy_gradient_loss          | -0.000299    |\n",
      "|    value_loss                    | 1.06e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 296          |\n",
      "|    time_elapsed                  | 27426        |\n",
      "|    total_timesteps               | 1212416      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0020179905 |\n",
      "|    clip_fraction                 | 0.0116       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.334       |\n",
      "|    explained_variance            | 0.804        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 367          |\n",
      "|    n_updates                     | 2950         |\n",
      "|    policy_gradient_loss          | 0.00149      |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1360.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 297          |\n",
      "|    time_elapsed                  | 27521        |\n",
      "|    total_timesteps               | 1216512      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025568688 |\n",
      "|    clip_fraction                 | 0.0171       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.335       |\n",
      "|    explained_variance            | 0.817        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 338          |\n",
      "|    n_updates                     | 2960         |\n",
      "|    policy_gradient_loss          | 0.000279     |\n",
      "|    value_loss                    | 1.03e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 298         |\n",
      "|    time_elapsed                  | 27614       |\n",
      "|    total_timesteps               | 1220608     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.001908784 |\n",
      "|    clip_fraction                 | 0.015       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.339      |\n",
      "|    explained_variance            | 0.8         |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 273         |\n",
      "|    n_updates                     | 2970        |\n",
      "|    policy_gradient_loss          | -0.000149   |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 299          |\n",
      "|    time_elapsed                  | 27706        |\n",
      "|    total_timesteps               | 1224704      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024644472 |\n",
      "|    clip_fraction                 | 0.0141       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.334       |\n",
      "|    explained_variance            | 0.82         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 264          |\n",
      "|    n_updates                     | 2980         |\n",
      "|    policy_gradient_loss          | -0.000116    |\n",
      "|    value_loss                    | 1.25e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 300          |\n",
      "|    time_elapsed                  | 27798        |\n",
      "|    total_timesteps               | 1228800      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0030423747 |\n",
      "|    clip_fraction                 | 0.0183       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.326       |\n",
      "|    explained_variance            | 0.85         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 385          |\n",
      "|    n_updates                     | 2990         |\n",
      "|    policy_gradient_loss          | -0.000506    |\n",
      "|    value_loss                    | 1.15e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 301          |\n",
      "|    time_elapsed                  | 27892        |\n",
      "|    total_timesteps               | 1232896      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0019962308 |\n",
      "|    clip_fraction                 | 0.0104       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.326       |\n",
      "|    explained_variance            | 0.831        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 338          |\n",
      "|    n_updates                     | 3000         |\n",
      "|    policy_gradient_loss          | -0.000308    |\n",
      "|    value_loss                    | 1.14e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 302          |\n",
      "|    time_elapsed                  | 27985        |\n",
      "|    total_timesteps               | 1236992      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0013524138 |\n",
      "|    clip_fraction                 | 0.0104       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.322       |\n",
      "|    explained_variance            | 0.849        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 405          |\n",
      "|    n_updates                     | 3010         |\n",
      "|    policy_gradient_loss          | 0.000915     |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 303          |\n",
      "|    time_elapsed                  | 28077        |\n",
      "|    total_timesteps               | 1241088      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0016895548 |\n",
      "|    clip_fraction                 | 0.0143       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.318       |\n",
      "|    explained_variance            | 0.827        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 522          |\n",
      "|    n_updates                     | 3020         |\n",
      "|    policy_gradient_loss          | -0.000199    |\n",
      "|    value_loss                    | 1.76e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1040.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 304          |\n",
      "|    time_elapsed                  | 28169        |\n",
      "|    total_timesteps               | 1245184      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0014765984 |\n",
      "|    clip_fraction                 | 0.0131       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.318       |\n",
      "|    explained_variance            | 0.819        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 364          |\n",
      "|    n_updates                     | 3030         |\n",
      "|    policy_gradient_loss          | 2.24e-05     |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 305          |\n",
      "|    time_elapsed                  | 28262        |\n",
      "|    total_timesteps               | 1249280      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0017865336 |\n",
      "|    clip_fraction                 | 0.0137       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.333       |\n",
      "|    explained_variance            | 0.826        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 318          |\n",
      "|    n_updates                     | 3040         |\n",
      "|    policy_gradient_loss          | -0.000427    |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 306          |\n",
      "|    time_elapsed                  | 28355        |\n",
      "|    total_timesteps               | 1253376      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0012224558 |\n",
      "|    clip_fraction                 | 0.00791      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.323       |\n",
      "|    explained_variance            | 0.768        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 834          |\n",
      "|    n_updates                     | 3050         |\n",
      "|    policy_gradient_loss          | -7.04e-05    |\n",
      "|    value_loss                    | 1.46e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -820.0       |\n",
      "|    intervention_sum              | 12           |\n",
      "|    nl_comm_sum                   | 34           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 307          |\n",
      "|    time_elapsed                  | 28448        |\n",
      "|    total_timesteps               | 1257472      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0018733083 |\n",
      "|    clip_fraction                 | 0.0125       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.324       |\n",
      "|    explained_variance            | 0.803        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 581          |\n",
      "|    n_updates                     | 3060         |\n",
      "|    policy_gradient_loss          | 0.000109     |\n",
      "|    value_loss                    | 1.42e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 308         |\n",
      "|    time_elapsed                  | 28540       |\n",
      "|    total_timesteps               | 1261568     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002006547 |\n",
      "|    clip_fraction                 | 0.0118      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.315      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 293         |\n",
      "|    n_updates                     | 3070        |\n",
      "|    policy_gradient_loss          | -0.000573   |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 30           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 309          |\n",
      "|    time_elapsed                  | 28632        |\n",
      "|    total_timesteps               | 1265664      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024055839 |\n",
      "|    clip_fraction                 | 0.017        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.314       |\n",
      "|    explained_variance            | 0.804        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 379          |\n",
      "|    n_updates                     | 3080         |\n",
      "|    policy_gradient_loss          | -0.0017      |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 310         |\n",
      "|    time_elapsed                  | 28725       |\n",
      "|    total_timesteps               | 1269760     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.001202494 |\n",
      "|    clip_fraction                 | 0.00918     |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.316      |\n",
      "|    explained_variance            | 0.801       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 803         |\n",
      "|    n_updates                     | 3090        |\n",
      "|    policy_gradient_loss          | 4.89e-05    |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 311          |\n",
      "|    time_elapsed                  | 28818        |\n",
      "|    total_timesteps               | 1273856      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0017109775 |\n",
      "|    clip_fraction                 | 0.0144       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.322       |\n",
      "|    explained_variance            | 0.784        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 353          |\n",
      "|    n_updates                     | 3100         |\n",
      "|    policy_gradient_loss          | -0.000842    |\n",
      "|    value_loss                    | 1.39e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 36           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 312          |\n",
      "|    time_elapsed                  | 28910        |\n",
      "|    total_timesteps               | 1277952      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025002938 |\n",
      "|    clip_fraction                 | 0.0144       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.308       |\n",
      "|    explained_variance            | 0.837        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 403          |\n",
      "|    n_updates                     | 3110         |\n",
      "|    policy_gradient_loss          | -0.00035     |\n",
      "|    value_loss                    | 1.01e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 313         |\n",
      "|    time_elapsed                  | 29002       |\n",
      "|    total_timesteps               | 1282048     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002118184 |\n",
      "|    clip_fraction                 | 0.0152      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.317      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 627         |\n",
      "|    n_updates                     | 3120        |\n",
      "|    policy_gradient_loss          | -0.000562   |\n",
      "|    value_loss                    | 1.51e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 314          |\n",
      "|    time_elapsed                  | 29095        |\n",
      "|    total_timesteps               | 1286144      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024687166 |\n",
      "|    clip_fraction                 | 0.0154       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.316       |\n",
      "|    explained_variance            | 0.821        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 202          |\n",
      "|    n_updates                     | 3130         |\n",
      "|    policy_gradient_loss          | 0.000238     |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1060.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 315          |\n",
      "|    time_elapsed                  | 29188        |\n",
      "|    total_timesteps               | 1290240      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0019741543 |\n",
      "|    clip_fraction                 | 0.0146       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.311       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 368          |\n",
      "|    n_updates                     | 3140         |\n",
      "|    policy_gradient_loss          | -0.000631    |\n",
      "|    value_loss                    | 1.15e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 316          |\n",
      "|    time_elapsed                  | 29280        |\n",
      "|    total_timesteps               | 1294336      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026914943 |\n",
      "|    clip_fraction                 | 0.0183       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.317       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 515          |\n",
      "|    n_updates                     | 3150         |\n",
      "|    policy_gradient_loss          | 0.000336     |\n",
      "|    value_loss                    | 1.33e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1060.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 317          |\n",
      "|    time_elapsed                  | 29373        |\n",
      "|    total_timesteps               | 1298432      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0021225868 |\n",
      "|    clip_fraction                 | 0.0144       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.315       |\n",
      "|    explained_variance            | 0.821        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 373          |\n",
      "|    n_updates                     | 3160         |\n",
      "|    policy_gradient_loss          | 0.00071      |\n",
      "|    value_loss                    | 1.2e+03      |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1300000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1060.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 318         |\n",
      "|    time_elapsed                  | 29466       |\n",
      "|    total_timesteps               | 1302528     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003303951 |\n",
      "|    clip_fraction                 | 0.0208      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.32       |\n",
      "|    explained_variance            | 0.837       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 248         |\n",
      "|    n_updates                     | 3170        |\n",
      "|    policy_gradient_loss          | 0.00177     |\n",
      "|    value_loss                    | 1.09e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 319         |\n",
      "|    time_elapsed                  | 29560       |\n",
      "|    total_timesteps               | 1306624     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002582442 |\n",
      "|    clip_fraction                 | 0.0154      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.317      |\n",
      "|    explained_variance            | 0.82        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 848         |\n",
      "|    n_updates                     | 3180        |\n",
      "|    policy_gradient_loss          | -0.000125   |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 320          |\n",
      "|    time_elapsed                  | 29652        |\n",
      "|    total_timesteps               | 1310720      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0016918959 |\n",
      "|    clip_fraction                 | 0.0116       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.319       |\n",
      "|    explained_variance            | 0.811        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 406          |\n",
      "|    n_updates                     | 3190         |\n",
      "|    policy_gradient_loss          | 5.95e-05     |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 321          |\n",
      "|    time_elapsed                  | 29745        |\n",
      "|    total_timesteps               | 1314816      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026429938 |\n",
      "|    clip_fraction                 | 0.0241       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.312       |\n",
      "|    explained_variance            | 0.844        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 306          |\n",
      "|    n_updates                     | 3200         |\n",
      "|    policy_gradient_loss          | -0.0011      |\n",
      "|    value_loss                    | 934          |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 322          |\n",
      "|    time_elapsed                  | 29838        |\n",
      "|    total_timesteps               | 1318912      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0010632538 |\n",
      "|    clip_fraction                 | 0.00715      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.309       |\n",
      "|    explained_variance            | 0.838        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 176          |\n",
      "|    n_updates                     | 3210         |\n",
      "|    policy_gradient_loss          | -0.000972    |\n",
      "|    value_loss                    | 1.05e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 323          |\n",
      "|    time_elapsed                  | 29930        |\n",
      "|    total_timesteps               | 1323008      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0014300247 |\n",
      "|    clip_fraction                 | 0.0113       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.304       |\n",
      "|    explained_variance            | 0.838        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 459          |\n",
      "|    n_updates                     | 3220         |\n",
      "|    policy_gradient_loss          | -0.000298    |\n",
      "|    value_loss                    | 1.28e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1260.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 324          |\n",
      "|    time_elapsed                  | 30022        |\n",
      "|    total_timesteps               | 1327104      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0017062014 |\n",
      "|    clip_fraction                 | 0.0103       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.299       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 508          |\n",
      "|    n_updates                     | 3230         |\n",
      "|    policy_gradient_loss          | -0.000245    |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -880.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 36           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 325          |\n",
      "|    time_elapsed                  | 30116        |\n",
      "|    total_timesteps               | 1331200      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0012289811 |\n",
      "|    clip_fraction                 | 0.00911      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.304       |\n",
      "|    explained_variance            | 0.844        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 456          |\n",
      "|    n_updates                     | 3240         |\n",
      "|    policy_gradient_loss          | 8.66e-05     |\n",
      "|    value_loss                    | 1.13e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1140.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 326          |\n",
      "|    time_elapsed                  | 30209        |\n",
      "|    total_timesteps               | 1335296      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0022372296 |\n",
      "|    clip_fraction                 | 0.0146       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.3         |\n",
      "|    explained_variance            | 0.831        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 414          |\n",
      "|    n_updates                     | 3250         |\n",
      "|    policy_gradient_loss          | 5.27e-05     |\n",
      "|    value_loss                    | 1.51e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 327          |\n",
      "|    time_elapsed                  | 30301        |\n",
      "|    total_timesteps               | 1339392      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0009698181 |\n",
      "|    clip_fraction                 | 0.0083       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.311       |\n",
      "|    explained_variance            | 0.765        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 434          |\n",
      "|    n_updates                     | 3260         |\n",
      "|    policy_gradient_loss          | -0.000273    |\n",
      "|    value_loss                    | 1.62e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 328          |\n",
      "|    time_elapsed                  | 30400        |\n",
      "|    total_timesteps               | 1343488      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0025000547 |\n",
      "|    clip_fraction                 | 0.022        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.307       |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 289          |\n",
      "|    n_updates                     | 3270         |\n",
      "|    policy_gradient_loss          | -0.000512    |\n",
      "|    value_loss                    | 1.12e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 329          |\n",
      "|    time_elapsed                  | 30498        |\n",
      "|    total_timesteps               | 1347584      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049105845 |\n",
      "|    clip_fraction                 | 0.0264       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.3         |\n",
      "|    explained_variance            | 0.8          |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 315          |\n",
      "|    n_updates                     | 3280         |\n",
      "|    policy_gradient_loss          | -2.16e-05    |\n",
      "|    value_loss                    | 1.14e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 330         |\n",
      "|    time_elapsed                  | 30594       |\n",
      "|    total_timesteps               | 1351680     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.001987832 |\n",
      "|    clip_fraction                 | 0.0139      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.297      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 489         |\n",
      "|    n_updates                     | 3290        |\n",
      "|    policy_gradient_loss          | -0.00079    |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 331          |\n",
      "|    time_elapsed                  | 30690        |\n",
      "|    total_timesteps               | 1355776      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0011762342 |\n",
      "|    clip_fraction                 | 0.0093       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.29        |\n",
      "|    explained_variance            | 0.798        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 512          |\n",
      "|    n_updates                     | 3300         |\n",
      "|    policy_gradient_loss          | -2.04e-05    |\n",
      "|    value_loss                    | 1.46e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1420.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 332          |\n",
      "|    time_elapsed                  | 30786        |\n",
      "|    total_timesteps               | 1359872      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0017908134 |\n",
      "|    clip_fraction                 | 0.0161       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.299       |\n",
      "|    explained_variance            | 0.833        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 295          |\n",
      "|    n_updates                     | 3310         |\n",
      "|    policy_gradient_loss          | -0.00073     |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1380.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 333          |\n",
      "|    time_elapsed                  | 30882        |\n",
      "|    total_timesteps               | 1363968      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0013194808 |\n",
      "|    clip_fraction                 | 0.00933      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.306       |\n",
      "|    explained_variance            | 0.819        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 385          |\n",
      "|    n_updates                     | 3320         |\n",
      "|    policy_gradient_loss          | 0.000218     |\n",
      "|    value_loss                    | 1.25e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1100.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 334          |\n",
      "|    time_elapsed                  | 30978        |\n",
      "|    total_timesteps               | 1368064      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0019329924 |\n",
      "|    clip_fraction                 | 0.0127       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.313       |\n",
      "|    explained_variance            | 0.821        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 323          |\n",
      "|    n_updates                     | 3330         |\n",
      "|    policy_gradient_loss          | -0.000225    |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 335         |\n",
      "|    time_elapsed                  | 31074       |\n",
      "|    total_timesteps               | 1372160     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002793798 |\n",
      "|    clip_fraction                 | 0.0265      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.322      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 259         |\n",
      "|    n_updates                     | 3340        |\n",
      "|    policy_gradient_loss          | 8.31e-05    |\n",
      "|    value_loss                    | 1.14e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 336         |\n",
      "|    time_elapsed                  | 31169       |\n",
      "|    total_timesteps               | 1376256     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.002091132 |\n",
      "|    clip_fraction                 | 0.0159      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.328      |\n",
      "|    explained_variance            | 0.777       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 315         |\n",
      "|    n_updates                     | 3350        |\n",
      "|    policy_gradient_loss          | 0.000342    |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 337         |\n",
      "|    time_elapsed                  | 31266       |\n",
      "|    total_timesteps               | 1380352     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003388421 |\n",
      "|    clip_fraction                 | 0.0257      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.33       |\n",
      "|    explained_variance            | 0.804       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 405         |\n",
      "|    n_updates                     | 3360        |\n",
      "|    policy_gradient_loss          | 0.000797    |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1420.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 338          |\n",
      "|    time_elapsed                  | 31363        |\n",
      "|    total_timesteps               | 1384448      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0010312976 |\n",
      "|    clip_fraction                 | 0.00845      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.335       |\n",
      "|    explained_variance            | 0.827        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 569          |\n",
      "|    n_updates                     | 3370         |\n",
      "|    policy_gradient_loss          | 3.89e-05     |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 339          |\n",
      "|    time_elapsed                  | 31459        |\n",
      "|    total_timesteps               | 1388544      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0027771408 |\n",
      "|    clip_fraction                 | 0.0291       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.342       |\n",
      "|    explained_variance            | 0.813        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 426          |\n",
      "|    n_updates                     | 3380         |\n",
      "|    policy_gradient_loss          | 7.49e-05     |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 340          |\n",
      "|    time_elapsed                  | 31554        |\n",
      "|    total_timesteps               | 1392640      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0019187639 |\n",
      "|    clip_fraction                 | 0.0183       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.333       |\n",
      "|    explained_variance            | 0.807        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 455          |\n",
      "|    n_updates                     | 3390         |\n",
      "|    policy_gradient_loss          | -0.000281    |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1460.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 62           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 341          |\n",
      "|    time_elapsed                  | 31651        |\n",
      "|    total_timesteps               | 1396736      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0011103625 |\n",
      "|    clip_fraction                 | 0.00701      |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.342       |\n",
      "|    explained_variance            | 0.848        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 284          |\n",
      "|    n_updates                     | 3400         |\n",
      "|    policy_gradient_loss          | -4.35e-05    |\n",
      "|    value_loss                    | 1.11e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1400000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 342          |\n",
      "|    time_elapsed                  | 31748        |\n",
      "|    total_timesteps               | 1400832      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0031676504 |\n",
      "|    clip_fraction                 | 0.0246       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.367       |\n",
      "|    explained_variance            | 0.789        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 396          |\n",
      "|    n_updates                     | 3410         |\n",
      "|    policy_gradient_loss          | 0.000445     |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 343          |\n",
      "|    time_elapsed                  | 31844        |\n",
      "|    total_timesteps               | 1404928      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0035743653 |\n",
      "|    clip_fraction                 | 0.0205       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.365       |\n",
      "|    explained_variance            | 0.794        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 535          |\n",
      "|    n_updates                     | 3420         |\n",
      "|    policy_gradient_loss          | 0.0004       |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1340.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 58           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 344          |\n",
      "|    time_elapsed                  | 31939        |\n",
      "|    total_timesteps               | 1409024      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0018465272 |\n",
      "|    clip_fraction                 | 0.0134       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.379       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 510          |\n",
      "|    n_updates                     | 3430         |\n",
      "|    policy_gradient_loss          | 0.000644     |\n",
      "|    value_loss                    | 1.42e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 345          |\n",
      "|    time_elapsed                  | 32036        |\n",
      "|    total_timesteps               | 1413120      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0036808804 |\n",
      "|    clip_fraction                 | 0.0261       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.368       |\n",
      "|    explained_variance            | 0.799        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 420          |\n",
      "|    n_updates                     | 3440         |\n",
      "|    policy_gradient_loss          | -0.00066     |\n",
      "|    value_loss                    | 1.1e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 36          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 346         |\n",
      "|    time_elapsed                  | 32133       |\n",
      "|    total_timesteps               | 1417216     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.003290149 |\n",
      "|    clip_fraction                 | 0.0219      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.362      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 220         |\n",
      "|    n_updates                     | 3450        |\n",
      "|    policy_gradient_loss          | 0.000361    |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -860.0       |\n",
      "|    intervention_sum              | 12           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 347          |\n",
      "|    time_elapsed                  | 32229        |\n",
      "|    total_timesteps               | 1421312      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0027131052 |\n",
      "|    clip_fraction                 | 0.0157       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.372       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 250          |\n",
      "|    n_updates                     | 3460         |\n",
      "|    policy_gradient_loss          | 0.000137     |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1020.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 348          |\n",
      "|    time_elapsed                  | 32325        |\n",
      "|    total_timesteps               | 1425408      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024452843 |\n",
      "|    clip_fraction                 | 0.0152       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.376       |\n",
      "|    explained_variance            | 0.834        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 411          |\n",
      "|    n_updates                     | 3470         |\n",
      "|    policy_gradient_loss          | 0.000804     |\n",
      "|    value_loss                    | 1.22e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 40           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 349          |\n",
      "|    time_elapsed                  | 32421        |\n",
      "|    total_timesteps               | 1429504      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0029746525 |\n",
      "|    clip_fraction                 | 0.0255       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.384       |\n",
      "|    explained_variance            | 0.824        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 405          |\n",
      "|    n_updates                     | 3480         |\n",
      "|    policy_gradient_loss          | 0.000811     |\n",
      "|    value_loss                    | 1.38e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 350          |\n",
      "|    time_elapsed                  | 32518        |\n",
      "|    total_timesteps               | 1433600      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0049973927 |\n",
      "|    clip_fraction                 | 0.0368       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.379       |\n",
      "|    explained_variance            | 0.778        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 253          |\n",
      "|    n_updates                     | 3490         |\n",
      "|    policy_gradient_loss          | -0.000344    |\n",
      "|    value_loss                    | 1.21e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 351          |\n",
      "|    time_elapsed                  | 32613        |\n",
      "|    total_timesteps               | 1437696      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034954143 |\n",
      "|    clip_fraction                 | 0.0305       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.377       |\n",
      "|    explained_variance            | 0.826        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 429          |\n",
      "|    n_updates                     | 3500         |\n",
      "|    policy_gradient_loss          | -0.000141    |\n",
      "|    value_loss                    | 1.49e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 352         |\n",
      "|    time_elapsed                  | 32709       |\n",
      "|    total_timesteps               | 1441792     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005318962 |\n",
      "|    clip_fraction                 | 0.0453      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.38       |\n",
      "|    explained_variance            | 0.785       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 431         |\n",
      "|    n_updates                     | 3510        |\n",
      "|    policy_gradient_loss          | -0.000862   |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 14           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 353          |\n",
      "|    time_elapsed                  | 32805        |\n",
      "|    total_timesteps               | 1445888      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0030961935 |\n",
      "|    clip_fraction                 | 0.0221       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.397       |\n",
      "|    explained_variance            | 0.798        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 478          |\n",
      "|    n_updates                     | 3520         |\n",
      "|    policy_gradient_loss          | -0.000488    |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -960.0       |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 36           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 354          |\n",
      "|    time_elapsed                  | 32902        |\n",
      "|    total_timesteps               | 1449984      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0051852074 |\n",
      "|    clip_fraction                 | 0.0338       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.397       |\n",
      "|    explained_variance            | 0.828        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 330          |\n",
      "|    n_updates                     | 3530         |\n",
      "|    policy_gradient_loss          | -0.000705    |\n",
      "|    value_loss                    | 1.24e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 355          |\n",
      "|    time_elapsed                  | 32997        |\n",
      "|    total_timesteps               | 1454080      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0032274225 |\n",
      "|    clip_fraction                 | 0.0229       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.388       |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 580          |\n",
      "|    n_updates                     | 3540         |\n",
      "|    policy_gradient_loss          | 0.0017       |\n",
      "|    value_loss                    | 1.32e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1200.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 356          |\n",
      "|    time_elapsed                  | 33093        |\n",
      "|    total_timesteps               | 1458176      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0024249752 |\n",
      "|    clip_fraction                 | 0.0197       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.403       |\n",
      "|    explained_variance            | 0.833        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 304          |\n",
      "|    n_updates                     | 3550         |\n",
      "|    policy_gradient_loss          | -0.000599    |\n",
      "|    value_loss                    | 1.37e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 357          |\n",
      "|    time_elapsed                  | 33189        |\n",
      "|    total_timesteps               | 1462272      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0026425635 |\n",
      "|    clip_fraction                 | 0.0218       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.4         |\n",
      "|    explained_variance            | 0.827        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 369          |\n",
      "|    n_updates                     | 3560         |\n",
      "|    policy_gradient_loss          | -0.000767    |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1080.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 358          |\n",
      "|    time_elapsed                  | 33285        |\n",
      "|    total_timesteps               | 1466368      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0034502652 |\n",
      "|    clip_fraction                 | 0.026        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.408       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 461          |\n",
      "|    n_updates                     | 3570         |\n",
      "|    policy_gradient_loss          | 0.000294     |\n",
      "|    value_loss                    | 1.46e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1120.0      |\n",
      "|    intervention_sum              | 16           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 359          |\n",
      "|    time_elapsed                  | 33380        |\n",
      "|    total_timesteps               | 1470464      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0043460615 |\n",
      "|    clip_fraction                 | 0.0374       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.404       |\n",
      "|    explained_variance            | 0.818        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 657          |\n",
      "|    n_updates                     | 3580         |\n",
      "|    policy_gradient_loss          | 1.46e-05     |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1180.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 360          |\n",
      "|    time_elapsed                  | 33477        |\n",
      "|    total_timesteps               | 1474560      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0044228104 |\n",
      "|    clip_fraction                 | 0.0269       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.416       |\n",
      "|    explained_variance            | 0.791        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 423          |\n",
      "|    n_updates                     | 3590         |\n",
      "|    policy_gradient_loss          | 0.000678     |\n",
      "|    value_loss                    | 1.41e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 361          |\n",
      "|    time_elapsed                  | 33574        |\n",
      "|    total_timesteps               | 1478656      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0041863034 |\n",
      "|    clip_fraction                 | 0.0326       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.413       |\n",
      "|    explained_variance            | 0.785        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 471          |\n",
      "|    n_updates                     | 3600         |\n",
      "|    policy_gradient_loss          | -0.000718    |\n",
      "|    value_loss                    | 1.43e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -880.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 36          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 362         |\n",
      "|    time_elapsed                  | 33670       |\n",
      "|    total_timesteps               | 1482752     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004164935 |\n",
      "|    clip_fraction                 | 0.0345      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.411      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 310         |\n",
      "|    n_updates                     | 3610        |\n",
      "|    policy_gradient_loss          | -0.000767   |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1360.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 44         |\n",
      "|    iterations                    | 363        |\n",
      "|    time_elapsed                  | 33765      |\n",
      "|    total_timesteps               | 1486848    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00550448 |\n",
      "|    clip_fraction                 | 0.0477     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.413     |\n",
      "|    explained_variance            | 0.822      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 290        |\n",
      "|    n_updates                     | 3620       |\n",
      "|    policy_gradient_loss          | 0.000562   |\n",
      "|    value_loss                    | 1.25e+03   |\n",
      "-------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1480.0      |\n",
      "|    intervention_sum              | 24           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 364          |\n",
      "|    time_elapsed                  | 33862        |\n",
      "|    total_timesteps               | 1490944      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0047969245 |\n",
      "|    clip_fraction                 | 0.0379       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.421       |\n",
      "|    explained_variance            | 0.772        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 528          |\n",
      "|    n_updates                     | 3630         |\n",
      "|    policy_gradient_loss          | -0.000272    |\n",
      "|    value_loss                    | 1.3e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 365         |\n",
      "|    time_elapsed                  | 33958       |\n",
      "|    total_timesteps               | 1495040     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004181292 |\n",
      "|    clip_fraction                 | 0.0294      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.426      |\n",
      "|    explained_variance            | 0.78        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 351         |\n",
      "|    n_updates                     | 3640        |\n",
      "|    policy_gradient_loss          | 7.68e-05    |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1060.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 44          |\n",
      "|    iterations                    | 366         |\n",
      "|    time_elapsed                  | 34054       |\n",
      "|    total_timesteps               | 1499136     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007944619 |\n",
      "|    clip_fraction                 | 0.0695      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.419      |\n",
      "|    explained_variance            | 0.812       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 304         |\n",
      "|    n_updates                     | 3650        |\n",
      "|    policy_gradient_loss          | 0.00236     |\n",
      "|    value_loss                    | 1.12e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1500000_steps.zip\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1160.0      |\n",
      "|    intervention_sum              | 15           |\n",
      "|    nl_comm_sum                   | 56           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 367          |\n",
      "|    time_elapsed                  | 34150        |\n",
      "|    total_timesteps               | 1503232      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0051446124 |\n",
      "|    clip_fraction                 | 0.0427       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.423       |\n",
      "|    explained_variance            | 0.831        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 252          |\n",
      "|    n_updates                     | 3660         |\n",
      "|    policy_gradient_loss          | -0.000639    |\n",
      "|    value_loss                    | 1.01e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 368          |\n",
      "|    time_elapsed                  | 34246        |\n",
      "|    total_timesteps               | 1507328      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0048578987 |\n",
      "|    clip_fraction                 | 0.0382       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.424       |\n",
      "|    explained_variance            | 0.79         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 369          |\n",
      "|    n_updates                     | 3670         |\n",
      "|    policy_gradient_loss          | 0.00231      |\n",
      "|    value_loss                    | 1.31e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 369          |\n",
      "|    time_elapsed                  | 34342        |\n",
      "|    total_timesteps               | 1511424      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0042271707 |\n",
      "|    clip_fraction                 | 0.0314       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.429       |\n",
      "|    explained_variance            | 0.85         |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 238          |\n",
      "|    n_updates                     | 3680         |\n",
      "|    policy_gradient_loss          | -0.00077     |\n",
      "|    value_loss                    | 952          |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 20           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 370          |\n",
      "|    time_elapsed                  | 34437        |\n",
      "|    total_timesteps               | 1515520      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0031051198 |\n",
      "|    clip_fraction                 | 0.0262       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.447       |\n",
      "|    explained_variance            | 0.789        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 483          |\n",
      "|    n_updates                     | 3690         |\n",
      "|    policy_gradient_loss          | 0.00109      |\n",
      "|    value_loss                    | 1.43e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 44           |\n",
      "|    iterations                    | 371          |\n",
      "|    time_elapsed                  | 34533        |\n",
      "|    total_timesteps               | 1519616      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0056350036 |\n",
      "|    clip_fraction                 | 0.0426       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.438       |\n",
      "|    explained_variance            | 0.805        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 470          |\n",
      "|    n_updates                     | 3700         |\n",
      "|    policy_gradient_loss          | 0.000562     |\n",
      "|    value_loss                    | 1.35e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 372          |\n",
      "|    time_elapsed                  | 34629        |\n",
      "|    total_timesteps               | 1523712      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0053033507 |\n",
      "|    clip_fraction                 | 0.0427       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.442       |\n",
      "|    explained_variance            | 0.814        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 379          |\n",
      "|    n_updates                     | 3710         |\n",
      "|    policy_gradient_loss          | 0.000942     |\n",
      "|    value_loss                    | 1.36e+03     |\n",
      "---------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1080.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 40         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 373        |\n",
      "|    time_elapsed                  | 34726      |\n",
      "|    total_timesteps               | 1527808    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.00831137 |\n",
      "|    clip_fraction                 | 0.0526     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.457     |\n",
      "|    explained_variance            | 0.813      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 340        |\n",
      "|    n_updates                     | 3720       |\n",
      "|    policy_gradient_loss          | 0.000495   |\n",
      "|    value_loss                    | 1.18e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 374         |\n",
      "|    time_elapsed                  | 34821       |\n",
      "|    total_timesteps               | 1531904     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.005486767 |\n",
      "|    clip_fraction                 | 0.0446      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.459      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 426         |\n",
      "|    n_updates                     | 3730        |\n",
      "|    policy_gradient_loss          | 0.00136     |\n",
      "|    value_loss                    | 1.2e+03     |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 44           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 375          |\n",
      "|    time_elapsed                  | 34917        |\n",
      "|    total_timesteps               | 1536000      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0083793495 |\n",
      "|    clip_fraction                 | 0.0522       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.448       |\n",
      "|    explained_variance            | 0.788        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 205          |\n",
      "|    n_updates                     | 3740         |\n",
      "|    policy_gradient_loss          | 0.00334      |\n",
      "|    value_loss                    | 1.18e+03     |\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1360.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 376          |\n",
      "|    time_elapsed                  | 35013        |\n",
      "|    total_timesteps               | 1540096      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0070398464 |\n",
      "|    clip_fraction                 | 0.0415       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.461       |\n",
      "|    explained_variance            | 0.795        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 522          |\n",
      "|    n_updates                     | 3750         |\n",
      "|    policy_gradient_loss          | 0.000128     |\n",
      "|    value_loss                    | 1.17e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 377         |\n",
      "|    time_elapsed                  | 35110       |\n",
      "|    total_timesteps               | 1544192     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010086946 |\n",
      "|    clip_fraction                 | 0.071       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.478      |\n",
      "|    explained_variance            | 0.757       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 434         |\n",
      "|    n_updates                     | 3760        |\n",
      "|    policy_gradient_loss          | 0.00634     |\n",
      "|    value_loss                    | 1.43e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 378         |\n",
      "|    time_elapsed                  | 35207       |\n",
      "|    total_timesteps               | 1548288     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.004102694 |\n",
      "|    clip_fraction                 | 0.0283      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.476      |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 281         |\n",
      "|    n_updates                     | 3770        |\n",
      "|    policy_gradient_loss          | 0.00119     |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 379         |\n",
      "|    time_elapsed                  | 35302       |\n",
      "|    total_timesteps               | 1552384     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010627622 |\n",
      "|    clip_fraction                 | 0.0651      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.497      |\n",
      "|    explained_variance            | 0.769       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 542         |\n",
      "|    n_updates                     | 3780        |\n",
      "|    policy_gradient_loss          | 0.00313     |\n",
      "|    value_loss                    | 1.49e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1300.0      |\n",
      "|    intervention_sum              | 22           |\n",
      "|    nl_comm_sum                   | 42           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 380          |\n",
      "|    time_elapsed                  | 35399        |\n",
      "|    total_timesteps               | 1556480      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0063632606 |\n",
      "|    clip_fraction                 | 0.0341       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.483       |\n",
      "|    explained_variance            | 0.808        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 360          |\n",
      "|    n_updates                     | 3790         |\n",
      "|    policy_gradient_loss          | 0.00283      |\n",
      "|    value_loss                    | 1.19e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 381         |\n",
      "|    time_elapsed                  | 35496       |\n",
      "|    total_timesteps               | 1560576     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025010211 |\n",
      "|    clip_fraction                 | 0.111       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.495      |\n",
      "|    explained_variance            | 0.773       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 399         |\n",
      "|    n_updates                     | 3800        |\n",
      "|    policy_gradient_loss          | 0.0108      |\n",
      "|    value_loss                    | 1.45e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1620.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 382         |\n",
      "|    time_elapsed                  | 35592       |\n",
      "|    total_timesteps               | 1564672     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014787869 |\n",
      "|    clip_fraction                 | 0.0684      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.512      |\n",
      "|    explained_variance            | 0.755       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 301         |\n",
      "|    n_updates                     | 3810        |\n",
      "|    policy_gradient_loss          | 0.00614     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 383         |\n",
      "|    time_elapsed                  | 35687       |\n",
      "|    total_timesteps               | 1568768     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011586204 |\n",
      "|    clip_fraction                 | 0.0658      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.539      |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 446         |\n",
      "|    n_updates                     | 3820        |\n",
      "|    policy_gradient_loss          | 0.00176     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 384         |\n",
      "|    time_elapsed                  | 35784       |\n",
      "|    total_timesteps               | 1572864     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011343967 |\n",
      "|    clip_fraction                 | 0.0695      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.54       |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 578         |\n",
      "|    n_updates                     | 3830        |\n",
      "|    policy_gradient_loss          | 0.00367     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 385         |\n",
      "|    time_elapsed                  | 35881       |\n",
      "|    total_timesteps               | 1576960     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024027571 |\n",
      "|    clip_fraction                 | 0.101       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.518      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 485         |\n",
      "|    n_updates                     | 3840        |\n",
      "|    policy_gradient_loss          | 0.00796     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 386         |\n",
      "|    time_elapsed                  | 35977       |\n",
      "|    total_timesteps               | 1581056     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022210386 |\n",
      "|    clip_fraction                 | 0.0978      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.519      |\n",
      "|    explained_variance            | 0.785       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 445         |\n",
      "|    n_updates                     | 3850        |\n",
      "|    policy_gradient_loss          | 0.00604     |\n",
      "|    value_loss                    | 1.6e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1420.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 387        |\n",
      "|    time_elapsed                  | 36072      |\n",
      "|    total_timesteps               | 1585152    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01959654 |\n",
      "|    clip_fraction                 | 0.1        |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.527     |\n",
      "|    explained_variance            | 0.759      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 558        |\n",
      "|    n_updates                     | 3860       |\n",
      "|    policy_gradient_loss          | 0.00992    |\n",
      "|    value_loss                    | 1.79e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 388         |\n",
      "|    time_elapsed                  | 36168       |\n",
      "|    total_timesteps               | 1589248     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013673513 |\n",
      "|    clip_fraction                 | 0.0773      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.602      |\n",
      "|    explained_variance            | 0.779       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 577         |\n",
      "|    n_updates                     | 3870        |\n",
      "|    policy_gradient_loss          | 0.00701     |\n",
      "|    value_loss                    | 1.81e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 389         |\n",
      "|    time_elapsed                  | 36266       |\n",
      "|    total_timesteps               | 1593344     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013923384 |\n",
      "|    clip_fraction                 | 0.0996      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.626      |\n",
      "|    explained_variance            | 0.742       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 653         |\n",
      "|    n_updates                     | 3880        |\n",
      "|    policy_gradient_loss          | 0.00664     |\n",
      "|    value_loss                    | 1.59e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1040.0    |\n",
      "|    intervention_sum              | 14         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 390        |\n",
      "|    time_elapsed                  | 36363      |\n",
      "|    total_timesteps               | 1597440    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01294628 |\n",
      "|    clip_fraction                 | 0.091      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.648     |\n",
      "|    explained_variance            | 0.707      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 517        |\n",
      "|    n_updates                     | 3890       |\n",
      "|    policy_gradient_loss          | 0.00537    |\n",
      "|    value_loss                    | 1.76e+03   |\n",
      "-------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1600000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 391         |\n",
      "|    time_elapsed                  | 36458       |\n",
      "|    total_timesteps               | 1601536     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015419784 |\n",
      "|    clip_fraction                 | 0.101       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.71       |\n",
      "|    explained_variance            | 0.732       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 530         |\n",
      "|    n_updates                     | 3900        |\n",
      "|    policy_gradient_loss          | 0.0069      |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 392         |\n",
      "|    time_elapsed                  | 36554       |\n",
      "|    total_timesteps               | 1605632     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021920085 |\n",
      "|    clip_fraction                 | 0.118       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.748      |\n",
      "|    explained_variance            | 0.729       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 772         |\n",
      "|    n_updates                     | 3910        |\n",
      "|    policy_gradient_loss          | 0.00897     |\n",
      "|    value_loss                    | 1.84e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 393         |\n",
      "|    time_elapsed                  | 36651       |\n",
      "|    total_timesteps               | 1609728     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018025385 |\n",
      "|    clip_fraction                 | 0.108       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.782      |\n",
      "|    explained_variance            | 0.73        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 670         |\n",
      "|    n_updates                     | 3920        |\n",
      "|    policy_gradient_loss          | 0.00859     |\n",
      "|    value_loss                    | 1.7e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 394         |\n",
      "|    time_elapsed                  | 36748       |\n",
      "|    total_timesteps               | 1613824     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.031087019 |\n",
      "|    clip_fraction                 | 0.142       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.734      |\n",
      "|    explained_variance            | 0.736       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 868         |\n",
      "|    n_updates                     | 3930        |\n",
      "|    policy_gradient_loss          | 0.0218      |\n",
      "|    value_loss                    | 1.67e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1680.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 395         |\n",
      "|    time_elapsed                  | 36843       |\n",
      "|    total_timesteps               | 1617920     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014799345 |\n",
      "|    clip_fraction                 | 0.109       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.745      |\n",
      "|    explained_variance            | 0.716       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 634         |\n",
      "|    n_updates                     | 3940        |\n",
      "|    policy_gradient_loss          | 0.00833     |\n",
      "|    value_loss                    | 2.02e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 396         |\n",
      "|    time_elapsed                  | 36939       |\n",
      "|    total_timesteps               | 1622016     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022431895 |\n",
      "|    clip_fraction                 | 0.147       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.815      |\n",
      "|    explained_variance            | 0.667       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 778         |\n",
      "|    n_updates                     | 3950        |\n",
      "|    policy_gradient_loss          | 0.0119      |\n",
      "|    value_loss                    | 2e+03       |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1560.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 397         |\n",
      "|    time_elapsed                  | 37036       |\n",
      "|    total_timesteps               | 1626112     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028343314 |\n",
      "|    clip_fraction                 | 0.153       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.781      |\n",
      "|    explained_variance            | 0.725       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 996         |\n",
      "|    n_updates                     | 3960        |\n",
      "|    policy_gradient_loss          | 0.0115      |\n",
      "|    value_loss                    | 1.84e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1640.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 398         |\n",
      "|    time_elapsed                  | 37132       |\n",
      "|    total_timesteps               | 1630208     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018141521 |\n",
      "|    clip_fraction                 | 0.121       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.82       |\n",
      "|    explained_variance            | 0.766       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 506         |\n",
      "|    n_updates                     | 3970        |\n",
      "|    policy_gradient_loss          | 0.0103      |\n",
      "|    value_loss                    | 1.8e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 78          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 399         |\n",
      "|    time_elapsed                  | 37228       |\n",
      "|    total_timesteps               | 1634304     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016979594 |\n",
      "|    clip_fraction                 | 0.121       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.79       |\n",
      "|    explained_variance            | 0.757       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 590         |\n",
      "|    n_updates                     | 3980        |\n",
      "|    policy_gradient_loss          | 0.00902     |\n",
      "|    value_loss                    | 1.95e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1800.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 80          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 400         |\n",
      "|    time_elapsed                  | 37325       |\n",
      "|    total_timesteps               | 1638400     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026115768 |\n",
      "|    clip_fraction                 | 0.125       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.809      |\n",
      "|    explained_variance            | 0.762       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 877         |\n",
      "|    n_updates                     | 3990        |\n",
      "|    policy_gradient_loss          | 0.0138      |\n",
      "|    value_loss                    | 2.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 401         |\n",
      "|    time_elapsed                  | 37425       |\n",
      "|    total_timesteps               | 1642496     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.033209376 |\n",
      "|    clip_fraction                 | 0.16        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.789      |\n",
      "|    explained_variance            | 0.703       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 659         |\n",
      "|    n_updates                     | 4000        |\n",
      "|    policy_gradient_loss          | 0.018       |\n",
      "|    value_loss                    | 2.03e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1820.0    |\n",
      "|    intervention_sum              | 26         |\n",
      "|    nl_comm_sum                   | 78         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 402        |\n",
      "|    time_elapsed                  | 37525      |\n",
      "|    total_timesteps               | 1646592    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01355079 |\n",
      "|    clip_fraction                 | 0.105      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.76      |\n",
      "|    explained_variance            | 0.784      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 871        |\n",
      "|    n_updates                     | 4010       |\n",
      "|    policy_gradient_loss          | 0.0102     |\n",
      "|    value_loss                    | 1.73e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 403         |\n",
      "|    time_elapsed                  | 37622       |\n",
      "|    total_timesteps               | 1650688     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017927796 |\n",
      "|    clip_fraction                 | 0.119       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.825      |\n",
      "|    explained_variance            | 0.787       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 685         |\n",
      "|    n_updates                     | 4020        |\n",
      "|    policy_gradient_loss          | 0.0104      |\n",
      "|    value_loss                    | 1.94e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1800.0     |\n",
      "|    intervention_sum              | 27          |\n",
      "|    nl_comm_sum                   | 72          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 404         |\n",
      "|    time_elapsed                  | 37718       |\n",
      "|    total_timesteps               | 1654784     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.041886203 |\n",
      "|    clip_fraction                 | 0.149       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.851      |\n",
      "|    explained_variance            | 0.753       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 881         |\n",
      "|    n_updates                     | 4030        |\n",
      "|    policy_gradient_loss          | 0.0155      |\n",
      "|    value_loss                    | 2.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1720.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 405         |\n",
      "|    time_elapsed                  | 37814       |\n",
      "|    total_timesteps               | 1658880     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023057386 |\n",
      "|    clip_fraction                 | 0.135       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.818      |\n",
      "|    explained_variance            | 0.788       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 519         |\n",
      "|    n_updates                     | 4040        |\n",
      "|    policy_gradient_loss          | 0.0134      |\n",
      "|    value_loss                    | 1.77e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 406         |\n",
      "|    time_elapsed                  | 37910       |\n",
      "|    total_timesteps               | 1662976     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023283955 |\n",
      "|    clip_fraction                 | 0.139       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.785      |\n",
      "|    explained_variance            | 0.745       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 807         |\n",
      "|    n_updates                     | 4050        |\n",
      "|    policy_gradient_loss          | 0.0105      |\n",
      "|    value_loss                    | 1.9e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 78          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 407         |\n",
      "|    time_elapsed                  | 38006       |\n",
      "|    total_timesteps               | 1667072     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032492004 |\n",
      "|    clip_fraction                 | 0.131       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.778      |\n",
      "|    explained_variance            | 0.771       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 616         |\n",
      "|    n_updates                     | 4060        |\n",
      "|    policy_gradient_loss          | 0.0124      |\n",
      "|    value_loss                    | 1.74e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 408         |\n",
      "|    time_elapsed                  | 38102       |\n",
      "|    total_timesteps               | 1671168     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023959093 |\n",
      "|    clip_fraction                 | 0.118       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.774      |\n",
      "|    explained_variance            | 0.769       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 465         |\n",
      "|    n_updates                     | 4070        |\n",
      "|    policy_gradient_loss          | 0.00964     |\n",
      "|    value_loss                    | 1.72e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1580.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 409         |\n",
      "|    time_elapsed                  | 38198       |\n",
      "|    total_timesteps               | 1675264     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016146814 |\n",
      "|    clip_fraction                 | 0.106       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.745      |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 537         |\n",
      "|    n_updates                     | 4080        |\n",
      "|    policy_gradient_loss          | 0.00727     |\n",
      "|    value_loss                    | 1.62e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 410         |\n",
      "|    time_elapsed                  | 38294       |\n",
      "|    total_timesteps               | 1679360     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032001477 |\n",
      "|    clip_fraction                 | 0.118       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.741      |\n",
      "|    explained_variance            | 0.795       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 556         |\n",
      "|    n_updates                     | 4090        |\n",
      "|    policy_gradient_loss          | 0.0116      |\n",
      "|    value_loss                    | 1.86e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 82          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 411         |\n",
      "|    time_elapsed                  | 38390       |\n",
      "|    total_timesteps               | 1683456     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018479817 |\n",
      "|    clip_fraction                 | 0.111       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.719      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 508         |\n",
      "|    n_updates                     | 4100        |\n",
      "|    policy_gradient_loss          | 0.0149      |\n",
      "|    value_loss                    | 1.7e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 80          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 412         |\n",
      "|    time_elapsed                  | 38486       |\n",
      "|    total_timesteps               | 1687552     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021936346 |\n",
      "|    clip_fraction                 | 0.101       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.727      |\n",
      "|    explained_variance            | 0.776       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 487         |\n",
      "|    n_updates                     | 4110        |\n",
      "|    policy_gradient_loss          | 0.00915     |\n",
      "|    value_loss                    | 1.62e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 413         |\n",
      "|    time_elapsed                  | 38583       |\n",
      "|    total_timesteps               | 1691648     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022154763 |\n",
      "|    clip_fraction                 | 0.0982      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.73       |\n",
      "|    explained_variance            | 0.746       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 572         |\n",
      "|    n_updates                     | 4120        |\n",
      "|    policy_gradient_loss          | 0.00904     |\n",
      "|    value_loss                    | 1.52e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1660.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 82          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 414         |\n",
      "|    time_elapsed                  | 38678       |\n",
      "|    total_timesteps               | 1695744     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013646387 |\n",
      "|    clip_fraction                 | 0.0828      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.728      |\n",
      "|    explained_variance            | 0.777       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 518         |\n",
      "|    n_updates                     | 4130        |\n",
      "|    policy_gradient_loss          | 0.00548     |\n",
      "|    value_loss                    | 1.68e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 415         |\n",
      "|    time_elapsed                  | 38775       |\n",
      "|    total_timesteps               | 1699840     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016004175 |\n",
      "|    clip_fraction                 | 0.0928      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.736      |\n",
      "|    explained_variance            | 0.755       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 646         |\n",
      "|    n_updates                     | 4140        |\n",
      "|    policy_gradient_loss          | 0.00864     |\n",
      "|    value_loss                    | 1.64e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1700000_steps.zip\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1360.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 416        |\n",
      "|    time_elapsed                  | 38872      |\n",
      "|    total_timesteps               | 1703936    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01374042 |\n",
      "|    clip_fraction                 | 0.0742     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.707     |\n",
      "|    explained_variance            | 0.802      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 381        |\n",
      "|    n_updates                     | 4150       |\n",
      "|    policy_gradient_loss          | 0.00546    |\n",
      "|    value_loss                    | 1.87e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1240.0    |\n",
      "|    intervention_sum              | 15         |\n",
      "|    nl_comm_sum                   | 64         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 417        |\n",
      "|    time_elapsed                  | 38968      |\n",
      "|    total_timesteps               | 1708032    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02055614 |\n",
      "|    clip_fraction                 | 0.0837     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.698     |\n",
      "|    explained_variance            | 0.734      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 899        |\n",
      "|    n_updates                     | 4160       |\n",
      "|    policy_gradient_loss          | 0.00937    |\n",
      "|    value_loss                    | 2.08e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 418         |\n",
      "|    time_elapsed                  | 39063       |\n",
      "|    total_timesteps               | 1712128     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026966475 |\n",
      "|    clip_fraction                 | 0.131       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.72       |\n",
      "|    explained_variance            | 0.644       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 429         |\n",
      "|    n_updates                     | 4170        |\n",
      "|    policy_gradient_loss          | 0.0161      |\n",
      "|    value_loss                    | 1.73e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1340.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 50           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 419          |\n",
      "|    time_elapsed                  | 39160        |\n",
      "|    total_timesteps               | 1716224      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0132846795 |\n",
      "|    clip_fraction                 | 0.0739       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.665       |\n",
      "|    explained_variance            | 0.734        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 520          |\n",
      "|    n_updates                     | 4180         |\n",
      "|    policy_gradient_loss          | 0.00784      |\n",
      "|    value_loss                    | 1.68e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 86          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 420         |\n",
      "|    time_elapsed                  | 39258       |\n",
      "|    total_timesteps               | 1720320     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013848738 |\n",
      "|    clip_fraction                 | 0.0708      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.707      |\n",
      "|    explained_variance            | 0.757       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 523         |\n",
      "|    n_updates                     | 4190        |\n",
      "|    policy_gradient_loss          | 0.00375     |\n",
      "|    value_loss                    | 1.57e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1660.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 78         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 421        |\n",
      "|    time_elapsed                  | 39353      |\n",
      "|    total_timesteps               | 1724416    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01826654 |\n",
      "|    clip_fraction                 | 0.0982     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.674     |\n",
      "|    explained_variance            | 0.762      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 329        |\n",
      "|    n_updates                     | 4200       |\n",
      "|    policy_gradient_loss          | 0.00465    |\n",
      "|    value_loss                    | 1.45e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 80          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 422         |\n",
      "|    time_elapsed                  | 39449       |\n",
      "|    total_timesteps               | 1728512     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011527276 |\n",
      "|    clip_fraction                 | 0.0734      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.62       |\n",
      "|    explained_variance            | 0.792       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 523         |\n",
      "|    n_updates                     | 4210        |\n",
      "|    policy_gradient_loss          | 0.00332     |\n",
      "|    value_loss                    | 1.21e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 92          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 423         |\n",
      "|    time_elapsed                  | 39546       |\n",
      "|    total_timesteps               | 1732608     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014442341 |\n",
      "|    clip_fraction                 | 0.0767      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.687      |\n",
      "|    explained_variance            | 0.758       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 512         |\n",
      "|    n_updates                     | 4220        |\n",
      "|    policy_gradient_loss          | 0.00582     |\n",
      "|    value_loss                    | 1.46e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 424         |\n",
      "|    time_elapsed                  | 39644       |\n",
      "|    total_timesteps               | 1736704     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016730092 |\n",
      "|    clip_fraction                 | 0.0851      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.695      |\n",
      "|    explained_variance            | 0.772       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 646         |\n",
      "|    n_updates                     | 4230        |\n",
      "|    policy_gradient_loss          | 0.011       |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 425         |\n",
      "|    time_elapsed                  | 39739       |\n",
      "|    total_timesteps               | 1740800     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022743817 |\n",
      "|    clip_fraction                 | 0.0797      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.672      |\n",
      "|    explained_variance            | 0.783       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 511         |\n",
      "|    n_updates                     | 4240        |\n",
      "|    policy_gradient_loss          | 0.00325     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1480.0    |\n",
      "|    intervention_sum              | 24         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 426        |\n",
      "|    time_elapsed                  | 39835      |\n",
      "|    total_timesteps               | 1744896    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01399288 |\n",
      "|    clip_fraction                 | 0.0665     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.653     |\n",
      "|    explained_variance            | 0.768      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 512        |\n",
      "|    n_updates                     | 4250       |\n",
      "|    policy_gradient_loss          | 0.00447    |\n",
      "|    value_loss                    | 1.67e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1720.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 427         |\n",
      "|    time_elapsed                  | 39932       |\n",
      "|    total_timesteps               | 1748992     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018353214 |\n",
      "|    clip_fraction                 | 0.0894      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.665      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 657         |\n",
      "|    n_updates                     | 4260        |\n",
      "|    policy_gradient_loss          | 0.00621     |\n",
      "|    value_loss                    | 1.66e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 428         |\n",
      "|    time_elapsed                  | 40029       |\n",
      "|    total_timesteps               | 1753088     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019379204 |\n",
      "|    clip_fraction                 | 0.0997      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.695      |\n",
      "|    explained_variance            | 0.782       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 387         |\n",
      "|    n_updates                     | 4270        |\n",
      "|    policy_gradient_loss          | 0.00595     |\n",
      "|    value_loss                    | 1.64e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 429         |\n",
      "|    time_elapsed                  | 40125       |\n",
      "|    total_timesteps               | 1757184     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011033058 |\n",
      "|    clip_fraction                 | 0.0694      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.64       |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 635         |\n",
      "|    n_updates                     | 4280        |\n",
      "|    policy_gradient_loss          | 0.00157     |\n",
      "|    value_loss                    | 1.55e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1420.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 430        |\n",
      "|    time_elapsed                  | 40221      |\n",
      "|    total_timesteps               | 1761280    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02339099 |\n",
      "|    clip_fraction                 | 0.0831     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.71      |\n",
      "|    explained_variance            | 0.756      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 751        |\n",
      "|    n_updates                     | 4290       |\n",
      "|    policy_gradient_loss          | 0.00464    |\n",
      "|    value_loss                    | 1.78e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 431         |\n",
      "|    time_elapsed                  | 40318       |\n",
      "|    total_timesteps               | 1765376     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010288419 |\n",
      "|    clip_fraction                 | 0.0593      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.623      |\n",
      "|    explained_variance            | 0.805       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 574         |\n",
      "|    n_updates                     | 4300        |\n",
      "|    policy_gradient_loss          | 0.00277     |\n",
      "|    value_loss                    | 1.42e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1700.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 90          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 432         |\n",
      "|    time_elapsed                  | 40414       |\n",
      "|    total_timesteps               | 1769472     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018406574 |\n",
      "|    clip_fraction                 | 0.0873      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.642      |\n",
      "|    explained_variance            | 0.767       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 378         |\n",
      "|    n_updates                     | 4310        |\n",
      "|    policy_gradient_loss          | 0.00496     |\n",
      "|    value_loss                    | 1.46e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 433         |\n",
      "|    time_elapsed                  | 40510       |\n",
      "|    total_timesteps               | 1773568     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016925348 |\n",
      "|    clip_fraction                 | 0.0761      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.671      |\n",
      "|    explained_variance            | 0.762       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 597         |\n",
      "|    n_updates                     | 4320        |\n",
      "|    policy_gradient_loss          | 0.00406     |\n",
      "|    value_loss                    | 1.46e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 434         |\n",
      "|    time_elapsed                  | 40606       |\n",
      "|    total_timesteps               | 1777664     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020005057 |\n",
      "|    clip_fraction                 | 0.0839      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.682      |\n",
      "|    explained_variance            | 0.755       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 428         |\n",
      "|    n_updates                     | 4330        |\n",
      "|    policy_gradient_loss          | 0.0089      |\n",
      "|    value_loss                    | 1.58e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 435         |\n",
      "|    time_elapsed                  | 40705       |\n",
      "|    total_timesteps               | 1781760     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025228897 |\n",
      "|    clip_fraction                 | 0.102       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.625      |\n",
      "|    explained_variance            | 0.767       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 593         |\n",
      "|    n_updates                     | 4340        |\n",
      "|    policy_gradient_loss          | 0.0143      |\n",
      "|    value_loss                    | 1.42e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 436         |\n",
      "|    time_elapsed                  | 40801       |\n",
      "|    total_timesteps               | 1785856     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024310444 |\n",
      "|    clip_fraction                 | 0.0882      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.597      |\n",
      "|    explained_variance            | 0.789       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 661         |\n",
      "|    n_updates                     | 4350        |\n",
      "|    policy_gradient_loss          | 0.00534     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 437         |\n",
      "|    time_elapsed                  | 40898       |\n",
      "|    total_timesteps               | 1789952     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015844898 |\n",
      "|    clip_fraction                 | 0.0824      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.606      |\n",
      "|    explained_variance            | 0.784       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 431         |\n",
      "|    n_updates                     | 4360        |\n",
      "|    policy_gradient_loss          | 0.00721     |\n",
      "|    value_loss                    | 1.46e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -980.0      |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 438         |\n",
      "|    time_elapsed                  | 40994       |\n",
      "|    total_timesteps               | 1794048     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013928289 |\n",
      "|    clip_fraction                 | 0.0691      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.612      |\n",
      "|    explained_variance            | 0.78        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 346         |\n",
      "|    n_updates                     | 4370        |\n",
      "|    policy_gradient_loss          | 0.00383     |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 439         |\n",
      "|    time_elapsed                  | 41090       |\n",
      "|    total_timesteps               | 1798144     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014994547 |\n",
      "|    clip_fraction                 | 0.0803      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.593      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 385         |\n",
      "|    n_updates                     | 4380        |\n",
      "|    policy_gradient_loss          | 0.00282     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1800000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 440         |\n",
      "|    time_elapsed                  | 41187       |\n",
      "|    total_timesteps               | 1802240     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024164105 |\n",
      "|    clip_fraction                 | 0.0822      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.626      |\n",
      "|    explained_variance            | 0.779       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 400         |\n",
      "|    n_updates                     | 4390        |\n",
      "|    policy_gradient_loss          | 0.00583     |\n",
      "|    value_loss                    | 1.55e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 441         |\n",
      "|    time_elapsed                  | 41284       |\n",
      "|    total_timesteps               | 1806336     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015347961 |\n",
      "|    clip_fraction                 | 0.0812      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.628      |\n",
      "|    explained_variance            | 0.755       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 554         |\n",
      "|    n_updates                     | 4400        |\n",
      "|    policy_gradient_loss          | 0.00538     |\n",
      "|    value_loss                    | 1.6e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1540.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 66         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 442        |\n",
      "|    time_elapsed                  | 41380      |\n",
      "|    total_timesteps               | 1810432    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01319365 |\n",
      "|    clip_fraction                 | 0.0556     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.563     |\n",
      "|    explained_variance            | 0.794      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 383        |\n",
      "|    n_updates                     | 4410       |\n",
      "|    policy_gradient_loss          | 0.00342    |\n",
      "|    value_loss                    | 1.35e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1360.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 443        |\n",
      "|    time_elapsed                  | 41476      |\n",
      "|    total_timesteps               | 1814528    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02407365 |\n",
      "|    clip_fraction                 | 0.0857     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.588     |\n",
      "|    explained_variance            | 0.778      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 518        |\n",
      "|    n_updates                     | 4420       |\n",
      "|    policy_gradient_loss          | 0.00441    |\n",
      "|    value_loss                    | 1.47e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1600.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 72         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 444        |\n",
      "|    time_elapsed                  | 41572      |\n",
      "|    total_timesteps               | 1818624    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01815116 |\n",
      "|    clip_fraction                 | 0.0834     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.625     |\n",
      "|    explained_variance            | 0.79       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 343        |\n",
      "|    n_updates                     | 4430       |\n",
      "|    policy_gradient_loss          | 0.00482    |\n",
      "|    value_loss                    | 1.31e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 445         |\n",
      "|    time_elapsed                  | 41668       |\n",
      "|    total_timesteps               | 1822720     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025281586 |\n",
      "|    clip_fraction                 | 0.0757      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.596      |\n",
      "|    explained_variance            | 0.764       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 349         |\n",
      "|    n_updates                     | 4440        |\n",
      "|    policy_gradient_loss          | 0.00942     |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1700.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 446         |\n",
      "|    time_elapsed                  | 41765       |\n",
      "|    total_timesteps               | 1826816     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021559965 |\n",
      "|    clip_fraction                 | 0.0852      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.603      |\n",
      "|    explained_variance            | 0.753       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 603         |\n",
      "|    n_updates                     | 4450        |\n",
      "|    policy_gradient_loss          | 0.00475     |\n",
      "|    value_loss                    | 1.74e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1000.0     |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 447         |\n",
      "|    time_elapsed                  | 41862       |\n",
      "|    total_timesteps               | 1830912     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023454783 |\n",
      "|    clip_fraction                 | 0.0991      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.649      |\n",
      "|    explained_variance            | 0.777       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 502         |\n",
      "|    n_updates                     | 4460        |\n",
      "|    policy_gradient_loss          | 0.0117      |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 448         |\n",
      "|    time_elapsed                  | 41957       |\n",
      "|    total_timesteps               | 1835008     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025756916 |\n",
      "|    clip_fraction                 | 0.0654      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.568      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 445         |\n",
      "|    n_updates                     | 4470        |\n",
      "|    policy_gradient_loss          | 0.00299     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 449         |\n",
      "|    time_elapsed                  | 42054       |\n",
      "|    total_timesteps               | 1839104     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016210329 |\n",
      "|    clip_fraction                 | 0.0584      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.563      |\n",
      "|    explained_variance            | 0.793       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 408         |\n",
      "|    n_updates                     | 4480        |\n",
      "|    policy_gradient_loss          | 0.00911     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 450         |\n",
      "|    time_elapsed                  | 42151       |\n",
      "|    total_timesteps               | 1843200     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021261312 |\n",
      "|    clip_fraction                 | 0.0942      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.604      |\n",
      "|    explained_variance            | 0.774       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 281         |\n",
      "|    n_updates                     | 4490        |\n",
      "|    policy_gradient_loss          | 0.00753     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -960.0      |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 451         |\n",
      "|    time_elapsed                  | 42247       |\n",
      "|    total_timesteps               | 1847296     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016529534 |\n",
      "|    clip_fraction                 | 0.0744      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.537      |\n",
      "|    explained_variance            | 0.787       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 387         |\n",
      "|    n_updates                     | 4500        |\n",
      "|    policy_gradient_loss          | 0.00485     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 452         |\n",
      "|    time_elapsed                  | 42343       |\n",
      "|    total_timesteps               | 1851392     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017873049 |\n",
      "|    clip_fraction                 | 0.084       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.552      |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 495         |\n",
      "|    n_updates                     | 4510        |\n",
      "|    policy_gradient_loss          | 0.00533     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 453         |\n",
      "|    time_elapsed                  | 42439       |\n",
      "|    total_timesteps               | 1855488     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012932563 |\n",
      "|    clip_fraction                 | 0.0607      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.566      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 508         |\n",
      "|    n_updates                     | 4520        |\n",
      "|    policy_gradient_loss          | 0.00522     |\n",
      "|    value_loss                    | 1.56e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 454         |\n",
      "|    time_elapsed                  | 42536       |\n",
      "|    total_timesteps               | 1859584     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011021523 |\n",
      "|    clip_fraction                 | 0.0537      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.52       |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 375         |\n",
      "|    n_updates                     | 4530        |\n",
      "|    policy_gradient_loss          | 0.00407     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 455         |\n",
      "|    time_elapsed                  | 42632       |\n",
      "|    total_timesteps               | 1863680     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.034974482 |\n",
      "|    clip_fraction                 | 0.0654      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.544      |\n",
      "|    explained_variance            | 0.805       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 519         |\n",
      "|    n_updates                     | 4540        |\n",
      "|    policy_gradient_loss          | 0.00116     |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 456         |\n",
      "|    time_elapsed                  | 42727       |\n",
      "|    total_timesteps               | 1867776     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014847604 |\n",
      "|    clip_fraction                 | 0.062       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.55       |\n",
      "|    explained_variance            | 0.771       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 405         |\n",
      "|    n_updates                     | 4550        |\n",
      "|    policy_gradient_loss          | 0.00642     |\n",
      "|    value_loss                    | 1.53e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1460.0    |\n",
      "|    intervention_sum              | 20         |\n",
      "|    nl_comm_sum                   | 66         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 457        |\n",
      "|    time_elapsed                  | 42823      |\n",
      "|    total_timesteps               | 1871872    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02417183 |\n",
      "|    clip_fraction                 | 0.0618     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.567     |\n",
      "|    explained_variance            | 0.815      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 616        |\n",
      "|    n_updates                     | 4560       |\n",
      "|    policy_gradient_loss          | 0.00416    |\n",
      "|    value_loss                    | 1.44e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 458         |\n",
      "|    time_elapsed                  | 42920       |\n",
      "|    total_timesteps               | 1875968     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015176967 |\n",
      "|    clip_fraction                 | 0.0663      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.541      |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 243         |\n",
      "|    n_updates                     | 4570        |\n",
      "|    policy_gradient_loss          | 0.00468     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1680.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 72          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 459         |\n",
      "|    time_elapsed                  | 43017       |\n",
      "|    total_timesteps               | 1880064     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016509105 |\n",
      "|    clip_fraction                 | 0.0751      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.52       |\n",
      "|    explained_variance            | 0.786       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 497         |\n",
      "|    n_updates                     | 4580        |\n",
      "|    policy_gradient_loss          | 0.00432     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 460         |\n",
      "|    time_elapsed                  | 43112       |\n",
      "|    total_timesteps               | 1884160     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021011882 |\n",
      "|    clip_fraction                 | 0.0788      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.554      |\n",
      "|    explained_variance            | 0.801       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 411         |\n",
      "|    n_updates                     | 4590        |\n",
      "|    policy_gradient_loss          | 0.00285     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "------------------------------------------------\n",
      "| episode/                         |           |\n",
      "|    direct_capacity_violation_sum | 0         |\n",
      "|    final_reward                  | -1360.0   |\n",
      "|    intervention_sum              | 18        |\n",
      "|    nl_comm_sum                   | 64        |\n",
      "| time/                            |           |\n",
      "|    fps                           | 43        |\n",
      "|    iterations                    | 461       |\n",
      "|    time_elapsed                  | 43208     |\n",
      "|    total_timesteps               | 1888256   |\n",
      "| total/                           |           |\n",
      "|    truncated                     | 0         |\n",
      "| train/                           |           |\n",
      "|    approx_kl                     | 0.0180635 |\n",
      "|    clip_fraction                 | 0.0729    |\n",
      "|    clip_range                    | 0.2       |\n",
      "|    entropy_loss                  | -0.568    |\n",
      "|    explained_variance            | 0.776     |\n",
      "|    learning_rate                 | 0.0005    |\n",
      "|    loss                          | 427       |\n",
      "|    n_updates                     | 4600      |\n",
      "|    policy_gradient_loss          | 0.00682   |\n",
      "|    value_loss                    | 1.27e+03  |\n",
      "------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 462         |\n",
      "|    time_elapsed                  | 43306       |\n",
      "|    total_timesteps               | 1892352     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018260643 |\n",
      "|    clip_fraction                 | 0.0666      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.548      |\n",
      "|    explained_variance            | 0.813       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 467         |\n",
      "|    n_updates                     | 4610        |\n",
      "|    policy_gradient_loss          | 0.00298     |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 463         |\n",
      "|    time_elapsed                  | 43402       |\n",
      "|    total_timesteps               | 1896448     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016518679 |\n",
      "|    clip_fraction                 | 0.0563      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.53       |\n",
      "|    explained_variance            | 0.791       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 575         |\n",
      "|    n_updates                     | 4620        |\n",
      "|    policy_gradient_loss          | 0.00437     |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_1900000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 464         |\n",
      "|    time_elapsed                  | 43498       |\n",
      "|    total_timesteps               | 1900544     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010986295 |\n",
      "|    clip_fraction                 | 0.047       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.499      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 437         |\n",
      "|    n_updates                     | 4630        |\n",
      "|    policy_gradient_loss          | 0.00186     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 465         |\n",
      "|    time_elapsed                  | 43594       |\n",
      "|    total_timesteps               | 1904640     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016430737 |\n",
      "|    clip_fraction                 | 0.0637      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.537      |\n",
      "|    explained_variance            | 0.779       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 456         |\n",
      "|    n_updates                     | 4640        |\n",
      "|    policy_gradient_loss          | 0.00829     |\n",
      "|    value_loss                    | 1.48e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 466         |\n",
      "|    time_elapsed                  | 43691       |\n",
      "|    total_timesteps               | 1908736     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023350444 |\n",
      "|    clip_fraction                 | 0.0648      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.519      |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 392         |\n",
      "|    n_updates                     | 4650        |\n",
      "|    policy_gradient_loss          | 0.00447     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 467        |\n",
      "|    time_elapsed                  | 43787      |\n",
      "|    total_timesteps               | 1912832    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02436953 |\n",
      "|    clip_fraction                 | 0.083      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.547     |\n",
      "|    explained_variance            | 0.777      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 371        |\n",
      "|    n_updates                     | 4660       |\n",
      "|    policy_gradient_loss          | 0.00689    |\n",
      "|    value_loss                    | 1.51e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 468         |\n",
      "|    time_elapsed                  | 43884       |\n",
      "|    total_timesteps               | 1916928     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014711747 |\n",
      "|    clip_fraction                 | 0.0504      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.521      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 352         |\n",
      "|    n_updates                     | 4670        |\n",
      "|    policy_gradient_loss          | 0.00422     |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 469         |\n",
      "|    time_elapsed                  | 43980       |\n",
      "|    total_timesteps               | 1921024     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.027142614 |\n",
      "|    clip_fraction                 | 0.0756      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.542      |\n",
      "|    explained_variance            | 0.786       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 552         |\n",
      "|    n_updates                     | 4680        |\n",
      "|    policy_gradient_loss          | 0.00481     |\n",
      "|    value_loss                    | 1.5e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 470         |\n",
      "|    time_elapsed                  | 44076       |\n",
      "|    total_timesteps               | 1925120     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016162984 |\n",
      "|    clip_fraction                 | 0.0602      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.529      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 420         |\n",
      "|    n_updates                     | 4690        |\n",
      "|    policy_gradient_loss          | 0.00438     |\n",
      "|    value_loss                    | 1.52e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 471         |\n",
      "|    time_elapsed                  | 44173       |\n",
      "|    total_timesteps               | 1929216     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009520766 |\n",
      "|    clip_fraction                 | 0.0468      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.471      |\n",
      "|    explained_variance            | 0.825       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 411         |\n",
      "|    n_updates                     | 4700        |\n",
      "|    policy_gradient_loss          | 0.00254     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 472         |\n",
      "|    time_elapsed                  | 44268       |\n",
      "|    total_timesteps               | 1933312     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015558227 |\n",
      "|    clip_fraction                 | 0.0543      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.509      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 430         |\n",
      "|    n_updates                     | 4710        |\n",
      "|    policy_gradient_loss          | 0.0049      |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 473         |\n",
      "|    time_elapsed                  | 44365       |\n",
      "|    total_timesteps               | 1937408     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016890656 |\n",
      "|    clip_fraction                 | 0.0504      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.509      |\n",
      "|    explained_variance            | 0.752       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 434         |\n",
      "|    n_updates                     | 4720        |\n",
      "|    policy_gradient_loss          | 0.00433     |\n",
      "|    value_loss                    | 1.63e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1640.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 76         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 474        |\n",
      "|    time_elapsed                  | 44461      |\n",
      "|    total_timesteps               | 1941504    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01657961 |\n",
      "|    clip_fraction                 | 0.0589     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.526     |\n",
      "|    explained_variance            | 0.777      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 479        |\n",
      "|    n_updates                     | 4730       |\n",
      "|    policy_gradient_loss          | 0.0081     |\n",
      "|    value_loss                    | 1.49e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 475         |\n",
      "|    time_elapsed                  | 44557       |\n",
      "|    total_timesteps               | 1945600     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.031677544 |\n",
      "|    clip_fraction                 | 0.0737      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.516      |\n",
      "|    explained_variance            | 0.763       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 312         |\n",
      "|    n_updates                     | 4740        |\n",
      "|    policy_gradient_loss          | 0.00728     |\n",
      "|    value_loss                    | 1.5e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 476         |\n",
      "|    time_elapsed                  | 44653       |\n",
      "|    total_timesteps               | 1949696     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021327514 |\n",
      "|    clip_fraction                 | 0.0567      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.473      |\n",
      "|    explained_variance            | 0.792       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 512         |\n",
      "|    n_updates                     | 4750        |\n",
      "|    policy_gradient_loss          | 0.00541     |\n",
      "|    value_loss                    | 1.52e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 477         |\n",
      "|    time_elapsed                  | 44749       |\n",
      "|    total_timesteps               | 1953792     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013601337 |\n",
      "|    clip_fraction                 | 0.0448      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.483      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 542         |\n",
      "|    n_updates                     | 4760        |\n",
      "|    policy_gradient_loss          | 0.00239     |\n",
      "|    value_loss                    | 1.64e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1140.0    |\n",
      "|    intervention_sum              | 15         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 478        |\n",
      "|    time_elapsed                  | 44845      |\n",
      "|    total_timesteps               | 1957888    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01557539 |\n",
      "|    clip_fraction                 | 0.0524     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.512     |\n",
      "|    explained_variance            | 0.827      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 415        |\n",
      "|    n_updates                     | 4770       |\n",
      "|    policy_gradient_loss          | 0.00378    |\n",
      "|    value_loss                    | 1.35e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 479         |\n",
      "|    time_elapsed                  | 44942       |\n",
      "|    total_timesteps               | 1961984     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026248286 |\n",
      "|    clip_fraction                 | 0.0717      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.53       |\n",
      "|    explained_variance            | 0.817       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 319         |\n",
      "|    n_updates                     | 4780        |\n",
      "|    policy_gradient_loss          | 0.0058      |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 480         |\n",
      "|    time_elapsed                  | 45038       |\n",
      "|    total_timesteps               | 1966080     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014308935 |\n",
      "|    clip_fraction                 | 0.0579      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.52       |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 384         |\n",
      "|    n_updates                     | 4790        |\n",
      "|    policy_gradient_loss          | 0.00566     |\n",
      "|    value_loss                    | 1.45e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1440.0    |\n",
      "|    intervention_sum              | 20         |\n",
      "|    nl_comm_sum                   | 64         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 481        |\n",
      "|    time_elapsed                  | 45134      |\n",
      "|    total_timesteps               | 1970176    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01751114 |\n",
      "|    clip_fraction                 | 0.0532     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.527     |\n",
      "|    explained_variance            | 0.841      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 686        |\n",
      "|    n_updates                     | 4800       |\n",
      "|    policy_gradient_loss          | 0.00481    |\n",
      "|    value_loss                    | 1.37e+03   |\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "| episode/                         |           |\n",
      "|    direct_capacity_violation_sum | 0         |\n",
      "|    final_reward                  | -960.0    |\n",
      "|    intervention_sum              | 15        |\n",
      "|    nl_comm_sum                   | 36        |\n",
      "| time/                            |           |\n",
      "|    fps                           | 43        |\n",
      "|    iterations                    | 482       |\n",
      "|    time_elapsed                  | 45231     |\n",
      "|    total_timesteps               | 1974272   |\n",
      "| total/                           |           |\n",
      "|    truncated                     | 0         |\n",
      "| train/                           |           |\n",
      "|    approx_kl                     | 0.1211888 |\n",
      "|    clip_fraction                 | 0.0537    |\n",
      "|    clip_range                    | 0.2       |\n",
      "|    entropy_loss                  | -0.524    |\n",
      "|    explained_variance            | 0.78      |\n",
      "|    learning_rate                 | 0.0005    |\n",
      "|    loss                          | 346       |\n",
      "|    n_updates                     | 4810      |\n",
      "|    policy_gradient_loss          | 0.00318   |\n",
      "|    value_loss                    | 1.77e+03  |\n",
      "------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1000.0    |\n",
      "|    intervention_sum              | 12         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 483        |\n",
      "|    time_elapsed                  | 45327      |\n",
      "|    total_timesteps               | 1978368    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01304814 |\n",
      "|    clip_fraction                 | 0.0419     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.483     |\n",
      "|    explained_variance            | 0.792      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 764        |\n",
      "|    n_updates                     | 4820       |\n",
      "|    policy_gradient_loss          | 0.00223    |\n",
      "|    value_loss                    | 1.62e+03   |\n",
      "-------------------------------------------------\n",
      "-----------------------------------------------\n",
      "| episode/                         |          |\n",
      "|    direct_capacity_violation_sum | 0        |\n",
      "|    final_reward                  | -1320.0  |\n",
      "|    intervention_sum              | 20       |\n",
      "|    nl_comm_sum                   | 52       |\n",
      "| time/                            |          |\n",
      "|    fps                           | 43       |\n",
      "|    iterations                    | 484      |\n",
      "|    time_elapsed                  | 45423    |\n",
      "|    total_timesteps               | 1982464  |\n",
      "| total/                           |          |\n",
      "|    truncated                     | 0        |\n",
      "| train/                           |          |\n",
      "|    approx_kl                     | 0.021816 |\n",
      "|    clip_fraction                 | 0.062    |\n",
      "|    clip_range                    | 0.2      |\n",
      "|    entropy_loss                  | -0.508   |\n",
      "|    explained_variance            | 0.809    |\n",
      "|    learning_rate                 | 0.0005   |\n",
      "|    loss                          | 472      |\n",
      "|    n_updates                     | 4830     |\n",
      "|    policy_gradient_loss          | 0.00529  |\n",
      "|    value_loss                    | 1.47e+03 |\n",
      "-----------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 485        |\n",
      "|    time_elapsed                  | 45519      |\n",
      "|    total_timesteps               | 1986560    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01484333 |\n",
      "|    clip_fraction                 | 0.0395     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.478     |\n",
      "|    explained_variance            | 0.811      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 418        |\n",
      "|    n_updates                     | 4840       |\n",
      "|    policy_gradient_loss          | 0.00284    |\n",
      "|    value_loss                    | 1.46e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 486         |\n",
      "|    time_elapsed                  | 45616       |\n",
      "|    total_timesteps               | 1990656     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017004922 |\n",
      "|    clip_fraction                 | 0.0517      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.503      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 440         |\n",
      "|    n_updates                     | 4850        |\n",
      "|    policy_gradient_loss          | 0.00207     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -920.0     |\n",
      "|    intervention_sum              | 12         |\n",
      "|    nl_comm_sum                   | 44         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 487        |\n",
      "|    time_elapsed                  | 45711      |\n",
      "|    total_timesteps               | 1994752    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02037955 |\n",
      "|    clip_fraction                 | 0.0563     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.485     |\n",
      "|    explained_variance            | 0.82       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 501        |\n",
      "|    n_updates                     | 4860       |\n",
      "|    policy_gradient_loss          | 0.00572    |\n",
      "|    value_loss                    | 1.13e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1260.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 50         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 488        |\n",
      "|    time_elapsed                  | 45807      |\n",
      "|    total_timesteps               | 1998848    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03386937 |\n",
      "|    clip_fraction                 | 0.0606     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.514     |\n",
      "|    explained_variance            | 0.758      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 330        |\n",
      "|    n_updates                     | 4870       |\n",
      "|    policy_gradient_loss          | 0.00591    |\n",
      "|    value_loss                    | 1.42e+03   |\n",
      "-------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2000000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 489         |\n",
      "|    time_elapsed                  | 45904       |\n",
      "|    total_timesteps               | 2002944     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025740694 |\n",
      "|    clip_fraction                 | 0.0529      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.513      |\n",
      "|    explained_variance            | 0.781       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 439         |\n",
      "|    n_updates                     | 4880        |\n",
      "|    policy_gradient_loss          | 0.00997     |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1440.0      |\n",
      "|    intervention_sum              | 23           |\n",
      "|    nl_comm_sum                   | 52           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 490          |\n",
      "|    time_elapsed                  | 46000        |\n",
      "|    total_timesteps               | 2007040      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0118275415 |\n",
      "|    clip_fraction                 | 0.0439       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.497       |\n",
      "|    explained_variance            | 0.802        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 501          |\n",
      "|    n_updates                     | 4890         |\n",
      "|    policy_gradient_loss          | 0.00413      |\n",
      "|    value_loss                    | 1.32e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 491         |\n",
      "|    time_elapsed                  | 46095       |\n",
      "|    total_timesteps               | 2011136     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019724913 |\n",
      "|    clip_fraction                 | 0.0447      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.473      |\n",
      "|    explained_variance            | 0.795       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 407         |\n",
      "|    n_updates                     | 4900        |\n",
      "|    policy_gradient_loss          | 0.0023      |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 492         |\n",
      "|    time_elapsed                  | 46192       |\n",
      "|    total_timesteps               | 2015232     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012665062 |\n",
      "|    clip_fraction                 | 0.0303      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 679         |\n",
      "|    n_updates                     | 4910        |\n",
      "|    policy_gradient_loss          | 0.00138     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 493         |\n",
      "|    time_elapsed                  | 46288       |\n",
      "|    total_timesteps               | 2019328     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014914567 |\n",
      "|    clip_fraction                 | 0.0515      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.496      |\n",
      "|    explained_variance            | 0.81        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 534         |\n",
      "|    n_updates                     | 4920        |\n",
      "|    policy_gradient_loss          | 0.00218     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 494         |\n",
      "|    time_elapsed                  | 46385       |\n",
      "|    total_timesteps               | 2023424     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018859819 |\n",
      "|    clip_fraction                 | 0.0486      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.504      |\n",
      "|    explained_variance            | 0.821       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 335         |\n",
      "|    n_updates                     | 4930        |\n",
      "|    policy_gradient_loss          | 0.00466     |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 495         |\n",
      "|    time_elapsed                  | 46482       |\n",
      "|    total_timesteps               | 2027520     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014624019 |\n",
      "|    clip_fraction                 | 0.0563      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.466      |\n",
      "|    explained_variance            | 0.804       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 459         |\n",
      "|    n_updates                     | 4940        |\n",
      "|    policy_gradient_loss          | 0.00179     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 496         |\n",
      "|    time_elapsed                  | 46577       |\n",
      "|    total_timesteps               | 2031616     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014530626 |\n",
      "|    clip_fraction                 | 0.0392      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 295         |\n",
      "|    n_updates                     | 4950        |\n",
      "|    policy_gradient_loss          | 0.00291     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 497         |\n",
      "|    time_elapsed                  | 46675       |\n",
      "|    total_timesteps               | 2035712     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.033707425 |\n",
      "|    clip_fraction                 | 0.054       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.478      |\n",
      "|    explained_variance            | 0.753       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 472         |\n",
      "|    n_updates                     | 4960        |\n",
      "|    policy_gradient_loss          | 0.00331     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 72          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 498         |\n",
      "|    time_elapsed                  | 46772       |\n",
      "|    total_timesteps               | 2039808     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013677305 |\n",
      "|    clip_fraction                 | 0.0477      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.463      |\n",
      "|    explained_variance            | 0.812       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 740         |\n",
      "|    n_updates                     | 4970        |\n",
      "|    policy_gradient_loss          | 0.00134     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 499         |\n",
      "|    time_elapsed                  | 46867       |\n",
      "|    total_timesteps               | 2043904     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026792329 |\n",
      "|    clip_fraction                 | 0.0415      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.477      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 509         |\n",
      "|    n_updates                     | 4980        |\n",
      "|    policy_gradient_loss          | 0.00334     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 500         |\n",
      "|    time_elapsed                  | 46962       |\n",
      "|    total_timesteps               | 2048000     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009249143 |\n",
      "|    clip_fraction                 | 0.037       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.462      |\n",
      "|    explained_variance            | 0.81        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 689         |\n",
      "|    n_updates                     | 4990        |\n",
      "|    policy_gradient_loss          | 0.00282     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 501         |\n",
      "|    time_elapsed                  | 47060       |\n",
      "|    total_timesteps               | 2052096     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013300205 |\n",
      "|    clip_fraction                 | 0.0362      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.487      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 697         |\n",
      "|    n_updates                     | 5000        |\n",
      "|    policy_gradient_loss          | 0.0021      |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 72          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 502         |\n",
      "|    time_elapsed                  | 47156       |\n",
      "|    total_timesteps               | 2056192     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018078677 |\n",
      "|    clip_fraction                 | 0.051       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.517      |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 488         |\n",
      "|    n_updates                     | 5010        |\n",
      "|    policy_gradient_loss          | 0.0042      |\n",
      "|    value_loss                    | 1.48e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 503         |\n",
      "|    time_elapsed                  | 47251       |\n",
      "|    total_timesteps               | 2060288     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020766648 |\n",
      "|    clip_fraction                 | 0.0501      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.464      |\n",
      "|    explained_variance            | 0.841       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 636         |\n",
      "|    n_updates                     | 5020        |\n",
      "|    policy_gradient_loss          | 0.00662     |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 504         |\n",
      "|    time_elapsed                  | 47348       |\n",
      "|    total_timesteps               | 2064384     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019719476 |\n",
      "|    clip_fraction                 | 0.057       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.483      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 318         |\n",
      "|    n_updates                     | 5030        |\n",
      "|    policy_gradient_loss          | 0.00201     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 505         |\n",
      "|    time_elapsed                  | 47445       |\n",
      "|    total_timesteps               | 2068480     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006858629 |\n",
      "|    clip_fraction                 | 0.0356      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.462      |\n",
      "|    explained_variance            | 0.796       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 362         |\n",
      "|    n_updates                     | 5040        |\n",
      "|    policy_gradient_loss          | 0.000545    |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 506         |\n",
      "|    time_elapsed                  | 47541       |\n",
      "|    total_timesteps               | 2072576     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015716339 |\n",
      "|    clip_fraction                 | 0.0437      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.476      |\n",
      "|    explained_variance            | 0.819       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 316         |\n",
      "|    n_updates                     | 5050        |\n",
      "|    policy_gradient_loss          | 0.00681     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1260.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 507        |\n",
      "|    time_elapsed                  | 47637      |\n",
      "|    total_timesteps               | 2076672    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02672787 |\n",
      "|    clip_fraction                 | 0.0475     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.48      |\n",
      "|    explained_variance            | 0.794      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 570        |\n",
      "|    n_updates                     | 5060       |\n",
      "|    policy_gradient_loss          | 0.00628    |\n",
      "|    value_loss                    | 1.58e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 508         |\n",
      "|    time_elapsed                  | 47734       |\n",
      "|    total_timesteps               | 2080768     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018765893 |\n",
      "|    clip_fraction                 | 0.0377      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.453      |\n",
      "|    explained_variance            | 0.846       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 322         |\n",
      "|    n_updates                     | 5070        |\n",
      "|    policy_gradient_loss          | 0.00325     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 509         |\n",
      "|    time_elapsed                  | 47830       |\n",
      "|    total_timesteps               | 2084864     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012233465 |\n",
      "|    clip_fraction                 | 0.0341      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.459      |\n",
      "|    explained_variance            | 0.796       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 393         |\n",
      "|    n_updates                     | 5080        |\n",
      "|    policy_gradient_loss          | 0.00425     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 510         |\n",
      "|    time_elapsed                  | 47926       |\n",
      "|    total_timesteps               | 2088960     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013377129 |\n",
      "|    clip_fraction                 | 0.0412      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.464      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 542         |\n",
      "|    n_updates                     | 5090        |\n",
      "|    policy_gradient_loss          | 0.00225     |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1360.0    |\n",
      "|    intervention_sum              | 20         |\n",
      "|    nl_comm_sum                   | 56         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 511        |\n",
      "|    time_elapsed                  | 48023      |\n",
      "|    total_timesteps               | 2093056    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01719132 |\n",
      "|    clip_fraction                 | 0.0438     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.476     |\n",
      "|    explained_variance            | 0.831      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 595        |\n",
      "|    n_updates                     | 5100       |\n",
      "|    policy_gradient_loss          | 0.00253    |\n",
      "|    value_loss                    | 1.26e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 512         |\n",
      "|    time_elapsed                  | 48120       |\n",
      "|    total_timesteps               | 2097152     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013664622 |\n",
      "|    clip_fraction                 | 0.0457      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.461      |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 637         |\n",
      "|    n_updates                     | 5110        |\n",
      "|    policy_gradient_loss          | 0.0039      |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2100000_steps.zip\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1080.0    |\n",
      "|    intervention_sum              | 15         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 513        |\n",
      "|    time_elapsed                  | 48215      |\n",
      "|    total_timesteps               | 2101248    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01889784 |\n",
      "|    clip_fraction                 | 0.0378     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.461     |\n",
      "|    explained_variance            | 0.81       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 343        |\n",
      "|    n_updates                     | 5120       |\n",
      "|    policy_gradient_loss          | 0.00417    |\n",
      "|    value_loss                    | 1.43e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 514         |\n",
      "|    time_elapsed                  | 48311       |\n",
      "|    total_timesteps               | 2105344     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014477886 |\n",
      "|    clip_fraction                 | 0.0437      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.813       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 446         |\n",
      "|    n_updates                     | 5130        |\n",
      "|    policy_gradient_loss          | 0.00191     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 515         |\n",
      "|    time_elapsed                  | 48408       |\n",
      "|    total_timesteps               | 2109440     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.047625195 |\n",
      "|    clip_fraction                 | 0.0663      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.476      |\n",
      "|    explained_variance            | 0.809       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 427         |\n",
      "|    n_updates                     | 5140        |\n",
      "|    policy_gradient_loss          | 0.021       |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 516         |\n",
      "|    time_elapsed                  | 48504       |\n",
      "|    total_timesteps               | 2113536     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023768833 |\n",
      "|    clip_fraction                 | 0.0465      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.492      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 464         |\n",
      "|    n_updates                     | 5150        |\n",
      "|    policy_gradient_loss          | 0.00103     |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 517         |\n",
      "|    time_elapsed                  | 48600       |\n",
      "|    total_timesteps               | 2117632     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026018968 |\n",
      "|    clip_fraction                 | 0.0528      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.474      |\n",
      "|    explained_variance            | 0.816       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 338         |\n",
      "|    n_updates                     | 5160        |\n",
      "|    policy_gradient_loss          | 0.00748     |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -980.0       |\n",
      "|    intervention_sum              | 13           |\n",
      "|    nl_comm_sum                   | 46           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 518          |\n",
      "|    time_elapsed                  | 48696        |\n",
      "|    total_timesteps               | 2121728      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0144451205 |\n",
      "|    clip_fraction                 | 0.0416       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.473       |\n",
      "|    explained_variance            | 0.815        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 392          |\n",
      "|    n_updates                     | 5170         |\n",
      "|    policy_gradient_loss          | 0.00202      |\n",
      "|    value_loss                    | 1.48e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 519         |\n",
      "|    time_elapsed                  | 48792       |\n",
      "|    total_timesteps               | 2125824     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032551404 |\n",
      "|    clip_fraction                 | 0.057       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.486      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 564         |\n",
      "|    n_updates                     | 5180        |\n",
      "|    policy_gradient_loss          | 0.00534     |\n",
      "|    value_loss                    | 1.49e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 520         |\n",
      "|    time_elapsed                  | 48889       |\n",
      "|    total_timesteps               | 2129920     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.030871576 |\n",
      "|    clip_fraction                 | 0.0519      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.47       |\n",
      "|    explained_variance            | 0.843       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 474         |\n",
      "|    n_updates                     | 5190        |\n",
      "|    policy_gradient_loss          | 0.00758     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1580.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 521         |\n",
      "|    time_elapsed                  | 48985       |\n",
      "|    total_timesteps               | 2134016     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019955553 |\n",
      "|    clip_fraction                 | 0.0523      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.469      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 643         |\n",
      "|    n_updates                     | 5200        |\n",
      "|    policy_gradient_loss          | 0.000651    |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 522         |\n",
      "|    time_elapsed                  | 49082       |\n",
      "|    total_timesteps               | 2138112     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023648301 |\n",
      "|    clip_fraction                 | 0.0394      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.45       |\n",
      "|    explained_variance            | 0.817       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 608         |\n",
      "|    n_updates                     | 5210        |\n",
      "|    policy_gradient_loss          | 0.00296     |\n",
      "|    value_loss                    | 1.43e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1440.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 56         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 523        |\n",
      "|    time_elapsed                  | 49179      |\n",
      "|    total_timesteps               | 2142208    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01070256 |\n",
      "|    clip_fraction                 | 0.0311     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.442     |\n",
      "|    explained_variance            | 0.829      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 467        |\n",
      "|    n_updates                     | 5220       |\n",
      "|    policy_gradient_loss          | 0.0012     |\n",
      "|    value_loss                    | 1.32e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1000.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 524         |\n",
      "|    time_elapsed                  | 49276       |\n",
      "|    total_timesteps               | 2146304     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014370138 |\n",
      "|    clip_fraction                 | 0.0422      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.451      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 423         |\n",
      "|    n_updates                     | 5230        |\n",
      "|    policy_gradient_loss          | 0.00187     |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 525         |\n",
      "|    time_elapsed                  | 49372       |\n",
      "|    total_timesteps               | 2150400     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020638334 |\n",
      "|    clip_fraction                 | 0.0418      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.474      |\n",
      "|    explained_variance            | 0.837       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 364         |\n",
      "|    n_updates                     | 5240        |\n",
      "|    policy_gradient_loss          | 0.00306     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 526         |\n",
      "|    time_elapsed                  | 49467       |\n",
      "|    total_timesteps               | 2154496     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017603118 |\n",
      "|    clip_fraction                 | 0.0468      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.48       |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 362         |\n",
      "|    n_updates                     | 5250        |\n",
      "|    policy_gradient_loss          | 0.00651     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 527         |\n",
      "|    time_elapsed                  | 49564       |\n",
      "|    total_timesteps               | 2158592     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016885862 |\n",
      "|    clip_fraction                 | 0.0382      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.472      |\n",
      "|    explained_variance            | 0.857       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 284         |\n",
      "|    n_updates                     | 5260        |\n",
      "|    policy_gradient_loss          | 0.00652     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 528         |\n",
      "|    time_elapsed                  | 49660       |\n",
      "|    total_timesteps               | 2162688     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.027089315 |\n",
      "|    clip_fraction                 | 0.0545      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.442      |\n",
      "|    explained_variance            | 0.819       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 359         |\n",
      "|    n_updates                     | 5270        |\n",
      "|    policy_gradient_loss          | 0.00703     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 529         |\n",
      "|    time_elapsed                  | 49757       |\n",
      "|    total_timesteps               | 2166784     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023364713 |\n",
      "|    clip_fraction                 | 0.0437      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.46       |\n",
      "|    explained_variance            | 0.853       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 480         |\n",
      "|    n_updates                     | 5280        |\n",
      "|    policy_gradient_loss          | 0.00641     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 530         |\n",
      "|    time_elapsed                  | 49852       |\n",
      "|    total_timesteps               | 2170880     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015469246 |\n",
      "|    clip_fraction                 | 0.0409      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.459      |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 444         |\n",
      "|    n_updates                     | 5290        |\n",
      "|    policy_gradient_loss          | 0.00342     |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 531         |\n",
      "|    time_elapsed                  | 49948       |\n",
      "|    total_timesteps               | 2174976     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012385725 |\n",
      "|    clip_fraction                 | 0.0497      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.812       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 420         |\n",
      "|    n_updates                     | 5300        |\n",
      "|    policy_gradient_loss          | 0.00798     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 532         |\n",
      "|    time_elapsed                  | 50045       |\n",
      "|    total_timesteps               | 2179072     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013307912 |\n",
      "|    clip_fraction                 | 0.0383      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.458      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 344         |\n",
      "|    n_updates                     | 5310        |\n",
      "|    policy_gradient_loss          | 0.00329     |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 533         |\n",
      "|    time_elapsed                  | 50141       |\n",
      "|    total_timesteps               | 2183168     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018713314 |\n",
      "|    clip_fraction                 | 0.0382      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.462      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 429         |\n",
      "|    n_updates                     | 5320        |\n",
      "|    policy_gradient_loss          | 0.00509     |\n",
      "|    value_loss                    | 1.54e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 534         |\n",
      "|    time_elapsed                  | 50236       |\n",
      "|    total_timesteps               | 2187264     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021757567 |\n",
      "|    clip_fraction                 | 0.0469      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.426      |\n",
      "|    explained_variance            | 0.794       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.03e+03    |\n",
      "|    n_updates                     | 5330        |\n",
      "|    policy_gradient_loss          | 0.00363     |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1220.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 535        |\n",
      "|    time_elapsed                  | 50332      |\n",
      "|    total_timesteps               | 2191360    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02162464 |\n",
      "|    clip_fraction                 | 0.0443     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.448     |\n",
      "|    explained_variance            | 0.838      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 485        |\n",
      "|    n_updates                     | 5340       |\n",
      "|    policy_gradient_loss          | 0.001      |\n",
      "|    value_loss                    | 1.32e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 536         |\n",
      "|    time_elapsed                  | 50429       |\n",
      "|    total_timesteps               | 2195456     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010515079 |\n",
      "|    clip_fraction                 | 0.0528      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.434      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 509         |\n",
      "|    n_updates                     | 5350        |\n",
      "|    policy_gradient_loss          | 0.00384     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 537         |\n",
      "|    time_elapsed                  | 50527       |\n",
      "|    total_timesteps               | 2199552     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011840469 |\n",
      "|    clip_fraction                 | 0.0355      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.426      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 349         |\n",
      "|    n_updates                     | 5360        |\n",
      "|    policy_gradient_loss          | 0.000941    |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2200000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 538         |\n",
      "|    time_elapsed                  | 50623       |\n",
      "|    total_timesteps               | 2203648     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011458682 |\n",
      "|    clip_fraction                 | 0.0482      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.414      |\n",
      "|    explained_variance            | 0.805       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 525         |\n",
      "|    n_updates                     | 5370        |\n",
      "|    policy_gradient_loss          | 0.00301     |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 539         |\n",
      "|    time_elapsed                  | 50719       |\n",
      "|    total_timesteps               | 2207744     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010664844 |\n",
      "|    clip_fraction                 | 0.0331      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.423      |\n",
      "|    explained_variance            | 0.789       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 468         |\n",
      "|    n_updates                     | 5380        |\n",
      "|    policy_gradient_loss          | 0.0032      |\n",
      "|    value_loss                    | 1.47e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 540         |\n",
      "|    time_elapsed                  | 50816       |\n",
      "|    total_timesteps               | 2211840     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019929467 |\n",
      "|    clip_fraction                 | 0.0366      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.432      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 578         |\n",
      "|    n_updates                     | 5390        |\n",
      "|    policy_gradient_loss          | 0.0022      |\n",
      "|    value_loss                    | 1.21e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 541         |\n",
      "|    time_elapsed                  | 50913       |\n",
      "|    total_timesteps               | 2215936     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012334037 |\n",
      "|    clip_fraction                 | 0.0383      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.451      |\n",
      "|    explained_variance            | 0.83        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 311         |\n",
      "|    n_updates                     | 5400        |\n",
      "|    policy_gradient_loss          | 0.0016      |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 542         |\n",
      "|    time_elapsed                  | 51009       |\n",
      "|    total_timesteps               | 2220032     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014291054 |\n",
      "|    clip_fraction                 | 0.0392      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.428      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 479         |\n",
      "|    n_updates                     | 5410        |\n",
      "|    policy_gradient_loss          | 0.00326     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 543         |\n",
      "|    time_elapsed                  | 51105       |\n",
      "|    total_timesteps               | 2224128     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014187533 |\n",
      "|    clip_fraction                 | 0.0344      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.431      |\n",
      "|    explained_variance            | 0.83        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 475         |\n",
      "|    n_updates                     | 5420        |\n",
      "|    policy_gradient_loss          | 0.00458     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1300.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 46         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 544        |\n",
      "|    time_elapsed                  | 51202      |\n",
      "|    total_timesteps               | 2228224    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03243753 |\n",
      "|    clip_fraction                 | 0.0466     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.452     |\n",
      "|    explained_variance            | 0.825      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 388        |\n",
      "|    n_updates                     | 5430       |\n",
      "|    policy_gradient_loss          | 0.00257    |\n",
      "|    value_loss                    | 1.32e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 545         |\n",
      "|    time_elapsed                  | 51298       |\n",
      "|    total_timesteps               | 2232320     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012603052 |\n",
      "|    clip_fraction                 | 0.0377      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.416      |\n",
      "|    explained_variance            | 0.825       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 404         |\n",
      "|    n_updates                     | 5440        |\n",
      "|    policy_gradient_loss          | 0.00272     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 546         |\n",
      "|    time_elapsed                  | 51394       |\n",
      "|    total_timesteps               | 2236416     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024580028 |\n",
      "|    clip_fraction                 | 0.05        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.44       |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 447         |\n",
      "|    n_updates                     | 5450        |\n",
      "|    policy_gradient_loss          | 0.00464     |\n",
      "|    value_loss                    | 1.45e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 547         |\n",
      "|    time_elapsed                  | 51491       |\n",
      "|    total_timesteps               | 2240512     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010714888 |\n",
      "|    clip_fraction                 | 0.0354      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.438      |\n",
      "|    explained_variance            | 0.848       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 383         |\n",
      "|    n_updates                     | 5460        |\n",
      "|    policy_gradient_loss          | 0.00225     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1120.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 548        |\n",
      "|    time_elapsed                  | 51586      |\n",
      "|    total_timesteps               | 2244608    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01766292 |\n",
      "|    clip_fraction                 | 0.0432     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.429     |\n",
      "|    explained_variance            | 0.768      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 664        |\n",
      "|    n_updates                     | 5470       |\n",
      "|    policy_gradient_loss          | 0.00249    |\n",
      "|    value_loss                    | 1.48e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1240.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 549        |\n",
      "|    time_elapsed                  | 51683      |\n",
      "|    total_timesteps               | 2248704    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01792765 |\n",
      "|    clip_fraction                 | 0.0458     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.423     |\n",
      "|    explained_variance            | 0.839      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 359        |\n",
      "|    n_updates                     | 5480       |\n",
      "|    policy_gradient_loss          | 0.00385    |\n",
      "|    value_loss                    | 1.18e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 550         |\n",
      "|    time_elapsed                  | 51779       |\n",
      "|    total_timesteps               | 2252800     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019037358 |\n",
      "|    clip_fraction                 | 0.049       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.449      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 380         |\n",
      "|    n_updates                     | 5490        |\n",
      "|    policy_gradient_loss          | 0.00631     |\n",
      "|    value_loss                    | 1.45e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 551         |\n",
      "|    time_elapsed                  | 51875       |\n",
      "|    total_timesteps               | 2256896     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014136029 |\n",
      "|    clip_fraction                 | 0.0491      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.451      |\n",
      "|    explained_variance            | 0.842       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 402         |\n",
      "|    n_updates                     | 5500        |\n",
      "|    policy_gradient_loss          | 0.0033      |\n",
      "|    value_loss                    | 1.12e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1320.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 552        |\n",
      "|    time_elapsed                  | 51972      |\n",
      "|    total_timesteps               | 2260992    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02873254 |\n",
      "|    clip_fraction                 | 0.0626     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.47      |\n",
      "|    explained_variance            | 0.851      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 242        |\n",
      "|    n_updates                     | 5510       |\n",
      "|    policy_gradient_loss          | 0.00461    |\n",
      "|    value_loss                    | 1.03e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1640.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 553         |\n",
      "|    time_elapsed                  | 52068       |\n",
      "|    total_timesteps               | 2265088     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020264927 |\n",
      "|    clip_fraction                 | 0.0526      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.435      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 187         |\n",
      "|    n_updates                     | 5520        |\n",
      "|    policy_gradient_loss          | 0.00329     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 554         |\n",
      "|    time_elapsed                  | 52164       |\n",
      "|    total_timesteps               | 2269184     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025864303 |\n",
      "|    clip_fraction                 | 0.0554      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 489         |\n",
      "|    n_updates                     | 5530        |\n",
      "|    policy_gradient_loss          | 0.00254     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 555         |\n",
      "|    time_elapsed                  | 52261       |\n",
      "|    total_timesteps               | 2273280     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024170095 |\n",
      "|    clip_fraction                 | 0.0479      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.469      |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 349         |\n",
      "|    n_updates                     | 5540        |\n",
      "|    policy_gradient_loss          | 0.00566     |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 556         |\n",
      "|    time_elapsed                  | 52357       |\n",
      "|    total_timesteps               | 2277376     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025060587 |\n",
      "|    clip_fraction                 | 0.0456      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.844       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 330         |\n",
      "|    n_updates                     | 5550        |\n",
      "|    policy_gradient_loss          | 0.00399     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 557         |\n",
      "|    time_elapsed                  | 52452       |\n",
      "|    total_timesteps               | 2281472     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.045795538 |\n",
      "|    clip_fraction                 | 0.0736      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.453      |\n",
      "|    explained_variance            | 0.819       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 497         |\n",
      "|    n_updates                     | 5560        |\n",
      "|    policy_gradient_loss          | 0.0103      |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 558         |\n",
      "|    time_elapsed                  | 52549       |\n",
      "|    total_timesteps               | 2285568     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032455694 |\n",
      "|    clip_fraction                 | 0.0658      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.477      |\n",
      "|    explained_variance            | 0.809       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 443         |\n",
      "|    n_updates                     | 5570        |\n",
      "|    policy_gradient_loss          | 0.00625     |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1640.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 559         |\n",
      "|    time_elapsed                  | 52645       |\n",
      "|    total_timesteps               | 2289664     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.037865296 |\n",
      "|    clip_fraction                 | 0.0698      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.462      |\n",
      "|    explained_variance            | 0.754       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 654         |\n",
      "|    n_updates                     | 5580        |\n",
      "|    policy_gradient_loss          | 0.00963     |\n",
      "|    value_loss                    | 1.6e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 560         |\n",
      "|    time_elapsed                  | 52741       |\n",
      "|    total_timesteps               | 2293760     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017306052 |\n",
      "|    clip_fraction                 | 0.0451      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.456      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.42e+03    |\n",
      "|    n_updates                     | 5590        |\n",
      "|    policy_gradient_loss          | 0.00221     |\n",
      "|    value_loss                    | 1.71e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 561         |\n",
      "|    time_elapsed                  | 52836       |\n",
      "|    total_timesteps               | 2297856     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032432534 |\n",
      "|    clip_fraction                 | 0.061       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.451      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 397         |\n",
      "|    n_updates                     | 5600        |\n",
      "|    policy_gradient_loss          | 0.00798     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2300000_steps.zip\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1500.0    |\n",
      "|    intervention_sum              | 24         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 562        |\n",
      "|    time_elapsed                  | 52933      |\n",
      "|    total_timesteps               | 2301952    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.05634164 |\n",
      "|    clip_fraction                 | 0.0685     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.434     |\n",
      "|    explained_variance            | 0.787      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 474        |\n",
      "|    n_updates                     | 5610       |\n",
      "|    policy_gradient_loss          | 0.00563    |\n",
      "|    value_loss                    | 1.83e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 563         |\n",
      "|    time_elapsed                  | 53030       |\n",
      "|    total_timesteps               | 2306048     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026986085 |\n",
      "|    clip_fraction                 | 0.0413      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.431      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 317         |\n",
      "|    n_updates                     | 5620        |\n",
      "|    policy_gradient_loss          | 0.0063      |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -880.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 564         |\n",
      "|    time_elapsed                  | 53126       |\n",
      "|    total_timesteps               | 2310144     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023515444 |\n",
      "|    clip_fraction                 | 0.0561      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.455      |\n",
      "|    explained_variance            | 0.82        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 604         |\n",
      "|    n_updates                     | 5630        |\n",
      "|    policy_gradient_loss          | 0.0077      |\n",
      "|    value_loss                    | 1.54e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 565         |\n",
      "|    time_elapsed                  | 53221       |\n",
      "|    total_timesteps               | 2314240     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024722688 |\n",
      "|    clip_fraction                 | 0.0583      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.465      |\n",
      "|    explained_variance            | 0.798       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 509         |\n",
      "|    n_updates                     | 5640        |\n",
      "|    policy_gradient_loss          | 0.00938     |\n",
      "|    value_loss                    | 1.42e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 566         |\n",
      "|    time_elapsed                  | 53317       |\n",
      "|    total_timesteps               | 2318336     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009872773 |\n",
      "|    clip_fraction                 | 0.039       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.423      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 607         |\n",
      "|    n_updates                     | 5650        |\n",
      "|    policy_gradient_loss          | 0.00225     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 567         |\n",
      "|    time_elapsed                  | 53414       |\n",
      "|    total_timesteps               | 2322432     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023478076 |\n",
      "|    clip_fraction                 | 0.0543      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.446      |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 383         |\n",
      "|    n_updates                     | 5660        |\n",
      "|    policy_gradient_loss          | 0.00623     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1520.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 568         |\n",
      "|    time_elapsed                  | 53511       |\n",
      "|    total_timesteps               | 2326528     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014004023 |\n",
      "|    clip_fraction                 | 0.0448      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.414      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 523         |\n",
      "|    n_updates                     | 5670        |\n",
      "|    policy_gradient_loss          | 0.0032      |\n",
      "|    value_loss                    | 1.52e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 569         |\n",
      "|    time_elapsed                  | 53606       |\n",
      "|    total_timesteps               | 2330624     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020168971 |\n",
      "|    clip_fraction                 | 0.049       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.443      |\n",
      "|    explained_variance            | 0.81        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 436         |\n",
      "|    n_updates                     | 5680        |\n",
      "|    policy_gradient_loss          | 0.00239     |\n",
      "|    value_loss                    | 1.43e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 570         |\n",
      "|    time_elapsed                  | 53702       |\n",
      "|    total_timesteps               | 2334720     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013047611 |\n",
      "|    clip_fraction                 | 0.0397      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.447      |\n",
      "|    explained_variance            | 0.771       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 368         |\n",
      "|    n_updates                     | 5690        |\n",
      "|    policy_gradient_loss          | 0.00488     |\n",
      "|    value_loss                    | 1.59e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1320.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 60           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 571          |\n",
      "|    time_elapsed                  | 53799        |\n",
      "|    total_timesteps               | 2338816      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0133379605 |\n",
      "|    clip_fraction                 | 0.0454       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.444       |\n",
      "|    explained_variance            | 0.822        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 490          |\n",
      "|    n_updates                     | 5700         |\n",
      "|    policy_gradient_loss          | 0.00236      |\n",
      "|    value_loss                    | 1.26e+03     |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1100.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 572         |\n",
      "|    time_elapsed                  | 53896       |\n",
      "|    total_timesteps               | 2342912     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021761052 |\n",
      "|    clip_fraction                 | 0.039       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.429      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 389         |\n",
      "|    n_updates                     | 5710        |\n",
      "|    policy_gradient_loss          | 0.00167     |\n",
      "|    value_loss                    | 1.11e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 573         |\n",
      "|    time_elapsed                  | 53991       |\n",
      "|    total_timesteps               | 2347008     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020215692 |\n",
      "|    clip_fraction                 | 0.056       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.441      |\n",
      "|    explained_variance            | 0.813       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 436         |\n",
      "|    n_updates                     | 5720        |\n",
      "|    policy_gradient_loss          | 0.00116     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 574         |\n",
      "|    time_elapsed                  | 54088       |\n",
      "|    total_timesteps               | 2351104     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020610537 |\n",
      "|    clip_fraction                 | 0.0464      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.416      |\n",
      "|    explained_variance            | 0.814       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 670         |\n",
      "|    n_updates                     | 5730        |\n",
      "|    policy_gradient_loss          | 0.00337     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 575         |\n",
      "|    time_elapsed                  | 54186       |\n",
      "|    total_timesteps               | 2355200     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012871642 |\n",
      "|    clip_fraction                 | 0.0422      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.432      |\n",
      "|    explained_variance            | 0.861       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 414         |\n",
      "|    n_updates                     | 5740        |\n",
      "|    policy_gradient_loss          | 0.00201     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 576         |\n",
      "|    time_elapsed                  | 54282       |\n",
      "|    total_timesteps               | 2359296     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021183413 |\n",
      "|    clip_fraction                 | 0.0435      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.427      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 346         |\n",
      "|    n_updates                     | 5750        |\n",
      "|    policy_gradient_loss          | 0.00506     |\n",
      "|    value_loss                    | 1.61e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 577         |\n",
      "|    time_elapsed                  | 54378       |\n",
      "|    total_timesteps               | 2363392     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010772996 |\n",
      "|    clip_fraction                 | 0.0382      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.404      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 226         |\n",
      "|    n_updates                     | 5760        |\n",
      "|    policy_gradient_loss          | 0.00197     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1560.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 578         |\n",
      "|    time_elapsed                  | 54474       |\n",
      "|    total_timesteps               | 2367488     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009717533 |\n",
      "|    clip_fraction                 | 0.0367      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.397      |\n",
      "|    explained_variance            | 0.841       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 246         |\n",
      "|    n_updates                     | 5770        |\n",
      "|    policy_gradient_loss          | 0.0037      |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 579         |\n",
      "|    time_elapsed                  | 54570       |\n",
      "|    total_timesteps               | 2371584     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019701157 |\n",
      "|    clip_fraction                 | 0.0434      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.422      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 498         |\n",
      "|    n_updates                     | 5780        |\n",
      "|    policy_gradient_loss          | 0.00267     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 580         |\n",
      "|    time_elapsed                  | 54666       |\n",
      "|    total_timesteps               | 2375680     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012168963 |\n",
      "|    clip_fraction                 | 0.0425      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.392      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 986         |\n",
      "|    n_updates                     | 5790        |\n",
      "|    policy_gradient_loss          | 0.00263     |\n",
      "|    value_loss                    | 1.51e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 581         |\n",
      "|    time_elapsed                  | 54762       |\n",
      "|    total_timesteps               | 2379776     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014256421 |\n",
      "|    clip_fraction                 | 0.0399      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.394      |\n",
      "|    explained_variance            | 0.79        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 673         |\n",
      "|    n_updates                     | 5800        |\n",
      "|    policy_gradient_loss          | 0.00436     |\n",
      "|    value_loss                    | 1.72e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 582         |\n",
      "|    time_elapsed                  | 54858       |\n",
      "|    total_timesteps               | 2383872     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014298006 |\n",
      "|    clip_fraction                 | 0.0424      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.419      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 345         |\n",
      "|    n_updates                     | 5810        |\n",
      "|    policy_gradient_loss          | 0.00312     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 583         |\n",
      "|    time_elapsed                  | 54955       |\n",
      "|    total_timesteps               | 2387968     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015257616 |\n",
      "|    clip_fraction                 | 0.0469      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.425      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 448         |\n",
      "|    n_updates                     | 5820        |\n",
      "|    policy_gradient_loss          | 0.00227     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 584         |\n",
      "|    time_elapsed                  | 55051       |\n",
      "|    total_timesteps               | 2392064     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017655812 |\n",
      "|    clip_fraction                 | 0.0439      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.402      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 472         |\n",
      "|    n_updates                     | 5830        |\n",
      "|    policy_gradient_loss          | 0.00271     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 585         |\n",
      "|    time_elapsed                  | 55147       |\n",
      "|    total_timesteps               | 2396160     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011630824 |\n",
      "|    clip_fraction                 | 0.0324      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.436      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 492         |\n",
      "|    n_updates                     | 5840        |\n",
      "|    policy_gradient_loss          | 0.00368     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2400000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 25          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 586         |\n",
      "|    time_elapsed                  | 55243       |\n",
      "|    total_timesteps               | 2400256     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017344085 |\n",
      "|    clip_fraction                 | 0.046       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.41       |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 380         |\n",
      "|    n_updates                     | 5850        |\n",
      "|    policy_gradient_loss          | 0.0011      |\n",
      "|    value_loss                    | 1.1e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 587         |\n",
      "|    time_elapsed                  | 55339       |\n",
      "|    total_timesteps               | 2404352     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010116857 |\n",
      "|    clip_fraction                 | 0.0306      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.404      |\n",
      "|    explained_variance            | 0.832       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 363         |\n",
      "|    n_updates                     | 5860        |\n",
      "|    policy_gradient_loss          | 0.00171     |\n",
      "|    value_loss                    | 1.44e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 11          |\n",
      "|    nl_comm_sum                   | 96          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 588         |\n",
      "|    time_elapsed                  | 55435       |\n",
      "|    total_timesteps               | 2408448     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.006559863 |\n",
      "|    clip_fraction                 | 0.0329      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.396      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 344         |\n",
      "|    n_updates                     | 5870        |\n",
      "|    policy_gradient_loss          | 0.000556    |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 589         |\n",
      "|    time_elapsed                  | 55532       |\n",
      "|    total_timesteps               | 2412544     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023020161 |\n",
      "|    clip_fraction                 | 0.0441      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.413      |\n",
      "|    explained_variance            | 0.843       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 309         |\n",
      "|    n_updates                     | 5880        |\n",
      "|    policy_gradient_loss          | 0.000778    |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 590         |\n",
      "|    time_elapsed                  | 55628       |\n",
      "|    total_timesteps               | 2416640     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013129819 |\n",
      "|    clip_fraction                 | 0.0447      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.408      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 340         |\n",
      "|    n_updates                     | 5890        |\n",
      "|    policy_gradient_loss          | 0.00129     |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 591         |\n",
      "|    time_elapsed                  | 55724       |\n",
      "|    total_timesteps               | 2420736     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013261707 |\n",
      "|    clip_fraction                 | 0.0372      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.386      |\n",
      "|    explained_variance            | 0.845       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 366         |\n",
      "|    n_updates                     | 5900        |\n",
      "|    policy_gradient_loss          | 0.00382     |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "-----------------------------------------------\n",
      "| episode/                         |          |\n",
      "|    direct_capacity_violation_sum | 0        |\n",
      "|    final_reward                  | -1480.0  |\n",
      "|    intervention_sum              | 24       |\n",
      "|    nl_comm_sum                   | 52       |\n",
      "| time/                            |          |\n",
      "|    fps                           | 43       |\n",
      "|    iterations                    | 592      |\n",
      "|    time_elapsed                  | 55820    |\n",
      "|    total_timesteps               | 2424832  |\n",
      "| total/                           |          |\n",
      "|    truncated                     | 0        |\n",
      "| train/                           |          |\n",
      "|    approx_kl                     | 0.032143 |\n",
      "|    clip_fraction                 | 0.0404   |\n",
      "|    clip_range                    | 0.2      |\n",
      "|    entropy_loss                  | -0.425   |\n",
      "|    explained_variance            | 0.83     |\n",
      "|    learning_rate                 | 0.0005   |\n",
      "|    loss                          | 578      |\n",
      "|    n_updates                     | 5910     |\n",
      "|    policy_gradient_loss          | 0.00336  |\n",
      "|    value_loss                    | 1.35e+03 |\n",
      "-----------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 21           |\n",
      "|    nl_comm_sum                   | 38           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 593          |\n",
      "|    time_elapsed                  | 55917        |\n",
      "|    total_timesteps               | 2428928      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0143265575 |\n",
      "|    clip_fraction                 | 0.0423       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.411       |\n",
      "|    explained_variance            | 0.787        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 248          |\n",
      "|    n_updates                     | 5920         |\n",
      "|    policy_gradient_loss          | 0.00698      |\n",
      "|    value_loss                    | 1.4e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 594         |\n",
      "|    time_elapsed                  | 56013       |\n",
      "|    total_timesteps               | 2433024     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016180525 |\n",
      "|    clip_fraction                 | 0.0393      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.398      |\n",
      "|    explained_variance            | 0.814       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 351         |\n",
      "|    n_updates                     | 5930        |\n",
      "|    policy_gradient_loss          | 0.00104     |\n",
      "|    value_loss                    | 1.2e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 595         |\n",
      "|    time_elapsed                  | 56109       |\n",
      "|    total_timesteps               | 2437120     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009338879 |\n",
      "|    clip_fraction                 | 0.0311      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.405      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 426         |\n",
      "|    n_updates                     | 5940        |\n",
      "|    policy_gradient_loss          | 0.0023      |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 596         |\n",
      "|    time_elapsed                  | 56205       |\n",
      "|    total_timesteps               | 2441216     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015958328 |\n",
      "|    clip_fraction                 | 0.048       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.427      |\n",
      "|    explained_variance            | 0.815       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 383         |\n",
      "|    n_updates                     | 5950        |\n",
      "|    policy_gradient_loss          | 0.00331     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 597         |\n",
      "|    time_elapsed                  | 56301       |\n",
      "|    total_timesteps               | 2445312     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007875388 |\n",
      "|    clip_fraction                 | 0.0403      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.409      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 323         |\n",
      "|    n_updates                     | 5960        |\n",
      "|    policy_gradient_loss          | 0.00302     |\n",
      "|    value_loss                    | 1.16e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 598         |\n",
      "|    time_elapsed                  | 56398       |\n",
      "|    total_timesteps               | 2449408     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014026371 |\n",
      "|    clip_fraction                 | 0.0428      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.406      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 347         |\n",
      "|    n_updates                     | 5970        |\n",
      "|    policy_gradient_loss          | 0.00161     |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 599         |\n",
      "|    time_elapsed                  | 56494       |\n",
      "|    total_timesteps               | 2453504     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013182066 |\n",
      "|    clip_fraction                 | 0.0311      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.393      |\n",
      "|    explained_variance            | 0.816       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 266         |\n",
      "|    n_updates                     | 5980        |\n",
      "|    policy_gradient_loss          | 0.00263     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 600         |\n",
      "|    time_elapsed                  | 56589       |\n",
      "|    total_timesteps               | 2457600     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007945978 |\n",
      "|    clip_fraction                 | 0.0284      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.407      |\n",
      "|    explained_variance            | 0.838       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 520         |\n",
      "|    n_updates                     | 5990        |\n",
      "|    policy_gradient_loss          | 0.00251     |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 38          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 601         |\n",
      "|    time_elapsed                  | 56685       |\n",
      "|    total_timesteps               | 2461696     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016957335 |\n",
      "|    clip_fraction                 | 0.0416      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.441      |\n",
      "|    explained_variance            | 0.811       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 693         |\n",
      "|    n_updates                     | 6000        |\n",
      "|    policy_gradient_loss          | 0.00377     |\n",
      "|    value_loss                    | 1.49e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 602         |\n",
      "|    time_elapsed                  | 56782       |\n",
      "|    total_timesteps               | 2465792     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021887355 |\n",
      "|    clip_fraction                 | 0.0471      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.418      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 462         |\n",
      "|    n_updates                     | 6010        |\n",
      "|    policy_gradient_loss          | 0.00658     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 603         |\n",
      "|    time_elapsed                  | 56879       |\n",
      "|    total_timesteps               | 2469888     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022214258 |\n",
      "|    clip_fraction                 | 0.0535      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.423      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 445         |\n",
      "|    n_updates                     | 6020        |\n",
      "|    policy_gradient_loss          | 0.00443     |\n",
      "|    value_loss                    | 1.37e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 604         |\n",
      "|    time_elapsed                  | 56973       |\n",
      "|    total_timesteps               | 2473984     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025950119 |\n",
      "|    clip_fraction                 | 0.058       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.425      |\n",
      "|    explained_variance            | 0.798       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 288         |\n",
      "|    n_updates                     | 6030        |\n",
      "|    policy_gradient_loss          | 0.00288     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 605         |\n",
      "|    time_elapsed                  | 57070       |\n",
      "|    total_timesteps               | 2478080     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012521437 |\n",
      "|    clip_fraction                 | 0.0491      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.413      |\n",
      "|    explained_variance            | 0.849       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 363         |\n",
      "|    n_updates                     | 6040        |\n",
      "|    policy_gradient_loss          | 0.00407     |\n",
      "|    value_loss                    | 1.14e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 606         |\n",
      "|    time_elapsed                  | 57167       |\n",
      "|    total_timesteps               | 2482176     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019333653 |\n",
      "|    clip_fraction                 | 0.0509      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.427      |\n",
      "|    explained_variance            | 0.802       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 449         |\n",
      "|    n_updates                     | 6050        |\n",
      "|    policy_gradient_loss          | 0.00502     |\n",
      "|    value_loss                    | 1.41e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1080.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 607         |\n",
      "|    time_elapsed                  | 57263       |\n",
      "|    total_timesteps               | 2486272     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017982706 |\n",
      "|    clip_fraction                 | 0.0605      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.423      |\n",
      "|    explained_variance            | 0.825       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 295         |\n",
      "|    n_updates                     | 6060        |\n",
      "|    policy_gradient_loss          | 0.0367      |\n",
      "|    value_loss                    | 1.34e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 608         |\n",
      "|    time_elapsed                  | 57358       |\n",
      "|    total_timesteps               | 2490368     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009815963 |\n",
      "|    clip_fraction                 | 0.0423      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.39       |\n",
      "|    explained_variance            | 0.848       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 642         |\n",
      "|    n_updates                     | 6070        |\n",
      "|    policy_gradient_loss          | 0.00193     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 609         |\n",
      "|    time_elapsed                  | 57455       |\n",
      "|    total_timesteps               | 2494464     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032952823 |\n",
      "|    clip_fraction                 | 0.0643      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.42       |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 328         |\n",
      "|    n_updates                     | 6080        |\n",
      "|    policy_gradient_loss          | 0.00264     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1040.0     |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 610         |\n",
      "|    time_elapsed                  | 57551       |\n",
      "|    total_timesteps               | 2498560     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015859399 |\n",
      "|    clip_fraction                 | 0.0424      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.398      |\n",
      "|    explained_variance            | 0.829       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 386         |\n",
      "|    n_updates                     | 6090        |\n",
      "|    policy_gradient_loss          | 0.00301     |\n",
      "|    value_loss                    | 1.44e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2500000_steps.zip\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1160.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 611        |\n",
      "|    time_elapsed                  | 57647      |\n",
      "|    total_timesteps               | 2502656    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01552656 |\n",
      "|    clip_fraction                 | 0.0547     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.41      |\n",
      "|    explained_variance            | 0.81       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 338        |\n",
      "|    n_updates                     | 6100       |\n",
      "|    policy_gradient_loss          | 0.00681    |\n",
      "|    value_loss                    | 1.58e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1240.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 612        |\n",
      "|    time_elapsed                  | 57743      |\n",
      "|    total_timesteps               | 2506752    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02213329 |\n",
      "|    clip_fraction                 | 0.0525     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.403     |\n",
      "|    explained_variance            | 0.823      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 696        |\n",
      "|    n_updates                     | 6110       |\n",
      "|    policy_gradient_loss          | 0.00324    |\n",
      "|    value_loss                    | 1.57e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1620.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 613         |\n",
      "|    time_elapsed                  | 57840       |\n",
      "|    total_timesteps               | 2510848     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011068078 |\n",
      "|    clip_fraction                 | 0.0555      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.403      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 460         |\n",
      "|    n_updates                     | 6120        |\n",
      "|    policy_gradient_loss          | 0.00307     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 614         |\n",
      "|    time_elapsed                  | 57936       |\n",
      "|    total_timesteps               | 2514944     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013641724 |\n",
      "|    clip_fraction                 | 0.0531      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.419      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 596         |\n",
      "|    n_updates                     | 6130        |\n",
      "|    policy_gradient_loss          | 0.00325     |\n",
      "|    value_loss                    | 1.69e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 615         |\n",
      "|    time_elapsed                  | 58032       |\n",
      "|    total_timesteps               | 2519040     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.031910546 |\n",
      "|    clip_fraction                 | 0.0671      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.395      |\n",
      "|    explained_variance            | 0.823       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 1.22e+03    |\n",
      "|    n_updates                     | 6140        |\n",
      "|    policy_gradient_loss          | 0.00723     |\n",
      "|    value_loss                    | 1.49e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -940.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 616         |\n",
      "|    time_elapsed                  | 58128       |\n",
      "|    total_timesteps               | 2523136     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017655205 |\n",
      "|    clip_fraction                 | 0.0527      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.393      |\n",
      "|    explained_variance            | 0.858       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 320         |\n",
      "|    n_updates                     | 6150        |\n",
      "|    policy_gradient_loss          | 0.0039      |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 617         |\n",
      "|    time_elapsed                  | 58224       |\n",
      "|    total_timesteps               | 2527232     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022467855 |\n",
      "|    clip_fraction                 | 0.0492      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.407      |\n",
      "|    explained_variance            | 0.856       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 562         |\n",
      "|    n_updates                     | 6160        |\n",
      "|    policy_gradient_loss          | 0.00523     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1300.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 58         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 618        |\n",
      "|    time_elapsed                  | 58321      |\n",
      "|    total_timesteps               | 2531328    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01637346 |\n",
      "|    clip_fraction                 | 0.0497     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.398     |\n",
      "|    explained_variance            | 0.811      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 377        |\n",
      "|    n_updates                     | 6170       |\n",
      "|    policy_gradient_loss          | 0.00124    |\n",
      "|    value_loss                    | 1.31e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 74          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 619         |\n",
      "|    time_elapsed                  | 58417       |\n",
      "|    total_timesteps               | 2535424     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013263151 |\n",
      "|    clip_fraction                 | 0.0487      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.419      |\n",
      "|    explained_variance            | 0.847       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 496         |\n",
      "|    n_updates                     | 6180        |\n",
      "|    policy_gradient_loss          | 0.00228     |\n",
      "|    value_loss                    | 1.43e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1560.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 620         |\n",
      "|    time_elapsed                  | 58514       |\n",
      "|    total_timesteps               | 2539520     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013615256 |\n",
      "|    clip_fraction                 | 0.0454      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.401      |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 537         |\n",
      "|    n_updates                     | 6190        |\n",
      "|    policy_gradient_loss          | 0.00324     |\n",
      "|    value_loss                    | 1.26e+03    |\n",
      "--------------------------------------------------\n",
      "------------------------------------------------\n",
      "| episode/                         |           |\n",
      "|    direct_capacity_violation_sum | 0         |\n",
      "|    final_reward                  | -1460.0   |\n",
      "|    intervention_sum              | 21        |\n",
      "|    nl_comm_sum                   | 62        |\n",
      "| time/                            |           |\n",
      "|    fps                           | 43        |\n",
      "|    iterations                    | 621       |\n",
      "|    time_elapsed                  | 58610     |\n",
      "|    total_timesteps               | 2543616   |\n",
      "| total/                           |           |\n",
      "|    truncated                     | 0         |\n",
      "| train/                           |           |\n",
      "|    approx_kl                     | 0.1934841 |\n",
      "|    clip_fraction                 | 0.0432    |\n",
      "|    clip_range                    | 0.2       |\n",
      "|    entropy_loss                  | -0.402    |\n",
      "|    explained_variance            | 0.806     |\n",
      "|    learning_rate                 | 0.0005    |\n",
      "|    loss                          | 347       |\n",
      "|    n_updates                     | 6200      |\n",
      "|    policy_gradient_loss          | 0.00244   |\n",
      "|    value_loss                    | 1.29e+03  |\n",
      "------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 68          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 622         |\n",
      "|    time_elapsed                  | 58706       |\n",
      "|    total_timesteps               | 2547712     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015224791 |\n",
      "|    clip_fraction                 | 0.0481      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.413      |\n",
      "|    explained_variance            | 0.804       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 339         |\n",
      "|    n_updates                     | 6210        |\n",
      "|    policy_gradient_loss          | 0.00473     |\n",
      "|    value_loss                    | 1.33e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 623         |\n",
      "|    time_elapsed                  | 58801       |\n",
      "|    total_timesteps               | 2551808     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017035047 |\n",
      "|    clip_fraction                 | 0.0414      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.414      |\n",
      "|    explained_variance            | 0.824       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 567         |\n",
      "|    n_updates                     | 6220        |\n",
      "|    policy_gradient_loss          | 0.00181     |\n",
      "|    value_loss                    | 1.45e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 624         |\n",
      "|    time_elapsed                  | 58898       |\n",
      "|    total_timesteps               | 2555904     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.032494906 |\n",
      "|    clip_fraction                 | 0.0488      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.409      |\n",
      "|    explained_variance            | 0.853       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 399         |\n",
      "|    n_updates                     | 6230        |\n",
      "|    policy_gradient_loss          | 0.00533     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 625         |\n",
      "|    time_elapsed                  | 58995       |\n",
      "|    total_timesteps               | 2560000     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016449003 |\n",
      "|    clip_fraction                 | 0.0436      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.419      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 498         |\n",
      "|    n_updates                     | 6240        |\n",
      "|    policy_gradient_loss          | 0.0029      |\n",
      "|    value_loss                    | 1.7e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1600.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 76          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 626         |\n",
      "|    time_elapsed                  | 59091       |\n",
      "|    total_timesteps               | 2564096     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014446736 |\n",
      "|    clip_fraction                 | 0.0437      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.414      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 592         |\n",
      "|    n_updates                     | 6250        |\n",
      "|    policy_gradient_loss          | 0.00512     |\n",
      "|    value_loss                    | 1.68e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 627         |\n",
      "|    time_elapsed                  | 59186       |\n",
      "|    total_timesteps               | 2568192     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012524882 |\n",
      "|    clip_fraction                 | 0.0457      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.401      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 368         |\n",
      "|    n_updates                     | 6260        |\n",
      "|    policy_gradient_loss          | 0.00405     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 628         |\n",
      "|    time_elapsed                  | 59283       |\n",
      "|    total_timesteps               | 2572288     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021118924 |\n",
      "|    clip_fraction                 | 0.0415      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.401      |\n",
      "|    explained_variance            | 0.838       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 409         |\n",
      "|    n_updates                     | 6270        |\n",
      "|    policy_gradient_loss          | 0.00281     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 629         |\n",
      "|    time_elapsed                  | 59379       |\n",
      "|    total_timesteps               | 2576384     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018173251 |\n",
      "|    clip_fraction                 | 0.0396      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.386      |\n",
      "|    explained_variance            | 0.846       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 359         |\n",
      "|    n_updates                     | 6280        |\n",
      "|    policy_gradient_loss          | 0.00394     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 630         |\n",
      "|    time_elapsed                  | 59475       |\n",
      "|    total_timesteps               | 2580480     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014950022 |\n",
      "|    clip_fraction                 | 0.0386      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.371      |\n",
      "|    explained_variance            | 0.816       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 414         |\n",
      "|    n_updates                     | 6290        |\n",
      "|    policy_gradient_loss          | 0.000335    |\n",
      "|    value_loss                    | 1.2e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 631         |\n",
      "|    time_elapsed                  | 59571       |\n",
      "|    total_timesteps               | 2584576     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017702442 |\n",
      "|    clip_fraction                 | 0.0394      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.375      |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 556         |\n",
      "|    n_updates                     | 6300        |\n",
      "|    policy_gradient_loss          | 0.00227     |\n",
      "|    value_loss                    | 1.51e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -980.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 632         |\n",
      "|    time_elapsed                  | 59667       |\n",
      "|    total_timesteps               | 2588672     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016178343 |\n",
      "|    clip_fraction                 | 0.0443      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.397      |\n",
      "|    explained_variance            | 0.824       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 203         |\n",
      "|    n_updates                     | 6310        |\n",
      "|    policy_gradient_loss          | 0.00658     |\n",
      "|    value_loss                    | 1.51e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 633         |\n",
      "|    time_elapsed                  | 59764       |\n",
      "|    total_timesteps               | 2592768     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015503344 |\n",
      "|    clip_fraction                 | 0.0475      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.387      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 444         |\n",
      "|    n_updates                     | 6320        |\n",
      "|    policy_gradient_loss          | 0.000664    |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1280.0      |\n",
      "|    intervention_sum              | 18           |\n",
      "|    nl_comm_sum                   | 56           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 634          |\n",
      "|    time_elapsed                  | 59860        |\n",
      "|    total_timesteps               | 2596864      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0077547044 |\n",
      "|    clip_fraction                 | 0.0345       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.372       |\n",
      "|    explained_variance            | 0.844        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 389          |\n",
      "|    n_updates                     | 6330         |\n",
      "|    policy_gradient_loss          | 0.000649     |\n",
      "|    value_loss                    | 1.16e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2600000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 42          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 635         |\n",
      "|    time_elapsed                  | 59956       |\n",
      "|    total_timesteps               | 2600960     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.055448398 |\n",
      "|    clip_fraction                 | 0.0518      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.387      |\n",
      "|    explained_variance            | 0.858       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 534         |\n",
      "|    n_updates                     | 6340        |\n",
      "|    policy_gradient_loss          | 0.00641     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1000.0    |\n",
      "|    intervention_sum              | 14         |\n",
      "|    nl_comm_sum                   | 44         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 636        |\n",
      "|    time_elapsed                  | 60053      |\n",
      "|    total_timesteps               | 2605056    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02930729 |\n",
      "|    clip_fraction                 | 0.0432     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.373     |\n",
      "|    explained_variance            | 0.842      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 247        |\n",
      "|    n_updates                     | 6350       |\n",
      "|    policy_gradient_loss          | 0.00577    |\n",
      "|    value_loss                    | 1.38e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 637         |\n",
      "|    time_elapsed                  | 60149       |\n",
      "|    total_timesteps               | 2609152     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012981458 |\n",
      "|    clip_fraction                 | 0.0318      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.359      |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 541         |\n",
      "|    n_updates                     | 6360        |\n",
      "|    policy_gradient_loss          | 0.00301     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 638         |\n",
      "|    time_elapsed                  | 60245       |\n",
      "|    total_timesteps               | 2613248     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012665203 |\n",
      "|    clip_fraction                 | 0.0299      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.381      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 407         |\n",
      "|    n_updates                     | 6370        |\n",
      "|    policy_gradient_loss          | 0.000358    |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 639         |\n",
      "|    time_elapsed                  | 60340       |\n",
      "|    total_timesteps               | 2617344     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.021466296 |\n",
      "|    clip_fraction                 | 0.0486      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.394      |\n",
      "|    explained_variance            | 0.803       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 634         |\n",
      "|    n_updates                     | 6380        |\n",
      "|    policy_gradient_loss          | 0.00391     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 640         |\n",
      "|    time_elapsed                  | 60438       |\n",
      "|    total_timesteps               | 2621440     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014230842 |\n",
      "|    clip_fraction                 | 0.0436      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.381      |\n",
      "|    explained_variance            | 0.837       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 451         |\n",
      "|    n_updates                     | 6390        |\n",
      "|    policy_gradient_loss          | 0.00313     |\n",
      "|    value_loss                    | 1.08e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 641         |\n",
      "|    time_elapsed                  | 60535       |\n",
      "|    total_timesteps               | 2625536     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009289386 |\n",
      "|    clip_fraction                 | 0.0366      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.371      |\n",
      "|    explained_variance            | 0.825       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 802         |\n",
      "|    n_updates                     | 6400        |\n",
      "|    policy_gradient_loss          | 0.0027      |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 642         |\n",
      "|    time_elapsed                  | 60631       |\n",
      "|    total_timesteps               | 2629632     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013006257 |\n",
      "|    clip_fraction                 | 0.0294      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.368      |\n",
      "|    explained_variance            | 0.853       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 446         |\n",
      "|    n_updates                     | 6410        |\n",
      "|    policy_gradient_loss          | 0.00258     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1300.0    |\n",
      "|    intervention_sum              | 20         |\n",
      "|    nl_comm_sum                   | 50         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 643        |\n",
      "|    time_elapsed                  | 60726      |\n",
      "|    total_timesteps               | 2633728    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01255875 |\n",
      "|    clip_fraction                 | 0.0253     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.354     |\n",
      "|    explained_variance            | 0.821      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 302        |\n",
      "|    n_updates                     | 6420       |\n",
      "|    policy_gradient_loss          | 0.000729   |\n",
      "|    value_loss                    | 1.25e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1240.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 644        |\n",
      "|    time_elapsed                  | 60823      |\n",
      "|    total_timesteps               | 2637824    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01028814 |\n",
      "|    clip_fraction                 | 0.0311     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.367     |\n",
      "|    explained_variance            | 0.849      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 411        |\n",
      "|    n_updates                     | 6430       |\n",
      "|    policy_gradient_loss          | 0.00175    |\n",
      "|    value_loss                    | 1.15e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 24          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 645         |\n",
      "|    time_elapsed                  | 60921       |\n",
      "|    total_timesteps               | 2641920     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013778126 |\n",
      "|    clip_fraction                 | 0.0386      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.362      |\n",
      "|    explained_variance            | 0.838       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 417         |\n",
      "|    n_updates                     | 6440        |\n",
      "|    policy_gradient_loss          | 0.004       |\n",
      "|    value_loss                    | 1.11e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1360.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 60         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 646        |\n",
      "|    time_elapsed                  | 61018      |\n",
      "|    total_timesteps               | 2646016    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01503101 |\n",
      "|    clip_fraction                 | 0.0356     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.368     |\n",
      "|    explained_variance            | 0.79       |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 374        |\n",
      "|    n_updates                     | 6450       |\n",
      "|    policy_gradient_loss          | 0.00296    |\n",
      "|    value_loss                    | 1.45e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 647         |\n",
      "|    time_elapsed                  | 61113       |\n",
      "|    total_timesteps               | 2650112     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008863149 |\n",
      "|    clip_fraction                 | 0.0361      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.366      |\n",
      "|    explained_variance            | 0.821       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 593         |\n",
      "|    n_updates                     | 6460        |\n",
      "|    policy_gradient_loss          | 0.00057     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 648         |\n",
      "|    time_elapsed                  | 61210       |\n",
      "|    total_timesteps               | 2654208     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012070961 |\n",
      "|    clip_fraction                 | 0.0378      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.372      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 545         |\n",
      "|    n_updates                     | 6470        |\n",
      "|    policy_gradient_loss          | 0.00116     |\n",
      "|    value_loss                    | 1.3e+03     |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1380.0    |\n",
      "|    intervention_sum              | 13         |\n",
      "|    nl_comm_sum                   | 86         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 649        |\n",
      "|    time_elapsed                  | 61307      |\n",
      "|    total_timesteps               | 2658304    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01682627 |\n",
      "|    clip_fraction                 | 0.0429     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.385     |\n",
      "|    explained_variance            | 0.828      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 369        |\n",
      "|    n_updates                     | 6480       |\n",
      "|    policy_gradient_loss          | 0.00475    |\n",
      "|    value_loss                    | 1.32e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 650         |\n",
      "|    time_elapsed                  | 61403       |\n",
      "|    total_timesteps               | 2662400     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020191798 |\n",
      "|    clip_fraction                 | 0.0472      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.4        |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 738         |\n",
      "|    n_updates                     | 6490        |\n",
      "|    policy_gradient_loss          | 0.00415     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1540.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 651         |\n",
      "|    time_elapsed                  | 61498       |\n",
      "|    total_timesteps               | 2666496     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009891214 |\n",
      "|    clip_fraction                 | 0.036       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.367      |\n",
      "|    explained_variance            | 0.845       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 333         |\n",
      "|    n_updates                     | 6500        |\n",
      "|    policy_gradient_loss          | 0.00259     |\n",
      "|    value_loss                    | 1.16e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 652         |\n",
      "|    time_elapsed                  | 61595       |\n",
      "|    total_timesteps               | 2670592     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020735905 |\n",
      "|    clip_fraction                 | 0.0536      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.378      |\n",
      "|    explained_variance            | 0.807       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 613         |\n",
      "|    n_updates                     | 6510        |\n",
      "|    policy_gradient_loss          | 0.00278     |\n",
      "|    value_loss                    | 1.44e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 22          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 653         |\n",
      "|    time_elapsed                  | 61692       |\n",
      "|    total_timesteps               | 2674688     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013414134 |\n",
      "|    clip_fraction                 | 0.0392      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.373      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 386         |\n",
      "|    n_updates                     | 6520        |\n",
      "|    policy_gradient_loss          | 0.00204     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 654         |\n",
      "|    time_elapsed                  | 61785       |\n",
      "|    total_timesteps               | 2678784     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010277312 |\n",
      "|    clip_fraction                 | 0.0363      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.354      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 388         |\n",
      "|    n_updates                     | 6530        |\n",
      "|    policy_gradient_loss          | 0.00258     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 655         |\n",
      "|    time_elapsed                  | 61877       |\n",
      "|    total_timesteps               | 2682880     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.027618354 |\n",
      "|    clip_fraction                 | 0.0426      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.346      |\n",
      "|    explained_variance            | 0.787       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 548         |\n",
      "|    n_updates                     | 6540        |\n",
      "|    policy_gradient_loss          | -3.46e-06   |\n",
      "|    value_loss                    | 1.48e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 656         |\n",
      "|    time_elapsed                  | 61970       |\n",
      "|    total_timesteps               | 2686976     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024911966 |\n",
      "|    clip_fraction                 | 0.0394      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.366      |\n",
      "|    explained_variance            | 0.849       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 552         |\n",
      "|    n_updates                     | 6550        |\n",
      "|    policy_gradient_loss          | 0.00411     |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 657         |\n",
      "|    time_elapsed                  | 62062       |\n",
      "|    total_timesteps               | 2691072     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019624036 |\n",
      "|    clip_fraction                 | 0.0273      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.341      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 464         |\n",
      "|    n_updates                     | 6560        |\n",
      "|    policy_gradient_loss          | 0.00129     |\n",
      "|    value_loss                    | 1.36e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 658         |\n",
      "|    time_elapsed                  | 62155       |\n",
      "|    total_timesteps               | 2695168     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023114545 |\n",
      "|    clip_fraction                 | 0.04        |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.351      |\n",
      "|    explained_variance            | 0.861       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 462         |\n",
      "|    n_updates                     | 6570        |\n",
      "|    policy_gradient_loss          | 0.00518     |\n",
      "|    value_loss                    | 1.35e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1200.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 659         |\n",
      "|    time_elapsed                  | 62247       |\n",
      "|    total_timesteps               | 2699264     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.007135133 |\n",
      "|    clip_fraction                 | 0.0322      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.347      |\n",
      "|    explained_variance            | 0.821       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 410         |\n",
      "|    n_updates                     | 6580        |\n",
      "|    policy_gradient_loss          | 0.00437     |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2700000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -620.0      |\n",
      "|    intervention_sum              | 8           |\n",
      "|    nl_comm_sum                   | 30          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 660         |\n",
      "|    time_elapsed                  | 62339       |\n",
      "|    total_timesteps               | 2703360     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014994185 |\n",
      "|    clip_fraction                 | 0.0291      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.316      |\n",
      "|    explained_variance            | 0.838       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 769         |\n",
      "|    n_updates                     | 6590        |\n",
      "|    policy_gradient_loss          | 0.00313     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 661         |\n",
      "|    time_elapsed                  | 62432       |\n",
      "|    total_timesteps               | 2707456     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013862687 |\n",
      "|    clip_fraction                 | 0.0273      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.313      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 435         |\n",
      "|    n_updates                     | 6600        |\n",
      "|    policy_gradient_loss          | 0.00203     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1500.0    |\n",
      "|    intervention_sum              | 22         |\n",
      "|    nl_comm_sum                   | 62         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 662        |\n",
      "|    time_elapsed                  | 62525      |\n",
      "|    total_timesteps               | 2711552    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01626377 |\n",
      "|    clip_fraction                 | 0.0229     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.334     |\n",
      "|    explained_variance            | 0.841      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 343        |\n",
      "|    n_updates                     | 6610       |\n",
      "|    policy_gradient_loss          | 0.00361    |\n",
      "|    value_loss                    | 1.24e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1500.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 66         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 663        |\n",
      "|    time_elapsed                  | 62617      |\n",
      "|    total_timesteps               | 2715648    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01635503 |\n",
      "|    clip_fraction                 | 0.0394     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.346     |\n",
      "|    explained_variance            | 0.847      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 345        |\n",
      "|    n_updates                     | 6620       |\n",
      "|    policy_gradient_loss          | 0.00213    |\n",
      "|    value_loss                    | 1.18e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 664         |\n",
      "|    time_elapsed                  | 62710       |\n",
      "|    total_timesteps               | 2719744     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024821853 |\n",
      "|    clip_fraction                 | 0.0423      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.34       |\n",
      "|    explained_variance            | 0.841       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 934         |\n",
      "|    n_updates                     | 6630        |\n",
      "|    policy_gradient_loss          | 0.00314     |\n",
      "|    value_loss                    | 1.08e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1300.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 665        |\n",
      "|    time_elapsed                  | 62803      |\n",
      "|    total_timesteps               | 2723840    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.07162273 |\n",
      "|    clip_fraction                 | 0.082      |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.34      |\n",
      "|    explained_variance            | 0.668      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 807        |\n",
      "|    n_updates                     | 6640       |\n",
      "|    policy_gradient_loss          | 0.0263     |\n",
      "|    value_loss                    | 1.52e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 666         |\n",
      "|    time_elapsed                  | 62896       |\n",
      "|    total_timesteps               | 2727936     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020758038 |\n",
      "|    clip_fraction                 | 0.0345      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.337      |\n",
      "|    explained_variance            | 0.797       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 321         |\n",
      "|    n_updates                     | 6650        |\n",
      "|    policy_gradient_loss          | 0.00504     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 667         |\n",
      "|    time_elapsed                  | 62988       |\n",
      "|    total_timesteps               | 2732032     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.015072938 |\n",
      "|    clip_fraction                 | 0.0424      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.334      |\n",
      "|    explained_variance            | 0.863       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 304         |\n",
      "|    n_updates                     | 6660        |\n",
      "|    policy_gradient_loss          | 0.00255     |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 64          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 668         |\n",
      "|    time_elapsed                  | 63080       |\n",
      "|    total_timesteps               | 2736128     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018091025 |\n",
      "|    clip_fraction                 | 0.0343      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.319      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 236         |\n",
      "|    n_updates                     | 6670        |\n",
      "|    policy_gradient_loss          | 0.00168     |\n",
      "|    value_loss                    | 1.13e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1220.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 669         |\n",
      "|    time_elapsed                  | 63173       |\n",
      "|    total_timesteps               | 2740224     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018913176 |\n",
      "|    clip_fraction                 | 0.026       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.338      |\n",
      "|    explained_variance            | 0.851       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 356         |\n",
      "|    n_updates                     | 6680        |\n",
      "|    policy_gradient_loss          | 0.00237     |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 670         |\n",
      "|    time_elapsed                  | 63266       |\n",
      "|    total_timesteps               | 2744320     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009849777 |\n",
      "|    clip_fraction                 | 0.0304      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.333      |\n",
      "|    explained_variance            | 0.872       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 644         |\n",
      "|    n_updates                     | 6690        |\n",
      "|    policy_gradient_loss          | 0.00128     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 671         |\n",
      "|    time_elapsed                  | 63358       |\n",
      "|    total_timesteps               | 2748416     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012394875 |\n",
      "|    clip_fraction                 | 0.0409      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.335      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 483         |\n",
      "|    n_updates                     | 6700        |\n",
      "|    policy_gradient_loss          | 0.00188     |\n",
      "|    value_loss                    | 1.24e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 672         |\n",
      "|    time_elapsed                  | 63451       |\n",
      "|    total_timesteps               | 2752512     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013589793 |\n",
      "|    clip_fraction                 | 0.0352      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.324      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 308         |\n",
      "|    n_updates                     | 6710        |\n",
      "|    policy_gradient_loss          | 0.00409     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 673         |\n",
      "|    time_elapsed                  | 63544       |\n",
      "|    total_timesteps               | 2756608     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012234695 |\n",
      "|    clip_fraction                 | 0.0264      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.309      |\n",
      "|    explained_variance            | 0.853       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 426         |\n",
      "|    n_updates                     | 6720        |\n",
      "|    policy_gradient_loss          | 0.0021      |\n",
      "|    value_loss                    | 1.4e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 674         |\n",
      "|    time_elapsed                  | 63637       |\n",
      "|    total_timesteps               | 2760704     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013640704 |\n",
      "|    clip_fraction                 | 0.0372      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.309      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 567         |\n",
      "|    n_updates                     | 6730        |\n",
      "|    policy_gradient_loss          | 0.00796     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1480.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 675         |\n",
      "|    time_elapsed                  | 63728       |\n",
      "|    total_timesteps               | 2764800     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013445541 |\n",
      "|    clip_fraction                 | 0.0289      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.329      |\n",
      "|    explained_variance            | 0.847       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 274         |\n",
      "|    n_updates                     | 6740        |\n",
      "|    policy_gradient_loss          | 0.000229    |\n",
      "|    value_loss                    | 1.16e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 676         |\n",
      "|    time_elapsed                  | 63822       |\n",
      "|    total_timesteps               | 2768896     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019651096 |\n",
      "|    clip_fraction                 | 0.0305      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.322      |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 263         |\n",
      "|    n_updates                     | 6750        |\n",
      "|    policy_gradient_loss          | 0.00339     |\n",
      "|    value_loss                    | 1.55e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 677         |\n",
      "|    time_elapsed                  | 63914       |\n",
      "|    total_timesteps               | 2772992     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010938758 |\n",
      "|    clip_fraction                 | 0.0238      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.316      |\n",
      "|    explained_variance            | 0.809       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 339         |\n",
      "|    n_updates                     | 6760        |\n",
      "|    policy_gradient_loss          | 0.000988    |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 678         |\n",
      "|    time_elapsed                  | 64006       |\n",
      "|    total_timesteps               | 2777088     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009021826 |\n",
      "|    clip_fraction                 | 0.026       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.326      |\n",
      "|    explained_variance            | 0.818       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 457         |\n",
      "|    n_updates                     | 6770        |\n",
      "|    policy_gradient_loss          | 0.00224     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "------------------------------------------------\n",
      "| episode/                         |           |\n",
      "|    direct_capacity_violation_sum | 0         |\n",
      "|    final_reward                  | -1420.0   |\n",
      "|    intervention_sum              | 21        |\n",
      "|    nl_comm_sum                   | 58        |\n",
      "| time/                            |           |\n",
      "|    fps                           | 43        |\n",
      "|    iterations                    | 679       |\n",
      "|    time_elapsed                  | 64098     |\n",
      "|    total_timesteps               | 2781184   |\n",
      "| total/                           |           |\n",
      "|    truncated                     | 0         |\n",
      "| train/                           |           |\n",
      "|    approx_kl                     | 0.0989431 |\n",
      "|    clip_fraction                 | 0.0629    |\n",
      "|    clip_range                    | 0.2       |\n",
      "|    entropy_loss                  | -0.33     |\n",
      "|    explained_variance            | 0.86      |\n",
      "|    learning_rate                 | 0.0005    |\n",
      "|    loss                          | 410       |\n",
      "|    n_updates                     | 6780      |\n",
      "|    policy_gradient_loss          | 0.0122    |\n",
      "|    value_loss                    | 1.81e+03  |\n",
      "------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1160.0    |\n",
      "|    intervention_sum              | 16         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 680        |\n",
      "|    time_elapsed                  | 64191      |\n",
      "|    total_timesteps               | 2785280    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.23441139 |\n",
      "|    clip_fraction                 | 0.0791     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.333     |\n",
      "|    explained_variance            | 0.796      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 665        |\n",
      "|    n_updates                     | 6790       |\n",
      "|    policy_gradient_loss          | 0.0305     |\n",
      "|    value_loss                    | 1.52e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 681         |\n",
      "|    time_elapsed                  | 64284       |\n",
      "|    total_timesteps               | 2789376     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.030334122 |\n",
      "|    clip_fraction                 | 0.0381      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.303      |\n",
      "|    explained_variance            | 0.806       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 542         |\n",
      "|    n_updates                     | 6800        |\n",
      "|    policy_gradient_loss          | 0.00714     |\n",
      "|    value_loss                    | 1.39e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1420.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 682         |\n",
      "|    time_elapsed                  | 64377       |\n",
      "|    total_timesteps               | 2793472     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014367556 |\n",
      "|    clip_fraction                 | 0.0282      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.305      |\n",
      "|    explained_variance            | 0.844       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 354         |\n",
      "|    n_updates                     | 6810        |\n",
      "|    policy_gradient_loss          | 0.00211     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 23          |\n",
      "|    nl_comm_sum                   | 58          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 683         |\n",
      "|    time_elapsed                  | 64469       |\n",
      "|    total_timesteps               | 2797568     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.028236635 |\n",
      "|    clip_fraction                 | 0.0302      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.312      |\n",
      "|    explained_variance            | 0.851       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 460         |\n",
      "|    n_updates                     | 6820        |\n",
      "|    policy_gradient_loss          | 0.00367     |\n",
      "|    value_loss                    | 1.31e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2800000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 684         |\n",
      "|    time_elapsed                  | 64562       |\n",
      "|    total_timesteps               | 2801664     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.034077268 |\n",
      "|    clip_fraction                 | 0.0382      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.311      |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 401         |\n",
      "|    n_updates                     | 6830        |\n",
      "|    policy_gradient_loss          | 0.00442     |\n",
      "|    value_loss                    | 1.38e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1360.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 685         |\n",
      "|    time_elapsed                  | 64656       |\n",
      "|    total_timesteps               | 2805760     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016547892 |\n",
      "|    clip_fraction                 | 0.0309      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.316      |\n",
      "|    explained_variance            | 0.841       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 387         |\n",
      "|    n_updates                     | 6840        |\n",
      "|    policy_gradient_loss          | 0.00395     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1220.0      |\n",
      "|    intervention_sum              | 17           |\n",
      "|    nl_comm_sum                   | 54           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 686          |\n",
      "|    time_elapsed                  | 64748        |\n",
      "|    total_timesteps               | 2809856      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0066594863 |\n",
      "|    clip_fraction                 | 0.0207       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.304       |\n",
      "|    explained_variance            | 0.833        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 624          |\n",
      "|    n_updates                     | 6850         |\n",
      "|    policy_gradient_loss          | 0.00123      |\n",
      "|    value_loss                    | 1.1e+03      |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1380.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 687         |\n",
      "|    time_elapsed                  | 64841       |\n",
      "|    total_timesteps               | 2813952     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012426179 |\n",
      "|    clip_fraction                 | 0.0264      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.31       |\n",
      "|    explained_variance            | 0.852       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 281         |\n",
      "|    n_updates                     | 6860        |\n",
      "|    policy_gradient_loss          | 0.00129     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1500.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 70          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 688         |\n",
      "|    time_elapsed                  | 64934       |\n",
      "|    total_timesteps               | 2818048     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012682142 |\n",
      "|    clip_fraction                 | 0.025       |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.312      |\n",
      "|    explained_variance            | 0.847       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 380         |\n",
      "|    n_updates                     | 6870        |\n",
      "|    policy_gradient_loss          | 0.00234     |\n",
      "|    value_loss                    | 1.1e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 689         |\n",
      "|    time_elapsed                  | 65026       |\n",
      "|    total_timesteps               | 2822144     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018498568 |\n",
      "|    clip_fraction                 | 0.0248      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.324      |\n",
      "|    explained_variance            | 0.822       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 349         |\n",
      "|    n_updates                     | 6880        |\n",
      "|    policy_gradient_loss          | 0.00103     |\n",
      "|    value_loss                    | 1.15e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1360.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 60           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 690          |\n",
      "|    time_elapsed                  | 65120        |\n",
      "|    total_timesteps               | 2826240      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0100754555 |\n",
      "|    clip_fraction                 | 0.026        |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.305       |\n",
      "|    explained_variance            | 0.861        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 361          |\n",
      "|    n_updates                     | 6890         |\n",
      "|    policy_gradient_loss          | 0.00116      |\n",
      "|    value_loss                    | 1.12e+03     |\n",
      "---------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1260.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 50         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 691        |\n",
      "|    time_elapsed                  | 65212      |\n",
      "|    total_timesteps               | 2830336    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.33708987 |\n",
      "|    clip_fraction                 | 0.0874     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.314     |\n",
      "|    explained_variance            | 0.856      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 408        |\n",
      "|    n_updates                     | 6900       |\n",
      "|    policy_gradient_loss          | 0.0235     |\n",
      "|    value_loss                    | 1.67e+03   |\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "| episode/                         |           |\n",
      "|    direct_capacity_violation_sum | 0         |\n",
      "|    final_reward                  | -1220.0   |\n",
      "|    intervention_sum              | 18        |\n",
      "|    nl_comm_sum                   | 50        |\n",
      "| time/                            |           |\n",
      "|    fps                           | 43        |\n",
      "|    iterations                    | 692       |\n",
      "|    time_elapsed                  | 65304     |\n",
      "|    total_timesteps               | 2834432   |\n",
      "| total/                           |           |\n",
      "|    truncated                     | 0         |\n",
      "| train/                           |           |\n",
      "|    approx_kl                     | 0.2796847 |\n",
      "|    clip_fraction                 | 0.0845    |\n",
      "|    clip_range                    | 0.2       |\n",
      "|    entropy_loss                  | -0.316    |\n",
      "|    explained_variance            | 0.792     |\n",
      "|    learning_rate                 | 0.0005    |\n",
      "|    loss                          | 407       |\n",
      "|    n_updates                     | 6910      |\n",
      "|    policy_gradient_loss          | 0.0166    |\n",
      "|    value_loss                    | 1.51e+03  |\n",
      "------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1060.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 693         |\n",
      "|    time_elapsed                  | 65396       |\n",
      "|    total_timesteps               | 2838528     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.035323143 |\n",
      "|    clip_fraction                 | 0.0367      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.3        |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 481         |\n",
      "|    n_updates                     | 6920        |\n",
      "|    policy_gradient_loss          | 0.00811     |\n",
      "|    value_loss                    | 1.03e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 694         |\n",
      "|    time_elapsed                  | 65490       |\n",
      "|    total_timesteps               | 2842624     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.029328644 |\n",
      "|    clip_fraction                 | 0.0351      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.296      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 290         |\n",
      "|    n_updates                     | 6930        |\n",
      "|    policy_gradient_loss          | 0.0151      |\n",
      "|    value_loss                    | 1.07e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 695         |\n",
      "|    time_elapsed                  | 65581       |\n",
      "|    total_timesteps               | 2846720     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013568607 |\n",
      "|    clip_fraction                 | 0.0296      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.328      |\n",
      "|    explained_variance            | 0.852       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 432         |\n",
      "|    n_updates                     | 6940        |\n",
      "|    policy_gradient_loss          | 0.00412     |\n",
      "|    value_loss                    | 1.14e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 696         |\n",
      "|    time_elapsed                  | 65674       |\n",
      "|    total_timesteps               | 2850816     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.023218771 |\n",
      "|    clip_fraction                 | 0.0321      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.294      |\n",
      "|    explained_variance            | 0.835       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 810         |\n",
      "|    n_updates                     | 6950        |\n",
      "|    policy_gradient_loss          | 0.00558     |\n",
      "|    value_loss                    | 1.28e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1400.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 697         |\n",
      "|    time_elapsed                  | 65766       |\n",
      "|    total_timesteps               | 2854912     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018007655 |\n",
      "|    clip_fraction                 | 0.0339      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.304      |\n",
      "|    explained_variance            | 0.814       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 446         |\n",
      "|    n_updates                     | 6960        |\n",
      "|    policy_gradient_loss          | 0.00297     |\n",
      "|    value_loss                    | 1.29e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1240.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 698         |\n",
      "|    time_elapsed                  | 65859       |\n",
      "|    total_timesteps               | 2859008     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.025484908 |\n",
      "|    clip_fraction                 | 0.0281      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.307      |\n",
      "|    explained_variance            | 0.828       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 472         |\n",
      "|    n_updates                     | 6970        |\n",
      "|    policy_gradient_loss          | 0.00493     |\n",
      "|    value_loss                    | 1.19e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 699         |\n",
      "|    time_elapsed                  | 65952       |\n",
      "|    total_timesteps               | 2863104     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.030806579 |\n",
      "|    clip_fraction                 | 0.0383      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.34       |\n",
      "|    explained_variance            | 0.827       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 982         |\n",
      "|    n_updates                     | 6980        |\n",
      "|    policy_gradient_loss          | 0.00294     |\n",
      "|    value_loss                    | 1.22e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1180.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 50         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 700        |\n",
      "|    time_elapsed                  | 66045      |\n",
      "|    total_timesteps               | 2867200    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.15504193 |\n",
      "|    clip_fraction                 | 0.0726     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.287     |\n",
      "|    explained_variance            | 0.825      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 297        |\n",
      "|    n_updates                     | 6990       |\n",
      "|    policy_gradient_loss          | 0.0227     |\n",
      "|    value_loss                    | 1.53e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -980.0     |\n",
      "|    intervention_sum              | 14         |\n",
      "|    nl_comm_sum                   | 42         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 701        |\n",
      "|    time_elapsed                  | 66138      |\n",
      "|    total_timesteps               | 2871296    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.06880477 |\n",
      "|    clip_fraction                 | 0.0492     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.295     |\n",
      "|    explained_variance            | 0.807      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 663        |\n",
      "|    n_updates                     | 7000       |\n",
      "|    policy_gradient_loss          | 0.017      |\n",
      "|    value_loss                    | 1.7e+03    |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1480.0    |\n",
      "|    intervention_sum              | 23         |\n",
      "|    nl_comm_sum                   | 56         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 702        |\n",
      "|    time_elapsed                  | 66231      |\n",
      "|    total_timesteps               | 2875392    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.08964163 |\n",
      "|    clip_fraction                 | 0.0655     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.297     |\n",
      "|    explained_variance            | 0.805      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 546        |\n",
      "|    n_updates                     | 7010       |\n",
      "|    policy_gradient_loss          | 0.0178     |\n",
      "|    value_loss                    | 1.59e+03   |\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 17         |\n",
      "|    nl_comm_sum                   | 52         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 703        |\n",
      "|    time_elapsed                  | 66323      |\n",
      "|    total_timesteps               | 2879488    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.20004307 |\n",
      "|    clip_fraction                 | 0.0783     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.307     |\n",
      "|    explained_variance            | 0.824      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 726        |\n",
      "|    n_updates                     | 7020       |\n",
      "|    policy_gradient_loss          | 0.0227     |\n",
      "|    value_loss                    | 1.47e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 704         |\n",
      "|    time_elapsed                  | 66415       |\n",
      "|    total_timesteps               | 2883584     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.017737556 |\n",
      "|    clip_fraction                 | 0.0351      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.275      |\n",
      "|    explained_variance            | 0.849       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 353         |\n",
      "|    n_updates                     | 7030        |\n",
      "|    policy_gradient_loss          | 0.0112      |\n",
      "|    value_loss                    | 988         |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 705         |\n",
      "|    time_elapsed                  | 66508       |\n",
      "|    total_timesteps               | 2887680     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.055922933 |\n",
      "|    clip_fraction                 | 0.0471      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.291      |\n",
      "|    explained_variance            | 0.859       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 352         |\n",
      "|    n_updates                     | 7040        |\n",
      "|    policy_gradient_loss          | 0.00945     |\n",
      "|    value_loss                    | 1.08e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 706         |\n",
      "|    time_elapsed                  | 66601       |\n",
      "|    total_timesteps               | 2891776     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024785167 |\n",
      "|    clip_fraction                 | 0.0296      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.285      |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 553         |\n",
      "|    n_updates                     | 7050        |\n",
      "|    policy_gradient_loss          | 0.00168     |\n",
      "|    value_loss                    | 1.15e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 707         |\n",
      "|    time_elapsed                  | 66693       |\n",
      "|    total_timesteps               | 2895872     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024465572 |\n",
      "|    clip_fraction                 | 0.0462      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.292      |\n",
      "|    explained_variance            | 0.817       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 578         |\n",
      "|    n_updates                     | 7060        |\n",
      "|    policy_gradient_loss          | 0.00809     |\n",
      "|    value_loss                    | 1.2e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 708         |\n",
      "|    time_elapsed                  | 66787       |\n",
      "|    total_timesteps               | 2899968     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.026189592 |\n",
      "|    clip_fraction                 | 0.0339      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.297      |\n",
      "|    explained_variance            | 0.839       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 482         |\n",
      "|    n_updates                     | 7070        |\n",
      "|    policy_gradient_loss          | 0.0102      |\n",
      "|    value_loss                    | 1.14e+03    |\n",
      "--------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_2900000_steps.zip\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1380.0    |\n",
      "|    intervention_sum              | 21         |\n",
      "|    nl_comm_sum                   | 54         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 709        |\n",
      "|    time_elapsed                  | 66879      |\n",
      "|    total_timesteps               | 2904064    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03298887 |\n",
      "|    clip_fraction                 | 0.0474     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.335     |\n",
      "|    explained_variance            | 0.817      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 527        |\n",
      "|    n_updates                     | 7080       |\n",
      "|    policy_gradient_loss          | 0.00984    |\n",
      "|    value_loss                    | 1.31e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 56          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 710         |\n",
      "|    time_elapsed                  | 66971       |\n",
      "|    total_timesteps               | 2908160     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.022112966 |\n",
      "|    clip_fraction                 | 0.0323      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.322      |\n",
      "|    explained_variance            | 0.862       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 408         |\n",
      "|    n_updates                     | 7090        |\n",
      "|    policy_gradient_loss          | 0.00313     |\n",
      "|    value_loss                    | 1.05e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 711         |\n",
      "|    time_elapsed                  | 67064       |\n",
      "|    total_timesteps               | 2912256     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.024516268 |\n",
      "|    clip_fraction                 | 0.0408      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.34       |\n",
      "|    explained_variance            | 0.834       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 364         |\n",
      "|    n_updates                     | 7100        |\n",
      "|    policy_gradient_loss          | 0.00688     |\n",
      "|    value_loss                    | 994         |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 712        |\n",
      "|    time_elapsed                  | 67157      |\n",
      "|    total_timesteps               | 2916352    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.03334994 |\n",
      "|    clip_fraction                 | 0.0368     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.315     |\n",
      "|    explained_variance            | 0.846      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 299        |\n",
      "|    n_updates                     | 7110       |\n",
      "|    policy_gradient_loss          | 0.0053     |\n",
      "|    value_loss                    | 1.05e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1020.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 46          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 713         |\n",
      "|    time_elapsed                  | 67250       |\n",
      "|    total_timesteps               | 2920448     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.018000625 |\n",
      "|    clip_fraction                 | 0.0316      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.312      |\n",
      "|    explained_variance            | 0.812       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 373         |\n",
      "|    n_updates                     | 7120        |\n",
      "|    policy_gradient_loss          | 0.00455     |\n",
      "|    value_loss                    | 1.21e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1440.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 60          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 714         |\n",
      "|    time_elapsed                  | 67342       |\n",
      "|    total_timesteps               | 2924544     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.014807127 |\n",
      "|    clip_fraction                 | 0.0375      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.307      |\n",
      "|    explained_variance            | 0.843       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 415         |\n",
      "|    n_updates                     | 7130        |\n",
      "|    policy_gradient_loss          | 0.00737     |\n",
      "|    value_loss                    | 968         |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1340.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 715         |\n",
      "|    time_elapsed                  | 67434       |\n",
      "|    total_timesteps               | 2928640     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008905454 |\n",
      "|    clip_fraction                 | 0.0248      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.292      |\n",
      "|    explained_variance            | 0.848       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 310         |\n",
      "|    n_updates                     | 7140        |\n",
      "|    policy_gradient_loss          | 0.00229     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1180.0     |\n",
      "|    intervention_sum              | 17          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 716         |\n",
      "|    time_elapsed                  | 67527       |\n",
      "|    total_timesteps               | 2932736     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.020186912 |\n",
      "|    clip_fraction                 | 0.0329      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.302      |\n",
      "|    explained_variance            | 0.831       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 485         |\n",
      "|    n_updates                     | 7150        |\n",
      "|    policy_gradient_loss          | 0.00604     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1280.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 717         |\n",
      "|    time_elapsed                  | 67620       |\n",
      "|    total_timesteps               | 2936832     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.019000553 |\n",
      "|    clip_fraction                 | 0.0359      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.312      |\n",
      "|    explained_variance            | 0.823       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 330         |\n",
      "|    n_updates                     | 7160        |\n",
      "|    policy_gradient_loss          | 0.00414     |\n",
      "|    value_loss                    | 1.32e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 54          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 718         |\n",
      "|    time_elapsed                  | 67713       |\n",
      "|    total_timesteps               | 2940928     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008862676 |\n",
      "|    clip_fraction                 | 0.0251      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.31       |\n",
      "|    explained_variance            | 0.853       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 333         |\n",
      "|    n_updates                     | 7170        |\n",
      "|    policy_gradient_loss          | 0.00319     |\n",
      "|    value_loss                    | 1.25e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1220.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 46         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 719        |\n",
      "|    time_elapsed                  | 67805      |\n",
      "|    total_timesteps               | 2945024    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.02171664 |\n",
      "|    clip_fraction                 | 0.0354     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.324     |\n",
      "|    explained_variance            | 0.849      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 423        |\n",
      "|    n_updates                     | 7180       |\n",
      "|    policy_gradient_loss          | 0.00719    |\n",
      "|    value_loss                    | 1.18e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1300.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 66          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 720         |\n",
      "|    time_elapsed                  | 67898       |\n",
      "|    total_timesteps               | 2949120     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013486959 |\n",
      "|    clip_fraction                 | 0.0316      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.313      |\n",
      "|    explained_variance            | 0.785       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 300         |\n",
      "|    n_updates                     | 7190        |\n",
      "|    policy_gradient_loss          | 0.00427     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 19         |\n",
      "|    nl_comm_sum                   | 44         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 721        |\n",
      "|    time_elapsed                  | 67991      |\n",
      "|    total_timesteps               | 2953216    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.04995843 |\n",
      "|    clip_fraction                 | 0.0469     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.331     |\n",
      "|    explained_variance            | 0.833      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 349        |\n",
      "|    n_updates                     | 7200       |\n",
      "|    policy_gradient_loss          | 0.00665    |\n",
      "|    value_loss                    | 1.16e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -960.0      |\n",
      "|    intervention_sum              | 12          |\n",
      "|    nl_comm_sum                   | 48          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 722         |\n",
      "|    time_elapsed                  | 68083       |\n",
      "|    total_timesteps               | 2957312     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010926752 |\n",
      "|    clip_fraction                 | 0.0263      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.313      |\n",
      "|    explained_variance            | 0.863       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 486         |\n",
      "|    n_updates                     | 7210        |\n",
      "|    policy_gradient_loss          | 0.00113     |\n",
      "|    value_loss                    | 1.05e+03    |\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------\n",
      "| episode/                         |            |\n",
      "|    direct_capacity_violation_sum | 0          |\n",
      "|    final_reward                  | -1200.0    |\n",
      "|    intervention_sum              | 18         |\n",
      "|    nl_comm_sum                   | 48         |\n",
      "| time/                            |            |\n",
      "|    fps                           | 43         |\n",
      "|    iterations                    | 723        |\n",
      "|    time_elapsed                  | 68175      |\n",
      "|    total_timesteps               | 2961408    |\n",
      "| total/                           |            |\n",
      "|    truncated                     | 0          |\n",
      "| train/                           |            |\n",
      "|    approx_kl                     | 0.01930765 |\n",
      "|    clip_fraction                 | 0.0397     |\n",
      "|    clip_range                    | 0.2        |\n",
      "|    entropy_loss                  | -0.324     |\n",
      "|    explained_variance            | 0.838      |\n",
      "|    learning_rate                 | 0.0005     |\n",
      "|    loss                          | 481        |\n",
      "|    n_updates                     | 7220       |\n",
      "|    policy_gradient_loss          | 0.00416    |\n",
      "|    value_loss                    | 1.29e+03   |\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 724         |\n",
      "|    time_elapsed                  | 68268       |\n",
      "|    total_timesteps               | 2965504     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010406798 |\n",
      "|    clip_fraction                 | 0.0248      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.311      |\n",
      "|    explained_variance            | 0.86        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 426         |\n",
      "|    n_updates                     | 7230        |\n",
      "|    policy_gradient_loss          | 0.000852    |\n",
      "|    value_loss                    | 988         |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1160.0     |\n",
      "|    intervention_sum              | 18          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 725         |\n",
      "|    time_elapsed                  | 68360       |\n",
      "|    total_timesteps               | 2969600     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010164597 |\n",
      "|    clip_fraction                 | 0.0287      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.292      |\n",
      "|    explained_variance            | 0.826       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 632         |\n",
      "|    n_updates                     | 7240        |\n",
      "|    policy_gradient_loss          | 0.00216     |\n",
      "|    value_loss                    | 1.1e+03     |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1260.0     |\n",
      "|    intervention_sum              | 19          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 726         |\n",
      "|    time_elapsed                  | 68454       |\n",
      "|    total_timesteps               | 2973696     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.012422623 |\n",
      "|    clip_fraction                 | 0.0294      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.296      |\n",
      "|    explained_variance            | 0.84        |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 242         |\n",
      "|    n_updates                     | 7250        |\n",
      "|    policy_gradient_loss          | 0.00173     |\n",
      "|    value_loss                    | 1.17e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1140.0     |\n",
      "|    intervention_sum              | 16          |\n",
      "|    nl_comm_sum                   | 50          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 727         |\n",
      "|    time_elapsed                  | 68546       |\n",
      "|    total_timesteps               | 2977792     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.011741469 |\n",
      "|    clip_fraction                 | 0.0278      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.314      |\n",
      "|    explained_variance            | 0.868       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 355         |\n",
      "|    n_updates                     | 7260        |\n",
      "|    policy_gradient_loss          | 0.0014      |\n",
      "|    value_loss                    | 1.09e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -920.0      |\n",
      "|    intervention_sum              | 13          |\n",
      "|    nl_comm_sum                   | 40          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 728         |\n",
      "|    time_elapsed                  | 68638       |\n",
      "|    total_timesteps               | 2981888     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.010822963 |\n",
      "|    clip_fraction                 | 0.0292      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.3        |\n",
      "|    explained_variance            | 0.865       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 309         |\n",
      "|    n_updates                     | 7270        |\n",
      "|    policy_gradient_loss          | 0.00391     |\n",
      "|    value_loss                    | 974         |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1460.0     |\n",
      "|    intervention_sum              | 21          |\n",
      "|    nl_comm_sum                   | 62          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 729         |\n",
      "|    time_elapsed                  | 68732       |\n",
      "|    total_timesteps               | 2985984     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.016471926 |\n",
      "|    clip_fraction                 | 0.0308      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.304      |\n",
      "|    explained_variance            | 0.808       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 290         |\n",
      "|    n_updates                     | 7280        |\n",
      "|    policy_gradient_loss          | 0.00272     |\n",
      "|    value_loss                    | 1.27e+03    |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1000.0     |\n",
      "|    intervention_sum              | 14          |\n",
      "|    nl_comm_sum                   | 44          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 730         |\n",
      "|    time_elapsed                  | 68824       |\n",
      "|    total_timesteps               | 2990080     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.008728144 |\n",
      "|    clip_fraction                 | 0.0283      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.29       |\n",
      "|    explained_variance            | 0.852       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 344         |\n",
      "|    n_updates                     | 7290        |\n",
      "|    policy_gradient_loss          | 0.00323     |\n",
      "|    value_loss                    | 1e+03       |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1320.0     |\n",
      "|    intervention_sum              | 20          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 731         |\n",
      "|    time_elapsed                  | 68916       |\n",
      "|    total_timesteps               | 2994176     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.009897022 |\n",
      "|    clip_fraction                 | 0.0274      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.297      |\n",
      "|    explained_variance            | 0.836       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 471         |\n",
      "|    n_updates                     | 7300        |\n",
      "|    policy_gradient_loss          | 0.00572     |\n",
      "|    value_loss                    | 1.18e+03    |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| episode/                         |              |\n",
      "|    direct_capacity_violation_sum | 0            |\n",
      "|    final_reward                  | -1240.0      |\n",
      "|    intervention_sum              | 19           |\n",
      "|    nl_comm_sum                   | 48           |\n",
      "| time/                            |              |\n",
      "|    fps                           | 43           |\n",
      "|    iterations                    | 732          |\n",
      "|    time_elapsed                  | 69008        |\n",
      "|    total_timesteps               | 2998272      |\n",
      "| total/                           |              |\n",
      "|    truncated                     | 0            |\n",
      "| train/                           |              |\n",
      "|    approx_kl                     | 0.0075181285 |\n",
      "|    clip_fraction                 | 0.0247       |\n",
      "|    clip_range                    | 0.2          |\n",
      "|    entropy_loss                  | -0.309       |\n",
      "|    explained_variance            | 0.851        |\n",
      "|    learning_rate                 | 0.0005       |\n",
      "|    loss                          | 300          |\n",
      "|    n_updates                     | 7310         |\n",
      "|    policy_gradient_loss          | 0.000843     |\n",
      "|    value_loss                    | 1.27e+03     |\n",
      "---------------------------------------------------\n",
      "Model saved at models/01_10-16_22_27//model_3000000_steps.zip\n",
      "--------------------------------------------------\n",
      "| episode/                         |             |\n",
      "|    direct_capacity_violation_sum | 0           |\n",
      "|    final_reward                  | -1120.0     |\n",
      "|    intervention_sum              | 15          |\n",
      "|    nl_comm_sum                   | 52          |\n",
      "| time/                            |             |\n",
      "|    fps                           | 43          |\n",
      "|    iterations                    | 733         |\n",
      "|    time_elapsed                  | 69102       |\n",
      "|    total_timesteps               | 3002368     |\n",
      "| total/                           |             |\n",
      "|    truncated                     | 0           |\n",
      "| train/                           |             |\n",
      "|    approx_kl                     | 0.013847696 |\n",
      "|    clip_fraction                 | 0.0281      |\n",
      "|    clip_range                    | 0.2         |\n",
      "|    entropy_loss                  | -0.313      |\n",
      "|    explained_variance            | 0.833       |\n",
      "|    learning_rate                 | 0.0005      |\n",
      "|    loss                          | 377         |\n",
      "|    n_updates                     | 7320        |\n",
      "|    policy_gradient_loss          | 0.00171     |\n",
      "|    value_loss                    | 1.23e+03    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.learn(\\n    total_timesteps=wandb_config[\"total_timesteps\"],\\n    callback=WandbCallback(\\n        gradient_save_freq=100,\\n        #model_save_path=f\"models/{run.id}\",\\n        verbose=1,\\n    ),\\n)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "callback = CustomTensorboardCallback(save_path = model_dir, verbose=1)    \n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=config['total_timesteps'],\n",
    "    callback=callback,\n",
    "    reset_num_timesteps = False,\n",
    "    tb_log_name=run_id\n",
    ")\n",
    "\n",
    "'''\n",
    "model.learn(\n",
    "    total_timesteps=wandb_config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        #model_save_path=f\"models/{run.id}\",\n",
    "        verbose=1,\n",
    "    ),\n",
    ")\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
